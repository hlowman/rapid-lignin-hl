---
title: "LMEMs-lignin"
author: "Heili Lowman"
date: "1/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Linear Mixed Effect Models

This document was last updated on NOVEMBER 28, 2020.

This is an R Markdown document that will walk through all of the LMEMs run for Chapter 3 of my dissertation and the resulting manuscript.

Model creation begins with fixed effects and random effects using a random intercept structure. Then, model selection follows the protocol outlined by Zuur et al. (2009, Chapter 5), beginning with a linear model, accounting for variance structure, optimizing the fixed structure, and validating best model fit using distribution of residuals and AIC values. All 24 of the below models follow the same format.

E&C Resubmission edits: I've added median grain size as a potential explanatory variable into the estuarine and marine models due to the reviewers' edits. Grain size was not measured for stream samples, so I have not added it to the overall or stream models.

**Shortcut Note: For future use, if you want to select and change multiple mentions of the same variable, hold CTRL + SHFT + ALT + M while highlighting the chosen variable and it will select all mentions within the document.**

```{r data and packages, include=FALSE}

library(tidyverse)
library(nlme)
library(multcomp)
library(emmeans)
library(GGally)

main <- read_csv("RAPID_Master_Datasheet_add_region_streamcode.csv") # Loads the newly updated dataset, as of April 8, 2019. 

#Some of the column headers have been changed, including the ones containing the "micro" symbol, which R apparently cannot process. 
#LTER_Site column - added so that naming convention is consistent, especially among stream sites which were entered differently in the "Site" column.
#Group_2 column - added to split reef sites into groupings near and far from streams by date. 
#Group_3 column - added to create regions from west to east as discussed with Matthieu.
# In addition, all NDs from Matthieu's original reports are replaced as NAs.

```

First, I reviewed all of the columns that were added manually to the original dataset to make data grouping by date easier.

Next, I am going to review the data in the tidyverse and make sure everything is in the correct numerical format and remove outliers for the *entirety* of the dataset.

```{r tidying up, include=FALSE}

# Format

str(main) # Shows the format of each of the columns in the dataset.

# Need to make Depth and Group_3 factors and convert C.N, C, and P numeric.

main$Depthf <- as.factor(main$Depth) # Makes the water depth column a series of factors.

main$Group_3f <- as.factor(main$Group_3) # Makes the regional column a series of factors.

# I don't actually use the following columns in the analysis, but figured it's best to make these transformations just in case.

main$C.Nnum <- as.numeric(main$C.N) # Makes the C:N column a series of numbers.

main$Cnum <- as.numeric(main$C) # Makes the cinnamyl column a series of numbers.

main$Pnum <- as.numeric(main$P) # Makes the p-phenol column a series of numbers.

# NAs and 0s

# The only "<0.01"s appear to be in the "C" column, so going to leave those since this column is not being analyzed in this code.

# Upon further inspection of the dataset, I feel it makes the most sense to only alter those columns that are needed for the below analysis, so that's what I'll do. See below:

# See e-mail correspondence with Matthieu on 1/22/2020: "ND does not mean 0. When doing analytical measurements using GC/MS or others detectors you never can say that you have 0. Indeed, due to analytical issues you have limits of quantification and limits of detection. To summarize, when you are under LOD, it does not mean that you do not have the presence of the analyte but that you cannot decipher it from the background."

# So, all NAs that were previously NDs will be left as such since they are not actually a 0 value.

# Outliers based on past models. I'm going to work through these and take a more conservative approach with removing outliers from the whole dataset.

# full (6)
# Sigma8 - 66
# Lambda - 164, 238 (choosing to keep in 161)
# S/V - 387 (choosing to keep in 282, 299, 301, 443)
# C/V - 389
# PVS - (choosing to keep in 21, 23)
# BdV - 300

# marine (1)
# Sigma8 - 56, 172 (238), (choosing to keep in 301 (367))
# Lambda - 172 (238) (choosing to keep in 374 (454))

# stream (0)
# Sigma8 - 2 (66)

# estuary (0)
# CV - 47 (389)

# Alright, so the seven outliers I'm removing will be 56, 66, 164, 238, 300, 387, and 389 from the original dataset.

mained <- main[ -c(56, 66, 164, 238, 300, 387, 389), ] # Starts with the original dataset and then removes desired rows.

# Quick calculation for manuscript:

OCmeans <- mained %>%
  group_by(Environment) %>%
  summarize(meanOC = mean(perc_OrgC, na.rm = TRUE), sdOC = sd(perc_OrgC, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

These models will be organized in this file as they are listed in Appendix Figure 13 of the manuscript.

# Entire Dataset

## Sigma 8

```{r Sigma, include=FALSE}

### Data Exploration

# I'm examining Region, Ecosystem Type (Stream, Estuarine, and Marine), Site, and Date as factors influencing lignin oxidation results. Here are the boxplots and pairplots necessary.

boxplot(Sigma8 ~ Group_3f, data = mained) # Boxplot by region. In past iterations, this was determined not to be a significant factor, but I am going to keep it in the workflow as a potential fixed effect for now.
boxplot(Sigma8 ~ Environment, data = mained) # Boxplot by environment. Fixed effect.
boxplot(Sigma8 ~ LTER_Site, data = mained) # Boxplot by site. Random effect - 11/28/2020, adding layers of water depth, replicates, and core section, which are not applicable to stream sites but are to estuarine/marine and must be considered.
boxplot(Sigma8 ~ Group, data = mained) # Boxplot by sampling date. Group lumps everything sampled on a single date together - the problem with this sampling design is that the sampling dates are SUPER closely correlated with Environment, but there are not consistent time blocks you can instead use to assign to each group of samples.

# New dataset.

sig <- mained %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Depthf, Replicate, Core, Group, Sigma8) %>%
  filter(!is.na(Sigma8)) %>%
  replace_na(list(Depthf = 10, Replicate = 1, Core = "T")) 
  # remove NAs and create new dataset.

ggpairs(sig) # Pairs plot.

sig$Environment <- factor(sig$Environment, levels = c("Stream", "Estuary", "Reef")) # Relevels for simpler labeling later.

#### STEP 1: Create a linear regression and check residuals.

# Reasoning for log-transforming Sigma values: per Chapter 19 of Zuur et al. 2009, I'm going to log transform the Sigma data because otherwise (using different variance structures) you are giving up lots of degrees of freedom and make GLS estimation unstable. And I KNOW homogeneity is an issue based on past attempts and the sheer spread of values. I know that this changes the values, but this will give me more flexibility in exploring explanatory variables, which I think is more important that the values themselves. I've applied a similar reasoning to the P/V+S and 3,5Bd/V models below as well.

sig$logSigma8 <- log10(sig$Sigma8) # Log transform data to make heterogeneity of residuals a non-issue (hopefully).

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(sig$Sigma8, groups = sig$LTER_Site) # Sigma8 versus Site on left.
dotchart(sig$logSigma8, groups = sig$LTER_Site) # Log(Sigma8) versus Site on right.
par(op) # Looking better! And I've deemed the negative values to be A-OK since it's not a Poisson distribution (according to Ana MtK).

# Based on boxplots & pairplots : 
# Response variables - logSigma8
# Explanatory (fixed) variables - Group_3f, Environment

a1 <- lm(logSigma8 ~ Environment + Group_3f, data = sig) # Creates the initial linear model with both fixed variables.
ra1 <- rstandard(a1) # Assigns standardized residuals to ra1.
sig <- sig %>%
  mutate(ra1 = ra1)

ggplot(data = sig, aes(x = Environment, y = ra1)) +
  geom_boxplot() + 
  geom_point() +
  labs(x = "Ecosystem", y = "Standardised residuals") # Plots said residuals.

ggplot(data = sig, aes(x = Group, y = ra1)) +
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

a2 <- gls(logSigma8 ~ Group_3f + Environment, data = sig) # This is effectively a linear regression since it has no additional calls.
a3 <- lme(logSigma8 ~ Group_3f + Environment, random =~1 | LTER_Site/Depthf/Replicate/Core, data = sig) # Creates the first LMEM with nested random term. I've subbed in dummy values for Depthf, Replicate, and Core for stream/estuarine sites that might not otherwise have all these.
anova(a2, a3) # Compares the two models. a3 preferred with AIC value of 486.318.

# STEP 3: Decide on a variance structure (aka random terms).

plot(a3, col=1) # Check the residuals before jumping right to applying a variance transformation.
qqnorm(a3) # This actually looks pretty good - so I'm going to skip the added variance structure. (This is likely thanks to the log transformation.)

# SIDE NOTE: KEEP IN MIND, log-transforming from the start is more powerful than adding in a variance component on the back end!!!

# STEP 4: Fit the lme().

# Using a3 <- lme(logSigma8 ~ Group_3f + Environment, random =~1 | LTER_Site/Depthf/Replicate/Core, data = sig)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

a3_ml <- lme(logSigma8 ~ Group_3f + Environment, 
      random =~1 | LTER_Site/Depthf/Replicate/Core,
      method = "ML", data = sig) # Switch over to ML for fixed component editing portion.

a4 <- lme(logSigma8 ~ Environment, 
      random =~1 | LTER_Site/Depthf/Replicate/Core,
      method = "ML", data = sig) # Remove Region as a fixed factor.

a5 <- lme(logSigma8 ~ Group_3f, 
      random =~1 | LTER_Site/Depthf/Replicate/Core,
      method = "ML", data = sig) # Remove Environment as a fixed factor.

anova(a3_ml, a4, a5) # Compare the three models. a4 preferred with AIC value of474.7521, so remove Region.

a4full <- lme(logSigma8 ~ Environment, 
      random =~1 | LTER_Site/Depthf/Replicate/Core,
      method = "ML", data = sig)

a4sub1 <- update(a4full, .~. -Environment) # Removes only term.

anova(a4full, a4sub1) # a4full preferred with AIC value of 474.7521, so a4full is the final full model!!!

# STEP 9: Refit with REML

afinal <- lme(logSigma8 ~ Environment, 
              random =~1 | LTER_Site/Depthf/Replicate/Core, method = "REML", data = sig) # YIPEE!!!

# Output of the model.
summary(afinal)

# Checking residuals.
plot(afinal, col=1) # Not perfect, but no pattern.
qqnorm(afinal) # This makes me feel pretty good.

# Final results.
anova(afinal)

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested with multiple samples (4+) taken from each site (18) on multiple occasions (2+). My model suggests there is a significant effect of ecosystem/environment type (stream, estuarine, marine) on Sigma 8 concentrations of a given sediment sample. Group (date sampled) and fGroup_3 (region sampled) were not included in the model due to variable selection using AIC values. Random intercepts by site/depth/replicate/core were added.

# Equation: log(Sigma 8) = 0.65 - 0.69[Estuary] - 1.25[Reef] + random

# BONUS POST HOC:

aHSD <- glht(afinal, linfct=mcp(Environment="Tukey")) # Run a Tukey's post hoc analysis on Environment factor.
summary(aHSD) # Stream & Reef significantly different from one another. Note : Use the results of the first run on this function.

# Quick stats calculation of Sigma8 values by environment for the manuscript:

sigmeans <- sig %>%
  group_by(Environment) %>%
  summarize(meanSig8 = mean(Sigma8, na.rm = TRUE), sdSig8 = sd(Sigma8, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : logSigma8 ~ Environment + 1|LTER_Site/Depth/Replicate/Core.

This translates to a formula of log(Sigma 8) = 0.65 - 0.69[Estuary] - 1.25[Reef] + random.

Post hoc results: Stream - Reef, p < 0.001

## Lambda

```{r Lambda, include=FALSE}

### Data Exploration - boxplots and pairplots

boxplot(Lambda ~ Group_3f, data = mained) # Boxplot by region. Fixed effect.
boxplot(Lambda ~ Environment, data = mained) # Boxplot by environment. Fixed effect.
boxplot(Lambda ~ LTER_Site, data = mained) # Boxplot by sampling site. Random effect.
boxplot(Lambda ~ Group, data = mained) # Boxplot by sampling site. Random effect.

# So, based on boxplots and Sigma model, I move forward with Group_3f (region) and Environment as fixed variables and Site/Depth/Replicate/Core as random NESTED variables.

lambda <- mained %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Depthf, Replicate, Core, Group, Lambda) %>%
  filter(!is.na(Lambda)) %>%
  replace_na(list(Depthf = 10, Replicate = 1, Core = "T")) # remove NAs and create new dataset.

lambda$Environment <- factor(lambda$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(lambda$Lambda, groups = lambda$LTER_Site) # Lambda versus Site on left from original dataset.
par(op) # Looking ok, but we're trying to keep outlier removal to a minimum, so moving on...

ggpairs(lambda) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Since the lambda data is normalized to organic carbon content, these values are much more normally distributed than the Sigma8 data. So, I've chosen not to transform the data in any way.

# Response variables - Lambda
# Explanatory variables - Group_3f, Environment

b1 <- lm(Lambda ~ Group_3f + Environment, data = lambda) # Creates the initial linear model.
rb1 <- rstandard(b1) # Assigns standardized residuals to rb1.
lambda <- lambda %>%
  mutate(rb1 = rb1)

ggplot(data = sig, aes(x = LTER_Site, y = ra1)) +
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = sig, aes(x = Group, y = ra1)) +
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

b2 <- gls(Lambda ~ Group_3f + Environment, data = lambda) # This is effectively a linear regression since it has no additional calls.
b3 <- lme(Lambda ~ Group_3f + Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, data = lambda) # Creates the first LMEM with random term.
anova(b2, b3) # Compares the two models. b3 preferred based on AIC value of 1034.102.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(b3, col=1) # Plots residuals before immediately applying variance transformation.
qqnorm(b3) # Does not appear it's needed.

# STEP 4: Fit the lme().

# Using b3 <- lme(Lambda ~ Group_3f + Environment, random =~1 | LTER_Site/Depthf/Replicate/Core, data = lambda)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

b4_ml <- lme(Lambda ~ Group_3f + Environment, 
             random =~1 | LTER_Site/Depthf/Replicate/Core, method = "ML", data = lambda) # Creates model using ML structure.

b5 <- lme(Lambda ~ Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, method = "ML", data = lambda) # Removes region.

b6 <- lme(Lambda ~ Group_3f, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, method = "ML", data = lambda) # Removes ecosystem.

anova(b4_ml, b5, b6) # Compares all three models. b5 is preferred with AIC value of 1024.237. So, we take out region.

b5full <- lme(Lambda ~ Environment, 
              random =~1 | LTER_Site/Depthf/Replicate/Core, method = "ML", data = lambda)

b5sub1 <- update(b5full, .~. -Environment) # Removes only term. Just checking...

anova(b5full, b5sub1) # First term needs to be in there.

# b5full is the final full model!!!

# STEP 9: Refit with REML

bfinal <- lme(Lambda ~ Environment, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "REML", data = lambda)

# Output of the model.
summary(bfinal)
plot(bfinal, col=1) # Checking residuals.
qqnorm(bfinal) # A little curvy, but ok.

# Final results.
anova(bfinal)

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of ecosystem type (stream, estuarine, marine) on lambda concentrations of a given sediment sample. fGroup_3 (region sampled) was not included in the model due to variable selection using AIC values. A random intercept by site/depth/replicate/core was added.

# Equation: Lambda = 2.13 + 0.03[Estuary] - 1.07[Reef] + random

# BONUS : Tukey's HSD Post Hoc
bHSD <- glht(bfinal, linfct=mcp(Environment="Tukey"))
summary(bHSD) # No significant difference between Stream & Estuarine samples.

# Quick stats calculation of Lambda values by environment for the manuscript:

lammeans <- lambda %>%
  group_by(Environment) %>%
  summarize(meanLam = mean(Lambda, na.rm = TRUE), sdLam = sd(Lambda, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : Lambda ~ Environment + 1|LTER_Site/Depthf/Replicate/Core

This translated to a formula of Lambda = 2.13 + 0.03[Estuary] - 1.07[Reef] + random.

Post hoc results: Stream - Estuary, p = 0.998 (NS); Estuary - Reef, p = 0.0062; Stream - Reef, p < 0.001.

## S/V

```{r S/V, include=FALSE}

### Data Exploration

boxplot(S/V ~ Group_3f, data = mained) # Boxplot by region. Fixed effect.
boxplot(S/V ~ Environment, data = mained) # Boxplot by environment. Fixed effect.
boxplot(S/V ~ LTER_Site, data = mained) # Boxplot by site. Random effect.
boxplot(S/V ~ Group, data = mained) # Boxplot by date. Random effect.

# So, based on boxplots and Sigma model, I move forward with Group_3f (region) and Environment as fixed variables and Site/Depth/Replicate/Core as random NESTED variables.

sv <- mained %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Depthf, Replicate, Core, Group, `S/V`) %>%
  filter(!is.na(`S/V`)) %>%
  mutate(SV = `S/V`) %>%
  replace_na(list(Depthf = 10, Replicate = 1, Core = "T")) # remove NAs and create new dataset.

sv$Environment <- factor(sv$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(sv$S.V, groups = sv$LTER_Site) # S/V versus Site.
par(op) # Looking ok.

ggpairs(sv) # Quick pairs plot to check correlated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - S/V
# Explanatory variables - Group_3f, Environment

c1 <- lm(SV ~ Group_3f + Environment, data = sv) # Creates the linear model.
rc1 <- rstandard(c1) # Assigns standardized residuals to rc1.
sv <- sv %>%
  mutate(rc1 = rc1)

ggplot(data = sv, aes(x = LTER_Site, y = rc1)) +
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

#### STEP 2: Fit the lm() with GLS and compare to lme().

c2 <- gls(SV ~ Group_3f + Environment, data = sv) # Linear regression.
c3 <- lme(SV ~ Group_3f + Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, data = sv) # Creates the first LMEM with random term.
anova(c2, c3) # Compares the two models. c3 preferred with AIC value of 1478.488.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(c3, col=1) # Plots residuals before immediately applying variance transformation.
qqnorm(c3) # Need a variacne structure by environment based on boxplots above.

c4 <- lme(SV ~ Group_3f + Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          data = sv,
          weights = varIdent(form =~1 | Environment))

anova(c3, c4) # Compares the two models. c3 is better with an AIC value of 1478.488, so we'll leave out this structure for now.

qqnorm(c4) # Also, the variance transformation hasn't improved the looks of the qqplot anyway.

# STEP 4: Fit the lme().

# Using c3 <- lme(SV ~ Group_3f + Environment, random =~1 | LTER_Site / Depthf / Replicate / Core, data = sv)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

c3_ml <- lme(SV ~ Group_3f + Environment, 
             random =~1 | LTER_Site/Depthf/Replicate/Core,
             method = "ML", data = sv) # Creates current model using ML structure.
c5 <- lme(SV ~ Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "ML", data = sv) # Removes region.
c6 <- lme(SV ~ Group_3f, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "ML", data = sv) # Removes ecosystem.
anova(c3_ml, c5, c6) # Compares all three models. c5 preferred with AIC value of 1474.168. So remove region.

c5full <- lme(SV ~ Environment, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "ML", data = sv)
c5sub1 <- update(c5full, .~. -Environment) # Just checking...
anova(c5full, c5sub1) # c6sub1 preferred, with AIC value of 1472.719, but I'm going to keep Environment in to have a structure of comparison.
# c5full is the final full model!!!

# STEP 9: Refit with REML

cfinal <- lme(SV ~ Environment, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "REML", data = sv)

# Output of the model.
summary(cfinal)
plot(cfinal, col=1) # Checking residuals.
qqnorm(cfinal) # I'll take it.

# Final results.
anova(cfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of either ecosystem type (stream, estuarine, marine) or Region (west to east) on S/V signatures of a given sediment sample. Random nested intercepts by site/depth/replicate/core were included.

# Equation: S/V = 2.45 + 0.22[Estuary] + 0.62[Reef] + random

# BONUS : Tukey's HSD Post Hoc
cHSD <- glht(cfinal, linfct=mcp(Environment="Tukey"))
summary(cHSD) # No significant difference between any samples by environment.

# Value calculations for manuscript:

svmeans <- mained %>% # Takes the original dataset and then ...
  group_by(Environment) %>%     # Groups data and then ...
  summarize(meanSV = mean(S.V, na.rm = TRUE), sdSV = sd(S.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : S/V ~ Environment + 1|LTER_Site / Depthf / Replicate / Core

This translated to a formula of S/V = 2.45 + 0.22[Estuary] + 0.62[Reef] + random.

Post hoc results: All Environment comparisons, p > 0.05 (NS).

## C/V

```{r C/V, include=FALSE}

### Data Exploration

boxplot(C.V ~ Group_3f, data = mained) # Regional boxplot. Fixed effect.
boxplot(C.V ~ Environment, data = mained) # Environmental boxplot. Fixed effect.
boxplot(C.V ~ LTER_Site, data = mained) # Site boxplot. Random effect.
boxplot(C.V ~ Group, data = mained) # Date boxplot. Fixed + random effect?

# So, based on boxplots and Sigma model, I move forward with Group_3 (region) and Environment as fixed variables and Site/Depth/Replicate/Core as random NESTED variables, as with S/V.

cv <- mained %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Depthf, Replicate, Core, Group, `C/V`) %>%
  filter(!is.na(`C/V`)) %>%
  mutate(CV = `C/V`) %>%
  replace_na(list(Depthf = 10, Replicate = 1, Core = "T")) # remove NAs and create new dataset.

cv$Environment <- factor(cv$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(cv$C.V, groups = cv$LTER_Site) # C/V versus Site on left from original dataset.
par(op) # Ok, leaving this for now, and we'll see how the residuals look.

ggpairs(cv) # Quick pairs plot to check correllated variables. Yep, variable choices still look good.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - C/V
# Explanatory variables - Group_3f, Environment

d1 <- lm(CV ~ Group_3f + Environment, data = cv) # Initial linear model.
rd1 <- rstandard(d1) # Assigns standardized residuals to rd1.
cv <- cv %>%
  mutate(rd1 = rd1)

ggplot(data = cv, aes(x = LTER_Site, y = rd1)) +
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

#### STEP 2: Fit the lm() with GLS and compare to lme().

d2 <- gls(CV ~ Group_3f + Environment, data = cv) # Linear regression.
d3 <- lme(CV ~ Group_3f + Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, data = cv) # Creates the first LMEM with random term.
anova(d2, d3) # Compares the two models. d3 preferred with AIC value of -619.3107.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(d3, col=1) # Plots residuals before immediately applying variance transformation. Looks fine.
qqnorm(d3) # Yeah, this curve resembles the one in the S/V data.

# Moving forward without additional variance structure.

# STEP 4: Fit the lme().

# Using d3 <- lme(CV ~ Group_3f + Environment, random =~1 | LTER_Site/Depthf/Replicate/Core, data = cv)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

d3_ml <- lme(CV ~ Group_3f + Environment, 
             random =~1 | LTER_Site/Depthf/Replicate/Core,
             method = "ML", data = cv) # Creates current model using ML structure.
d4 <- lme(CV ~ Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          method = "ML", data = cv) # Removes region.
d5 <- lme(CV ~ Group_3f, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          method = "ML", data = cv) # Removes ecosystem.
anova(d3_ml, d4, d5) # Compares all three models. d7 is preferred with AIC value of -651.5736. So, I will remove region.

d6full <- lme(CV ~ Environment, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "ML", data = cv)
d6sub1 <- update(d6full, .~. -Environment) # Is Environment necessary?
anova(d6full, d6sub1) # d6full is preferred with an AIC value of -651.5736 so yes!
# d6full is the final full model!!!

# STEP 9: Refit with REML

dfinal <- lme(CV ~ Environment, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "REML", data = cv) # Yay!! 

# Output of the model.
summary(dfinal)
plot(dfinal, col=1) # Checking residuals.
qqnorm(dfinal) # I'll take it.

# Final results.
anova(dfinal) # Output for the paper

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of ecosystem type (stream, estuarine, marine) but not Region (west to east) on C/V signatures of a given sediment sample. Random nested intercepts by site/depth/replicate/core were included.

# Equation: C/V = 0.27 + 0.04[Estuary] - 0.17[Reef] + random

# BONUS : Tukey's HSD Post Hoc
dHSD <- glht(dfinal, linfct=mcp(Environment="Tukey"))
summary(dHSD) # See below for results.

# Value calculations for manuscript:

cvmeans <- mained %>% # Takes the original dataset and then ...
  group_by(Environment) %>%     # Groups data and then ...
  summarize(meanCV = mean(C.V, na.rm = TRUE), sdCV = sd(C.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : C.V ~ Environment + 1|LTER_Site / Depth / Replicate / Core

This translated to a formula of C/V = 0.27 + 0.04[Estuary] - 0.17[Reef] + random.

Post hoc results: Stream - Estuary, p = 0.47 (NS); Stream - Reef, p < 0.0001; Estuary - Reef, p < 0.0001.

##P/V+S

```{r P/V+S, include=FALSE}

### Data Exploration

boxplot(P..V.S. ~ Group_3f, data = mained) # Regional boxplot. Fixed effect
boxplot(P..V.S. ~ Environment, data = mained) # Environment boxplot. Fixed effect.
boxplot(P..V.S. ~ LTER_Site, data = mained) # Site boxplot. Random effect.
boxplot(P..V.S. ~ Group, data = mained) # Sampling date boxplot. Random effect. Again, looks like there may be a temporal trend, but I am going to focus on differentiating between environments for now, since I do not feel I can do both.

# So, based on boxplots, I move forward with Group_3f (region) and Environment as fixed variables and random NESTED variable as above.

pvs <- mained %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Depthf, Replicate, Core, Group, `P/(V+S)`) %>%
  filter(!is.na(`P/(V+S)`)) %>%
  mutate(PVS = `P/(V+S)`) %>%
  replace_na(list(Depthf = 10, Replicate = 1, Core = "T"))

pvs$Environment <- factor(pvs$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(pvs$P..V.S., groups = pvs$LTER_Site) # P/V+S versus Site.
par(op) # Looking ok - I think I'm going to log transform since I'm not taking out any more outliers.

pvs$logPVS <- log10(pvs$PVS) # Makes log-transformed column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(pvs$P..V.S., groups = pvs$LTER_Site) # P/V+S versus Site on left from created dataset.
dotchart(pvs$logPVS, groups = pvs$LTER_Site) # log(P/V+S) versus Site on right from created dataset.
par(op) # Looking way better!!

ggpairs(pvs) # Quick pairs plot to check correllated variables. Yep, variable choices still look good.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - P/V+S
# Explanatory variables - Group_3f, Environment

e1 <- lm(logPVS ~ Group_3f + Environment, data = pvs) # Creates the initial linear model.
re1 <- rstandard(e1) # Assigns standardized residuals to e.j.
pvs <- pvs %>%
  mutate(re1 = re1)

ggplot(data = pvs, aes(x = LTER_Site, y = re1)) +
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

#### STEP 2: Fit the lm() with GLS and compare to lme().

e2 <- gls(logPVS ~ Group_3f + Environment, data = pvs) # Linear regression.
e3 <- lme(logPVS ~ Group_3f + Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          data = pvs) # Creates the first LMEM with random term.
anova(e2, e3) # Compares the two models. e3 preferred with an AIC value of 135.4327.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(e3, col=1) # Plots residuals before immediately applying variance transformation.
qqnorm(e3) # Looks A-OK!

# I'm going back to the simpler structure of e3.

# STEP 4: Fit the lme().

# Using e3 <- lme(logPVS ~ Group_3f + Environment, random =~1 | LTER_Site/Depthf/Replicate/Core, data = pvs)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

e3_ml <- lme(logPVS ~ Group_3f + Environment, 
             random =~1 | LTER_Site/Depthf/Replicate/Core,
             method = "ML", data = pvs) # Creates model using ML structure.
e4 <- lme(logPVS ~ Environment, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "ML", data = pvs) # Removes region.
e5 <- lme(logPVS ~ Group_3f, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "ML", data = pvs) # Removes ecosystem.
anova(e3_ml, e4, e5) # Compares all three models. e4 is slightly preferred with an AIC value of 118.0819. So, remove region.

e6full <- lme(logPVS ~ Environment, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "ML", data = pvs)
e6sub1 <- update(e6full, .~. -Environment) # Just checking...
anova(e6full, e6sub1) # So removing both fixed variables, e6sub1, is preferred with an AIC value of 114.5014.

#To stick with our "Environment" as a fixed effect, I'm going to use e6full going forward.

# STEP 9: Refit with REML

efinal <- lme(logPVS ~ Environment, 
              random = ~1 | LTER_Site/Depthf/Replicate/Core,
              method = "REML", data = pvs)

# Output of the model.
summary(efinal)
plot(efinal, col=1) # Checking residuals.
qqnorm(efinal) # I'll take it.

# Final results.
anova(efinal) # Output for the paper

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of either ecosystem type (stream, estuarine, marine) or Region (west to east) on P/V+S signatures of a given sediment sample. Random nested intercepts by site/depth/replicate/core section sampled.

# Equation: log(P/V+S) = -0.77 - 0.09[Estuary] - 0.01[Reef] + random

# BONUS : Tukey's HSD Post Hoc

# NA.

# Value calculations for manuscript:

pvsmeans <- mained %>% # Takes the original dataset and then ...
  group_by(Environment) %>%     # Groups data and then ...
  summarize(meanPVS = mean(P..V.S., na.rm = TRUE), sdPVS = sd(P..V.S., na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : log(PVS) ~ Environment + 1|LTER_Site/Depth/Replicate/Core

This translated to a formula of log(P/V+S) = -0.77 - 0.09[Estuary] - 0.01[Reef] + random.

Post hoc results: NA.

##3,5Bd/V

```{r 35Bd/V, include=FALSE}

### Data Exploration

boxplot(Bd.V ~ Group_3f, data = mained) # Regional boxplot. Fixed effect.
boxplot(Bd.V ~ Environment, data = mained) # Environmental boxplot. Fixed effect.
boxplot(Bd.V ~ LTER_Site, data = mained) # Site boxplot. Random effect.
boxplot(Bd.V ~ Group, data = mained) # Date boxplot. Random effect.

# So, based on boxplots, I move forward with Group_3f (region) and Environment as fixed variables and Group (date sampled) and Site as random NESTED variables.

bdv <- mained %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Group, Bd.V) %>%
  na.omit # Creates a final dataset with no outliers or NAs. 

bdv$Environment <- factor(bdv$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(bdv$Bd.V, groups = bdv$LTER_Site) # Bd/V versus Site on left from original dataset.
par(op) # Looking ok - I think I'm going to log transform again.

bdv$logBDV <- log10(bdv$Bd.V) # Makes log-transformed column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(bdv$Bd.V, groups = bdv$LTER_Site) # Bd/V versus Site on left from created dataset.
dotchart(bdv$logBDV, groups = bdv$LTER_Site) # log(Bd/V) versus Site on right from created dataset.
par(op) # Looking way better!!

pairs(bdv) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - 3,5-Bd/V
# Explanatory variables - Group_3f, Environment

f1 <- lm(logBDV ~ Group_3f + Environment, data = bdv) # Creates the initial linear model with both fixed variables.
rf1 <- rstandard(f1) # Assigns standardized residuals to rf1.
plot(rf1 ~ bdv$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Keeping it as part of a random structure.

plot(rf1 ~ bdv$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not quite as extreme as Site, but I still want to include it in my random structure. This will probably come out...

#### STEP 2: Fit the lm() with GLS and compare to lme().

f2 <- gls(logBDV ~ Group_3f + Environment, data = bdv) # Linear regression.
f3 <- lme(logBDV ~ Group_3f + Environment, 
          random =~1 | LTER_Site / Group, data = bdv) # Creates the first LMEM.
anova(f2, f3) # Compares the two models. f3 preferred with AIC value of 165.1639.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

f4 <- lme(logBDV ~ Group_3f + Environment, 
          random =~1 | Group, data = bdv) # Remove Site from random term.
f5 <- lme(logBDV ~ Group_3f + Environment, 
          random =~1 | LTER_Site, data = bdv) # Remove Date sampled from random term.
anova(f3, f4, f5) # Compares all three models. f3 is preferred, so keep random term as is.

plot(f3, col=1) # Plots residuals before immediately applying variance transformation. I don't think we need an additional variance structure.

# STEP 4: Fit the lme().

# Using f3 <- lme(logBDV ~ Group_3f + Environment, random =~1 | LTER_Site / Group, data = bdv)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(f3, col=1) # Residuals look good.
qqnorm(f3) # Looks good!!

# STEP 7/8: Step-wise Optimal Fixed Structure

f3_ml <- lme(logBDV ~ Group_3f + Environment, 
             random =~1 | LTER_Site / Group, method = "ML", data = bdv) # Creates current model using ML structure.
f6 <- lme(logBDV ~ Environment, 
          random =~1 | LTER_Site / Group, method = "ML", data = bdv) # Removes region.
f7 <- lme(logBDV ~ Group_3f, 
          random =~1 | LTER_Site / Group, method = "ML", data = bdv) # Removes ecosystem.
anova(f3_ml, f6, f7) # Compares all three models. f6 is preferred with an AIC value of 143.6322. So, remove Region.

f6full <- lme(logBDV ~ Environment, 
              random =~1 | LTER_Site / Group, method = "ML", data = bdv)
f6sub1 <- update(f6full, .~. -Environment) # Just checking...
anova(f6full, f6sub1) # So keep Environment. f6full has an AIC value of 143.6322.

# STEP 9: Refit with REML

ffinal <- lme(logBDV ~ Environment, 
              random =~1 | LTER_Site / Group, method = "REML", data = bdv) # Final full model.

# Output of the model.
summary(ffinal)
plot(ffinal, col=1) # Checking residuals.
qqnorm(ffinal) # I'll take it.
intervals(ffinal) # Show intervals.

# Final results.
anova(ffinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of ecosystem type (stream, estuarine, marine) on 3,5-Bd/V signatures of a given sediment sample. Random nested intercepts by date sampled and site were also included.

# Equation: log(3,5-Bd/V) = -0.77 + 0.009[Estuary] + 0.40[Reef] + random

# BONUS : Tukey's HSD Post Hoc
fHSD <- glht(ffinal, linfct=mcp(Environment="Tukey"))
summary(fHSD) # Significantly different (p<0.0001): Stream & Reef and Estuary & Reef

# Value calculations for manuscript:

bdvmeans <- mained %>% # Takes the original dataset and then ...
  group_by(Environment) %>%     # Groups data and then ...
  summarize(meanBdv = mean(Bd.V, na.rm = TRUE), sdBdv = sd(Bd.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : log(PVS) ~ Environment + 1|LTER_Site / Group

This translated to a formula of log(P/V+S) = -0.77 + 0.009[Estuary] + 0.40[Reef] + random.

Post hoc results: Stream - Estuary, p = 0.996 (NS); Stream - Reef, p < 0.0001; Estuary - Reef, p < 0.0001.

#Stream Data

```{r stream data, include=FALSE}

stream <- read_csv("stream_only_ed.csv") # This imports a stream-data only dataset with watershed characteristics added in (watershed area, land cover, etc.)

streamed <- stream[ -2, ]# Removes the necessary outliers.

```

##Sigma 8 (stream)

```{r Sigma stream, include=FALSE}

### Data Exploration

sigstream <- streamed %>%
  dplyr::select(LTER_Site, Area, Land_Cover, Group, Sigma8) %>%
  na.omit # Create new dataset. Not testing region any longer since I've decided it's arbitrary.

boxplot(Sigma8 ~ LTER_Site, data = sigstream) # Site boxplot. Random effect.
boxplot(Sigma8 ~ Group, data = sigstream) # Date boxplot. Fixed effect.
boxplot(Sigma8 ~ Area, data = sigstream) # Watershed area boxplot. Fixed effect?
boxplot(Sigma8 ~ Land_Cover, data = sigstream) # Land cover boxplot. Fixed effect.

pairs(sigstream) # Pairs plot. So, I'm going to investigate all three as fixed effects at first, but Site should go in as a random effect too.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - Sigma8
# Explanatory variables - Group, Land_Cover, Watershed Area

g1 <- lm(Sigma8 ~ Group + Land_Cover + Area, data = sigstream) # Creates the initial linear model with all fixed variables.
rg1 <- rstandard(g1) # Assigns standardized residuals to rg1.

plot(rg1 ~ sigstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Site WILL be used as a random effect.

plot(rg1 ~ sigstream$Group, xlab = "Date",
     ylab = "Standardised residuals") 
abline(0,0) # Group looks all about zero, so removing as a random effect.

plot(rg1 ~ sigstream$Area, xlab = "Watershed Size",
     ylab = "Standardised residuals") 
abline(0,0) # Watershed size looks all about zero.

plot(rg1 ~ sigstream$Land_Cover, xlab = "Land Use",
     ylab = "Standardised residuals") 
abline(0,0) # Same here.

#### STEP 2: Fit the lm() with GLS and compare to lme().

g2 <- gls(Sigma8 ~ Group + Land_Cover + Area, data = sigstream)

g3 <- lme(Sigma8 ~ Group + Land_Cover + Area, 
          random =~1 | LTER_Site, data = sigstream) # Creates the first LMEM.

anova(g2, g3) # Compares the two models. g3 preferred with AIC of 122.1638.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(g3, col=1) # Check the residuals.
qqnorm(g3) # This is ok...

# No additional variance structure necessary.

# STEP 4: Fit the lme().

# Using g3 <- lme(Sigma8 ~ Group + Land_Cover + Area, random =~1 | LTER_Site, data = sigstream)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

g3_ml <- lme(Sigma8 ~ Group + Land_Cover + Area, 
             random =~1 | LTER_Site, method = "ML", data = sigstream)
# Need to switch over to ML for the fixed component editing portion.

g3sub1 <- update(g3_ml, .~. -Group) # Removes Group.
g3sub2 <- update(g3_ml, .~. -Land_Cover) # Removes Land_Cover.
g3sub3 <- update(g3_ml, .~. -Area) # Removes Area.

anova(g3_ml, g3sub1, g3sub2, g3sub3) # Compare the models. sub3 preferred with and AIC value of 130.9081, so remove Area.

g4 <- lme(Sigma8 ~ Group + Land_Cover, 
          random =~1 | LTER_Site, method = "ML", data = sigstream)

g4sub1 <- update(g4, .~. -Group) # Removes Group.
g4sub2 <- update(g4, .~. -Land_Cover) # Removes Land_Cover.

anova(g4, g4sub1, g4sub2) # Compares the models. g4 preferred with an AIC value of 130.9081, so keep them both in.

g4full <- lme(Sigma8 ~ Group + Land_Cover, 
              random =~1 | LTER_Site, method = "ML", data = sigstream) # the final full model!!!

# STEP 9: Refit with REML

gfinal <- lme(Sigma8 ~ Group + Land_Cover, 
              random =~1 | LTER_Site, method = "REML", data = sigstream)

# Output of the model.
summary(gfinal)

# Checking residuals.
plot(gfinal, col=1) # No pattern.
qqnorm(gfinal) # This makes me feel pretty good.
intervals(gfinal) # Show intervals.

# Final results.
anova(gfinal)

# STEP 10: What does this mean in WORDS?

# My model suggests there is NO significant effect of sampling date OR land use/cover on Sigma 8 concentrations of a given stream sediment sample.

# Equation: Sigma 8 = 2.59 + 1.91[GroupC] + 3.39[GroupI] - 1.12[Undeveloped] + 3.09[Urban] + random

# POST HOC: NA


```

The final model took the form : Sigma ~ Group + Land_Cover + 1|LTER_Site

This translated to a formula of Sigma 8 = 2.59 + 1.91[GroupC] + 3.39[GroupI] - 1.12[Undeveloped] + 3.09[Urban] + random

Post hoc results: NA.

## Lambda (stream)

```{r Lambda stream, include=FALSE}

### Data Exploration

lamstream <- streamed %>%
  dplyr::select(LTER_Site, Area, Land_Cover, Group, Lambda) %>%
  na.omit # Create new dataset.

boxplot(Lambda ~ LTER_Site, data = lamstream) # Site boxplot. Random effect.
boxplot(Lambda ~ Group, data = lamstream) # Date boxplot. Fixed effect.
boxplot(Lambda ~ Area, data = lamstream) # Watershed area boxplot. Fixed effect?
boxplot(Lambda ~ Land_Cover, data = lamstream) # Land cover boxplot. Fixed effect?

pairs(lamstream) # Pairs plot. So, I'm going to investigate all three as fixed effects at first, but Site should go in as a random effect too.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - Lambda
# Explanatory variables - Group, Land_Cover, Watershed Area

h1 <- lm(Lambda ~ Group + Land_Cover + Area, data = lamstream) # Initial linear model.
rh1 <- rstandard(h1) # Assigns standardized residuals to rh1.

plot(rh1 ~ lamstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Site WILL be used as a random effect.

#### STEP 2: Fit the lm() with GLS and compare to lme().

h2 <- gls(Lambda ~ Group + Land_Cover + Area, data = lamstream)

h3 <- lme(Lambda ~ Group + Land_Cover + Area, 
          random =~1 | LTER_Site, data = lamstream) # Creates the first LMEM.

anova(h2, h3) # Compares the two models. h2 preferred with an AIC value of 60.67366.

#### STEP 3: Decide on a variance structure (aka random terms).
# I'm deciding to keep a random term in to acknowledge the repeated measurement structure of the project design.

plot(h3, col=1) # Check the residuals.
qqnorm(h3) # This actually looks ok...

# Going to skip the extra variance structure.

# STEP 4: Fit the lme().

# Using h3 <- lme(Lambda ~ Group + Land_Cover + Area, random =~1 | LTER_Site, data = lamstream)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3. 

# STEP 7/8: Step-wise Optimal Fixed Structure

h3_ml <- lme(Lambda ~ Group + Land_Cover + Area, 
             random =~1 | LTER_Site, method = "ML", data = lamstream) # Need to switch over to ML for the fixed component editing portion.
h3sub1 <- update(h3_ml, .~. -Group) # Removes Group.
h3sub2 <- update(h3_ml, .~. -Land_Cover) # Removes Land_Cover.
h3sub3 <- update(h3_ml, .~. -Area) # Removes Area.

anova(h3_ml, h3sub1, h3sub2, h3sub3) # Compare the models. sub2 preferred with an AIC value of 49.25669, so remove Land Cover.

h4 <- lme(Lambda ~ Group + Area, 
          random =~1 | LTER_Site, method = "ML", data = lamstream)
h4sub1 <- update(h4, .~. -Group) # Removes Group.
h4sub2 <- update(h4, .~. -Area) # Removes Area.

anova(h4, h4sub1, h4sub2) # Compares the models. h4 preferred with an AIC value of 49.25669, so keep both terms in.

h4full <- lme(Lambda ~ Group + Area, 
              random =~1 | LTER_Site, method = "ML", data = lamstream)

# STEP 9: Refit with REML

hfinal <- lme(Lambda ~ Group + Area, 
              random =~1 | LTER_Site, method = "REML", data = lamstream)

# Output of the model.
summary(hfinal)

# Checking residuals.
plot(hfinal, col=1) # No pattern.
qqnorm(hfinal) # This looks good.

# Show intervals.
intervals(hfinal)
anova(hfinal)

# STEP 10: What does this mean in WORDS?

# My model suggests there is a significant effect of sampling date but not watershed size on Lambda concentrations of a given stream sediment sample.

# Equation: Lambda = 1.72 + 0.44[GroupC] + 1.87[GroupI] - 0.02[Area] + random

# BONUS POST HOC:

hHSD <- glht(hfinal, linfct=mcp(Group="Tukey"))
summary(hHSD) # Significant different between Jan 2016 and Jan 2017 (p < 0.0001) as well as March 2016 and Jan 2017 (p < 0.0001).

```

The final model took the form : Lambda ~ Group + Area + 1|LTER_Site

This translated to a formula of Lambda = 1.72 + 0.44[GroupC] + 1.87[GroupI] - 0.02[Area] + random

Post hoc results: Mar 16 (C) - Jan 16 (B), p = 0.253 (NS); Jan 17 (I) - Jan 16 (B), p < 0.0001; Jan 17 (I) - Mar 16 (C), p < 0.0001.

## S/V (stream)

```{r S/V stream, include=FALSE}

### Data Exploration

boxplot(S.V ~ LTER_Site, data = streamed) # Site boxplot. Random effect.
boxplot(S.V ~ Group, data = streamed) # Date boxplot. Fixed effect.
boxplot(S.V ~ Area, data = streamed) # Watershed area boxplot. Fixed effect.
boxplot(S.V ~ Land_Cover, data = streamed) # Land cover boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), Area and Land_Cover as fixed variables and Group (date sampled) and Site as random NESTED variables.

svstream <- streamed %>%
  dplyr::select(LTER_Site, Group, Area, Land_Cover, S.V) %>%
  na.omit # Create new dataset.

svstream$Land_Cover <- factor(svstream$Land_Cover, levels = c("UND", "AGR", "URB")) # Relevels the land cover categories.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(svstream$S.V, groups = svstream$LTER_Site) # S/V versus Site.
par(op) # Looking ok so no need to log-transform, and likely will not need an additional variance structure.

pairs(svstream) # Pairs plot. Yep, variable choices still look good.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - S/V
# Explanatory variables - Group, Area, Land_Cover

i1 <- lm(S.V ~ Group + Area + Land_Cover, data = svstream) # Initial linear model.
ri1 <- rstandard(i1) # Assigns standardized residuals to ri1.
plot(ri1 ~ svstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Some within site correlation, so keep in random structure.

plot(ri1 ~ svstream$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not quite as extreme , so taking it out of random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

i2 <- gls(S.V ~ Group + Area + Land_Cover, data = svstream) # Linear regression.
i3 <- lme(S.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = svstream) # First LMEM with random term.

anova(i2, i3) # Compares the two models. i2 preferred with AIC value of 65.11196. But, I want to keep the random term in to account for repeated measures' sake.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(i3, col=1) # Plots residuals before immediately applying variance transformation. Looks like we may still need one.

i4 <- lme(S.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = svstream,
          weights = varIdent(form =~1 | Group)) # Adds variance structure by date.

anova(i3, i4) # Compares models. i4 is best with an AIC value of 54.03685.

# STEP 4: Fit the lme().

# Using i4 <- lme(S.V ~ Group + Area + Land_Cover, random =~1 | LTER_Site, data = svstream, weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(i2, i4) # 4 definitely outperforms 2 with an AIC value of 54.03685.

# STEP 6: Everything ok? Check residuals.

plot(i4, col=1) # Residuals look pretty good.
qqnorm(i4) # Looks a little weird, but it's a small dataset.

# STEP 7/8: Step-wise Optimal Fixed Structure

i4_ml <- lme(S.V ~ Group + Area + Land_Cover, 
             random =~1 | LTER_Site, method = "ML", data = svstream, 
             weights = varIdent(form =~1 | Group)) # Creates ML structure model.
# Using the shorter syntax to save space since I've got so many variables.
i4sub1 <- update(i4_ml, .~. -Group) # Removes date sampled.
i4sub2 <- update(i4_ml, .~. -Area) # Removes watershed area.
i4sub3 <- update(i4_ml, .~. -Land_Cover) # Removes land use type.

anova(i4_ml, i4sub1, i4sub2, i4sub3) # Compares all models. i4sub3 preferred with an AIC value of 29.90527, so remove land cover.

i5 <- lme(S.V ~ Group + Area, 
          random =~1 | LTER_Site, method = "ML", data = svstream, 
          weights = varIdent(form =~1 | Group))

i5sub1 <- update(i5, .~. -Group) # Removes date sampled.
i5sub2 <- update(i5, .~. -Area) # Removes watershed area.

anova(i5, i5sub1, i5sub2) # Compares all models. i5 preferred with AIC value of 29.90527.

# i5 is the final full model!!!

# STEP 9: Refit with REML

ifinal <- lme(S.V ~ Group + Area, 
              random =~1 | LTER_Site, method = "REML", data = svstream, 
              weights = varIdent(form =~1 | Group)) # Yay!!

# Output of the model.
summary(ifinal)
plot(ifinal, col=1) # Checking residuals. Looking good!
qqnorm(ifinal) # Looks better than before - blippy at the start, but OK I think.
qqnorm(ifinal, ~ranef (.), col = 1) # Plot of random effect residuals looks good!
intervals(ifinal) # Show intervals.

# Final results.
anova(ifinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled and watershed area on stream S/V signatures. Random intercepts by site were included as well as a variance term for date.

# Equation: S/V = 1.49 + 1.41[GroupC] + 0.57[GroupI] + 0.013[Area] + random + variance

# BONUS : Tukey's HSD Post Hoc
iHSD <- glht(ifinal, linfct=mcp(Group="Tukey"))
summary(iHSD) # Significant different between B&C (p = 0.00143), B&I (p < 0.001), but not between C&I (p = 0.07674).

```

The final model took the form : S.V ~ Group + Area + 1|LTER_Site + 1|Group(var)

This translated to a formula of S/V = 1.49 + 1.41[GroupC] + 0.57[GroupI] + 0.013[Area] + random + variance.

Post hoc results: Jan16 & Mar16, p = 0.00143 ; Jan16 & Jan17, p < 0.001; Mar16 & Jan 17, p = 0.07674 (NS).

## C/V (stream)

```{r C/V stream, include=FALSE}

### Data Exploration.

boxplot(C.V ~ LTER_Site, data = streamed) # Site boxplot. Random effect.
boxplot(C.V ~ Group, data = streamed) # Date boxplot. Fixed effect.
boxplot(C.V ~ Area, data = streamed) # Watershed area boxplot. Fixed effect?
boxplot(C.V ~ Land_Cover, data = streamed) # Land cover boxplot. Fixed effect?

# So, based on boxplots, I move forward with Group (date sampled), Area and Land_Cover as fixed variables and Group and Site as random NESTED variables.

cvstream <- streamed %>%
  dplyr::select(LTER_Site, Group, Area, Land_Cover, C.V) %>%
  na.omit# Create new dataset.

cvstream$Land_Cover <- factor(cvstream$Land_Cover, levels = c("UND", "AGR", "URB")) # Relevels the land cover categories.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(cvstream$C.V, groups = cvstream$LTER_Site) # C/V versus Site.
par(op) # Looking very evenly dispersed.

pairs(cvstream) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - C/V
# Explanatory variables - Group, Area, Land_Cover

j1 <- lm(C.V ~ Group + Area + Land_Cover, data = cvstream) # Initial linear model.
rj1 <- rstandard(j1) # Assigns standardized residuals to rji.
plot(rj1 ~ cvstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Some within site correlation, so part of random structure.

plot(rj1 ~ cvstream$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not quite as extreme , so removing from my random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

j2 <- gls(C.V ~ Group + Area + Land_Cover, data = cvstream) # Linear regression.
j3 <- lme(C.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = cvstream) # First LMEM with random term.
anova(j2, j3) # Compares the two models. j2 preferred with AIC value of -1.6875. But, I want to keep the random term in to account for repeated measures' sake.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(j3, col=1) # Plots residuals before immediately applying variance transformation. I don't believe there is a variance term necessary.

# STEP 4: Fit the lme().

# Using j3 <- lme(C.V ~ Group + Area + Land_Cover, random =~1 | LTER_Site, data = cvstream)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(j3, col=1) # Residuals look pretty good save that one kind of outlier that I believe is inevitable given the small size of the dataset.
qqnorm(j3) # Looks a little weird, but likely due to same reasoning as above.

# STEP 7/8: Step-wise Optimal Fixed Structure

j3_ml <- lme(C.V ~ Group + Area + Land_Cover, 
             random =~1 | LTER_Site, method = "ML", data = cvstream) # ML model structure.

j3sub1 <- update(j3_ml, .~. -Group) # Removes date sampled.
j3sub2 <- update(j3_ml, .~. -Area) # Removes watershed area.
j3sub3 <- update(j3_ml, .~. -Land_Cover) # Removes land cover.
anova(j3_ml, j3sub1, j3sub2, j3sub3) # Compares all models. j3sub3 preferred with an AIC value of -34.85286, so remove land cover.

j4 <- lme(C.V ~ Group + Area, 
          random =~1 | LTER_Site, method = "ML", data = cvstream)

j4sub1 <- update(j4, .~. -Group) # Removes date sampled.
j4sub2 <- update(j4, .~. -Area) # Removes watershed area.
anova(j4, j4sub1, j4sub2) # Compares all models. j4sub2 preferred with an AIC value of -35.59545, so remove area.

j5 <- lme(C.V ~ Group, 
          random =~1 | LTER_Site, method = "ML", data = cvstream)

j5sub1 <- update(j5, .~. -Group) # Removes date sampled.

anova(j5, j5sub1) # Compares all models. j5 preferred with an AIC value of -35.59545.
# j5 is the final full model!!!

# STEP 9: Refit with REML

jfinal <- lme(C.V ~ Group, 
              random =~1 | LTER_Site, method = "REML", data = cvstream)

# Output of the model.
summary(jfinal)
plot(jfinal, col=1) # Checking residuals. Looking ok other than that one outlier!
qqnorm(jfinal) # Looks OK.
qqnorm(jfinal, ~ranef (.), col = 1) # Plot of random effect residuals looks good!
intervals(jfinal) # Show intervals.

# Final results.
anova(jfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled on stream C/V signatures. Random intercepts by site were included.

# Equation: C/V = 0.12 - 0.10[GroupC] + 0.08[GroupI] + random

# BONUS : Tukey's HSD Post Hoc
jHSD <- glht(jfinal, linfct=mcp(Group="Tukey"))
summary(jHSD) # Significant different between B&I (p = 0.0003), C&I (p = 0.0002), but not between B&C (p = 0.9978).

```

The final model took the form : C.V ~ Group + 1|LTER_Site

This translated to a formula of C/V = 0.12 - 0.10[GroupC] + 0.08[GroupI] + random.

Post hoc results: Jan16 & Mar16, p = 0.9978 (NS) ; Jan16 & Jan17, p = 0.0003; Mar16 & Jan 17, p = 0.0002.

## P/V+S (stream)

```{r P/V+S stream, include=FALSE}

### Data Exploration.

boxplot(P..V.S. ~ LTER_Site, data = streamed) # Site boxplot. Random effect.
boxplot(P..V.S. ~ Group, data = streamed) # Date boxplot. Fixed effect.
boxplot(P..V.S. ~ Area, data = streamed) # Area boxplot. Fixed effect?
boxplot(P..V.S. ~ Land_Cover, data = streamed) # Land cover boxplot. Fixed effect?

# So, based on boxplots, I move forward with Group (date sampled), Area and Land_Cover as fixed variables and Group and Site as random NESTED variables.

pvsstream <- streamed %>%
  dplyr::select(LTER_Site, Group, Area, Land_Cover, P..V.S.) %>%
  na.omit# Create new dataset.

pvsstream$Land_Cover <- factor(pvsstream$Land_Cover, levels = c("UND", "AGR", "URB")) # Relevels the land cover categories.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(pvsstream$P..V.S., groups = pvsstream$LTER_Site) # P/V+S versus Site.
par(op) # Looking good.

pairs(pvsstream) # Quick pairs plot to check correllated variables. Yep, variable choices still look good, and it looks like date is again going to drive the relationship here.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - P/V+S
# Explanatory variables - Group, Area, Land Cover

k1 <- lm(P..V.S. ~ Group + Area + Land_Cover, data = pvsstream) # Linear model.
rk1 <- rstandard(k1) # Assigns standardized residuals to rk1.

plot(rk1 ~ pvsstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # It will definitely be part of a random structure.

plot(rk1 ~ pvsstream$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Removing from random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

k2 <- gls(P..V.S. ~ Group + Area + Land_Cover, data = pvsstream) # Linear regression.
k3 <- lme(P..V.S. ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = pvsstream ) # First LMEM with random term.

anova(k2, k3) # Compares the two models. k2 preferred with an AIC value of -25.61488, but I'm keeping the random term in for repeated measures sake.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(k3, col=1) # Plots residuals before immediately applying variance transformation. I don't think we need an additional variance structure.

# STEP 4: Fit the lme().

# k3 <- lme(P..V.S. ~ Group + Area + Land_Cover, random =~1 | LTER_Site, data = pvsstream)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(k3, col=1) # Residuals look really quite good.
qqnorm(k3) # Looks fine.

# STEP 7/8: Step-wise Optimal Fixed Structure

k3_ml <- lme(P..V.S. ~ Group + Area + Land_Cover, 
             random =~1 | LTER_Site, method = "ML", data = pvsstream) # ML model structure.

k3sub1 <- update(k3_ml, .~. -Group) # Removes date.
k3sub2 <- update(k3_ml, .~. -Area) # Removes watershed area.
k3sub3 <- update(k3_ml, .~. -Land_Cover) # Removes land use.

anova(k3_ml, k3sub1, k3sub2, k3sub3) # Compares all models. k3sub2 is preferred with an AIC value of -68.42672. So, remove area.

k4 <- lme(P..V.S. ~ Group + Land_Cover, 
          random =~1 | LTER_Site, method = "ML", data = pvsstream)

k4sub1 <- update(k4, .~. -Group) # Removes date.
k4sub2 <- update(k4, .~. -Land_Cover) # Removes land use.

anova(k4, k4sub1, k4sub2) # k4sub2 preferred with AIC value of -69.13217; remove land use.

k5 <- lme(P..V.S. ~ Group, 
          random =~1 | LTER_Site, method = "ML", data = pvsstream)

k5sub1 <- update(k5, .~. -Group) # Just checking...

anova(k5, k5sub1) # k5 preferred with an AIC value of -69.13217, so keep Group in.

# STEP 9: Refit with REML

kfinal <- lme(P..V.S. ~ Group, 
              random =~1 | LTER_Site, method = "REML", data = pvsstream)

# Output of the model.
summary(kfinal)
plot(kfinal, col=1) # Checking residuals.They're fine.
qqnorm(kfinal) # Look pretty good considering low # of samples.
qqnorm(kfinal, ~ranef (.), col = 1) # Plot of random effect residuals, looks good.
intervals(kfinal) # Show intervals.

# Final results.
anova(kfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of region, watershed area, or land use on P/V+S signatures of a given sediment sample, but DATE has a significant effect. Random intercept by sample site was also included.

# Equation: P/V+S = 0.30 - 0.08[C] - 0.22[I] + random

# BONUS : Tukey's HSD Post Hoc
kHSD <- glht(kfinal, linfct=mcp(Group="Tukey"))
summary(kHSD) # All significantly different.

```

The final model took the form : P..V.S. ~ Group + 1|LTER_Site

This translated to a formula of P/V+S = 0.30 - 0.08[C] - 0.22[I] + random.

Post hoc results: Jan16 (B) & Mar16 (C), p = 0.0004 ; Jan16 (B) & Jan17 (I), p < 0.0001; Mar16 (C) & Jan 17 (I), p < 0.0001.

# 3,5Bd/V (stream)

```{r 35Bd/V stream, include=FALSE}

### Data Exploration 

boxplot(Bd.V ~ LTER_Site, data = streamed) # Site boxplot. Random effect.
boxplot(Bd.V ~ Group, data = streamed) # Date boxplot. Fixed effect.
boxplot(Bd.V ~ Area, data = streamed) # Watershed area. Fixed effect? These really look random, but I'm choosing to keep them in for reasoning purposes - it doesn't really make sense for them to be part of the random effect structure AND it was found to be significant in Lambda stream values so...
boxplot(Bd.V ~ Land_Cover, data = streamed) # Land cover boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), Area and Land_Cover as fixed variables and Group and Site as random NESTED variables.

bdvstream <- streamed %>%
  dplyr::select(LTER_Site, Group, Area, Land_Cover, Bd.V) %>%
  na.omit# Create new dataset.

bdvstream$Land_Cover <- factor(bdvstream$Land_Cover, levels = c("UND", "AGR", "URB")) # Relevels the land cover categories.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(bdvstream$Bd.V, groups = bdvstream$LTER_Site) # P/V+S versus Site.
par(op) # Looking ok. There's definitely an outlier, but I'm not taking any more out.

pairs(bdvstream) # Pairs plot. Variable choices look good, and land cover may play a role!

#### STEP 1: Create a linear regression and check residuals.

# Response variables - 3,5-Bd/V
# Explanatory variables - Group, Area, Land Cover

l1 <- lm(Bd.V ~ Group + Area + Land_Cover, data = bdvstream) # Initial linear model.
rl1 <- rstandard(l1) # Assigns standardized residuals to rl1.

plot(rl1 ~ bdvstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Within site correlation, so it will definitely be part of a random structure.

plot(rl1 ~ bdvstream$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Taking it out of my random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

l2 <- gls(Bd.V ~ Group + Area + Land_Cover, data = bdvstream) # Linear regression.
l3 <- lme(Bd.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site / Group, data = bdvstream ) # First LMEM with random term.

anova(l2, l3) # Compares the two models. l2 preferred with an AIC value of -18.67473, but I'm keeping the random term in for repeated measures sake.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(l3, col=1) # Plots residuals before immediately applying variance transformation. We definitely need a transformation, so I'll make it by date.

l4 <- lme(Bd.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = bdvstream,
          weights = varIdent(form =~1 | Group))

anova(l3, l4) # Compares models. l4 is best with an AIC value of -15.35811.

# STEP 4: Fit the lme().

# Using l4 <- lme(Bd.V ~ Group + Area + Land_Cover, random =~1 | LTER_Site, data = bdvstream, weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(l2,l4) # l2 still preferred, but I'm keeping the random term in.

# STEP 6: Everything ok? Check residuals.

plot(l4, col=1) # Residuals look pretty good.
qqnorm(l4) # Looks GOOD.

# STEP 7/8: Step-wise Optimal Fixed Structure

l4_ml <- lme(Bd.V ~ Group + Area + Land_Cover, 
             random =~1 | LTER_Site, method = "ML", data = bdvstream,
             weights = varIdent(form =~1 | Group))  # ML model structure.

l4sub1 <- update(l4_ml, .~. -Group) # Removes date.
l4sub2 <- update(l4_ml, .~. -Area) # Removes watershed area.
l4sub3 <- update(l4_ml, .~. -Land_Cover) # Removes land use.

anova(l4_ml, l4sub1, l4sub2, l4sub3) # Compares all models. l4sub1 is preferred with an AIC value of -59.31871. So, remove sampling date.

l5 <- lme(Bd.V ~ Area + Land_Cover, 
          random =~1 | LTER_Site, method = "ML", data = bdvstream,
          weights = varIdent(form =~1 | Group))

l5sub1 <- update(l5, .~. -Area) # Removes watershed area.
l5sub2 <- update(l5, .~. -Land_Cover) # Removes land cover.

anova(l5, l5sub1, l5sub2) # l5sub1 preferred with an AIC value of -61.01911 - remove area.

l6 <- lme(Bd.V ~ Land_Cover, 
          random =~1 | LTER_Site, method = "ML", data = bdvstream,
          weights = varIdent(form =~1 | Group))

l6sub1 <- update(l6, .~. -Land_Cover) # Removes land cover.

anova(l6, l6sub1) # l6 preferred with AIC value of -61.01911. Keep it in.

# STEP 9: Refit with REML

lfinal <- lme(Bd.V ~ Land_Cover, 
              random =~1 | LTER_Site, method = "REML", data = bdvstream,
              weights = varIdent(form =~1 | Group))

# Output of the model.
summary(lfinal)
plot(lfinal, col=1) # Checking residuals.
qqnorm(lfinal) # Looks better than before.
qqnorm(lfinal, ~ranef (.), col = 1) # Plot of random effect residuals, looks ok.
#intervals(lfinal) # Show intervals.

# Final results.
anova(lfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of date sampled, watershed area, or land use on 3,5Bd/V signatures of a given sediment sample. A random intercept term by sample site and a variance term by sampling date were also included.

# Equation: 3,5Bd/V = 0.23 - 0.05[AGR] - 0.07[URB] + random + variance

```

The final model took the form : Bd.V ~ Land_Cover + 1|LTER_Site + varIdent(Group)

This translated to a formula of 3,5Bd/V = 0.23 - 0.05[AGR] - 0.07[URB] + random + variance.

Post hoc results: NA.

# Estuarine data

```{r estuarine data, include=FALSE}

# For the following code chunks, I'll use this same dataset since I've not added in any additional info like I did with the stream data.

estuary <- mained %>%
  filter(mained$Environment=="Estuary")

# Ok, but in the following code, unless I create a separate dataset, all of the stream/marine site levels, for example, will still be in there, which I don't want for modeling purposes. So I'm going to do the following:

#write.csv(estuary,"estuary.csv") # Export the data.
estuarine <- read_csv("estuary.csv") %>% # Load the data back in.
  mutate(Diameter_50 = Diameter_50.00.) # Create more nicely named column.
#str(estuarine) # Check to make sure its in the format I want. Perfect!

```

## Sigma 8 (estuarine)

```{r Sigma estuary, include=FALSE}

### Data Exploration
# Not testing region since I've decided it's arbitrary.
# Largest change from previous analysis, choosing to remove Site as a fixed variable (since it likely is not responsible for large changes in Sigma8 values), but rather keeping it in as only a random variable, along with replicate cores and core section, to account for nested, repeated measures.
boxplot(Sigma8 ~ LTER_Site, data = estuarine) # Site boxplot. 
boxplot(Sigma8 ~ Group, data = estuarine) # Date boxplot. 
boxplot(Sigma8 ~ Core, data = estuarine) # Core section boxplot. 
boxplot(Sigma8 ~ Diameter_50, data = estuarine) # Grain size boxplot.

# So, based on boxplots, and lots of reading from these sites:
# https://www.esf.edu/quest/documents/workshop-expdesign-shortversion.pdf
# https://www.vsni.co.uk/case-studies/pseudo-replication
# https://ourcodingclub.github.io/tutorials/mixed-models/#types
# ...I move forward with Group (sampling date), Core, and Diameter as fixed variables and Site/Replicate/Core as a nested random variable.

# Remember: Random variables are nested larger to smaller.

sigest <- estuarine %>%
  dplyr::select(LTER_Site, Replicate, Core, Group, Diameter_50, Sigma8) %>%
  #mutate(logSig8 = log10(Sigma8)) %>% # Creating log transformed column
  na.omit# Create new dataset.

ggpairs(sigest) # Pairs plot. 

#### STEP 1: Create a linear regression and check residuals.

# Response variables - Sigma8
# Explanatory variables - Group, Core, Diameter

m1 <- lm(Sigma8 ~ Group + Core + Diameter_50, data = sigest) # Initial linear model.
rm1 <- rstandard(m1) # Assigns standardized residuals to rm1.
sigest <- sigest %>%
  mutate(rm1 = rm1) # Adds residuals to dataframe for plotting.

ggplot(data = sigest, aes(x = LTER_Site, y = rm1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = sigest, aes(x = Replicate, y = rm1)) + 
  #geom_boxplot() + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals") # Plots said residuals.

ggplot(data = sigest, aes(x = Group, y = rm1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals") # Group looks all about zero.

ggplot(data = sigest, aes(x = Core, y = rm1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Core Section", y = "Standardised residuals") # Section looks all about zero too.

ggplot(data = sigest, aes(x = Diameter_50, y = rm1)) + 
  #geom_boxplot() + 
  geom_point() +
  labs(x = "Median Diameter", y = "Standardised residuals") # Diameter also feels relatively well spread about zero.

#### STEP 2: Fit the lm() with GLS and compare to lme().

m2 <- gls(Sigma8 ~ Group + Core + Diameter_50, data = sigest)

m3 <- lme(Sigma8 ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, data = sigest) # First LMEM.

anova(m2, m3) # Compares the two models. m3 is preferred with an AIC value of 227.3028.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(m3, col=1) # Check the residuals.
qqnorm(m3) # Ok...skipping a variance term.

# STEP 4: Fit the lme().

# See Step 2.

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

m3_ml <- lme(Sigma8 ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, method = "ML", data = sigest) # ML model.

m3sub1 <- update(m3_ml, .~. -Group) # Removes Group.
m3sub2 <- update(m3_ml, .~. -Core) # Removes Core Section.
m3sub3 <- update(m3_ml, .~. -Diameter_50) # Removes Median Diameter.

anova(m3_ml, m3sub1, m3sub2, m3sub3) # Compare the models. m3sub2 preferred with an AIC value of 219.7146, so remove Core.

m4 <- lme(Sigma8 ~ Group + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, method = "ML", data = sigest)

m4sub1 <- update(m4, .~. -Group) # Removes Group.
m4sub2 <- update(m4, .~. -Diameter_50) # Removes Median Diameter.

anova(m4, m4sub1, m4sub2) # Compares the models. m4sub1 preferred with an AIC value of 219.2553, so remove Group.

m5 <- lme(Sigma8 ~ Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, method = "ML", data = sigest)

m5sub1 <- update(m5, .~. -Diameter_50) # Removes Median Diameter.

anova(m5, m5sub1) # Compares the models. m5 preferred with an AIC value of 219.2553, so stop here.

# m5 is the final full model!

# STEP 9: Refit with REML

mfinal <- lme(Sigma8 ~ Diameter_50, 
              random =~1 | LTER_Site/Replicate/Core, method = "REML", data = sigest)

# Output of the model.
summary(mfinal)
plot(mfinal, col=1) # Checking residuals.They're fine. Chose to log-transform.
qqnorm(mfinal) # A little curvy but otherwise ok.

# Final results.
anova(mfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# My model suggests there is a significant effect of median grain size on Sigma 8 concentrations of a given estuarine sediment sample.

# Equation: Sigma 8 = 4.65 - 0.01[Median Diameter] + random

# BONUS POST HOC:

# NOT NECESSARY

```

The final model took the form : Sigma8 ~ Median Diameter + 1|LTER_Site/Replicate/Core

This translated to a formula of Sigma 8 = 4.65 - 0.01[Median Diameter] + random.

Post hoc results: NA.

##Lambda (estuarine)

```{r Lambda estuary, include=FALSE}

### Data Exploration

boxplot(Lambda ~ LTER_Site, data = estuarine) # Site boxplot.
boxplot(Lambda ~ Group, data = estuarine) # Date boxplot.
boxplot(Lambda ~ Core, data = estuarine) # Core section boxplot.
boxplot(Lambda ~ Diameter_50, data = estuarine) # Grain size boxplot.

lamest <- estuarine %>%
  dplyr::select(LTER_Site, Replicate, Core, Group, Diameter_50, Lambda) %>%
  na.omit # Creates new dataset.

ggpairs(lamest) # Pairs plot.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - Lambda
# Explanatory variables - Group, Core, Diameter

n1 <- lm(Lambda ~ Group + Core + Diameter_50, data = lamest) # Initial linear model.
rn1 <- rstandard(n1) # Assigns standardized residuals to rn1.

lamest <- lamest %>%
  mutate(rn1 = rn1) # Adds residuals to dataframe for plotting.

ggplot(data = lamest, aes(x = LTER_Site, y = rn1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = lamest, aes(x = Replicate, y = rn1)) + 
  #geom_boxplot() + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals") # Plots said residuals.

ggplot(data = lamest, aes(x = Group, y = rn1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals") # Groups look all about zero.

ggplot(data = lamest, aes(x = Core, y = rn1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Core Section", y = "Standardised residuals") # Section looks all about zero too.

ggplot(data = lamest, aes(x = Diameter_50, y = rn1)) + 
  #geom_boxplot() + 
  geom_point() +
  labs(x = "Median Diameter", y = "Standardised residuals") # Diameter looks all about zero too.

#### STEP 2: Fit the lm() with GLS and compare to lme().

n2 <- gls(Lambda ~ Group + Core + Diameter_50, data = lamest)
n3 <- lme(Lambda ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, data = lamest) # First LMEM with a random term.

anova(n2, n3) # Compares the two models. n2 is preferred with an AIC value of 182.5031, but I must keep the random term in.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(n3, col=1) # Check the residuals. AWESOME.
qqnorm(n3) # Pretty good. Going to skip the variance term.

# STEP 4: Fit the lme().

# See Step 2.

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

n3_ml <- lme(Lambda ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, method = "ML", data = lamest) # ML model format.

n3sub1 <- update(n3_ml, .~. -Group) # Removes Group.
n3sub2 <- update(n3_ml, .~. -Core) # Removes Core Section.
n3sub3 <- update(n3_ml, .~. -Diameter_50) # Removes Diameter.

anova(n3_ml, n3sub1, n3sub2, n3sub3) # Compare the models. n3sub1 preferred with an AIC value of 171.2744, so remove Group.

n4 <- lme(Lambda ~ Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, method = "ML", data = lamest)

n4sub1 <- update(n4, .~. -Core) # Removes Core Section.
n4sub2 <- update(n4, .~. -Diameter_50) # Removes Diameter.

anova(n4, n4sub1, n4sub2) # Compares the models. n4 preferred with an AIC value of 171.2744, so stop here.

# n4 is the final full model!

# STEP 9: Refit with REML

nfinal <- lme(Lambda ~ Core + Diameter_50, 
              random =~1 | LTER_Site/Replicate/Core, method = "REML", data = lamest)

# Output of the model.
summary(nfinal)
plot(nfinal, col=1) # Checking residuals.They're fine.
qqnorm(nfinal) # A little curvy but otherwise ok.

# Final results.
anova(nfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is no significant effect of median grain size or core section on Lambda signatures of a given sediment sample.

# Equation: Lambda = 2.34 + 0.47[CoreT] - 0.003[Median Diameter] + random

# BONUS : Tukey's HSD Post Hoc

# NOT NECESSARY

```

The final model took the form : Lambda ~ Core + Diameter + 1|LTER_Site/Replicate/Core

This translated to a formula of Lambda = 2.34 + 0.47[CoreT] - 0.003[Median Diameter] + random.

Post hoc results: NA.

## S/V (estuarine)

```{r S/V estuary, include=FALSE}
### Data Exploration - boxplots and pairplots

boxplot(S.V ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(S.V ~ Group, data = estuarine) # Date boxplot. Fixed effect?
boxplot(S.V ~ Core, data = estuarine) # Core boxplot. Fixed effect?

svest <- estuarine %>%
  dplyr::select(LTER_Site, Replicate, Core, Diameter_50, Group, S.V) %>%
  na.omit # Creates new dataset.

# So, based on boxplots, I move forward with Site, Group, and Core as fixed effects and Site as a random variable.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(svest$S.V, groups = svest$LTER_Site) # S/V versus Site.
par(op) # A few outliers, but not taking out any more data.

ggpairs(svest) # Pairs plot. Hard to discern patterns here honestly.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - S/V
# Explanatory variables - Group, Site, Core

o1 <- lm(S.V ~ Group + Core + Diameter_50, data = svest) # Initial linear model.
ro1 <- rstandard(o1) # Assigns standardized residuals.
svest <- svest %>%
  mutate(ro1 = ro1) # Add residuals to dataframe for plotting.

ggplot(data = svest, aes(x = LTER_Site, y = ro1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = svest, aes(x = Group, y = ro1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals") # Plots said residuals.

ggplot(data = svest, aes(x = Core, y = ro1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Top/Bottom", y = "Standardised residuals") # Plots said residuals.

ggplot(data = svest, aes(x = Replicate, y = ro1)) + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

o2 <- gls(S.V ~ Group + Core + Diameter_50, data = svest) # Linear regression.
o3 <- lme(S.V ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, data = svest) # First LMEM with random term.

anova(o2, o3) # Compares the two models. o3 preferred with AIC value of 167.4215.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(o3, col=1) # Plots residuals before immediately applying variance transformation.

o4 <- lme(S.V ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, data = svest,
          weights = varIdent(form =~1 | Group)) # Adding in a variance structure to allow for different variance by date - based on boxplots.

anova(o3, o4) # Compares model with random effect and model with both random and variance effects. o4 preferred with an AIC value of 151.5614 so keep alternate variance structure in there.

# STEP 4: Fit the lme().

# Using o4 <- lme(S.V ~ Group + Core + Diameter_50, 
#          random =~1 | LTER_Site/Replicate/Core, data = svest,
#          weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(o2, o4) # 4 definitely outperforms 2 with an AIC value of 151.5614.

# STEP 6: Everything ok? Check residuals.

plot(o4, col=1) # Residuals look better than they did.
qqnorm(o4) # Looks a little weird...but not terrible.

# STEP 7/8: Step-wise Optimal Fixed Structure

o4_ml <- lme(S.V ~ Group + Core + Diameter_50,
             random =~1 | LTER_Site/Replicate/Core, method = "ML", data = svest,
             weights = varIdent(form =~1 | Group)) # Creates current model using ML structure.

# Using the shorter syntax to save space.
o4sub1 <- update(o4_ml, .~. -Group) # Removes date sampled.
o4sub2 <- update(o4_ml, .~. -Core) # Removes core section.
o4sub3 <- update(o4_ml, .~. -Diameter_50) # Removes grain size.
anova(o4_ml, o4sub1, o4sub2, o4sub3) # Compares all models. o4sub1 preferred with an AIC value of 131.9398. Remove Date sampled.

o5 <- lme(S.V ~ Core + Diameter_50,
             random =~1 | LTER_Site/Replicate/Core, method = "ML", data = svest,
             weights = varIdent(form =~1 | Group))
o5sub1 <- update(o5, .~. -Core) # Removes core section.
o5sub2 <- update(o5, .~. -Diameter_50) # Removes grain size.
anova(o5, o5sub1, o5sub2) # Compares all models. o5sub1 preferred with an AIC value of 129.9795, so remove Core.

o6 <- lme(S.V ~ Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, method = "ML", data = svest,
          weights = varIdent(form =~1 | Group))
o6sub1 <- update(o6, .~. -Diameter_50) # Removes grain size.
anova(o6, o6sub1) # Compares all models. o6 model preferred.

# o6 is the final model!

# STEP 9: Refit with REML

ofinal <- lme(S.V ~ Diameter_50, 
              random =~1 | LTER_Site/Replicate/Core, method = "REML", data = svest, weights = varIdent(form =~1 | Group))

# Output of the model.
summary(ofinal)
plot(ofinal, col=1) # Checking residuals.They're fine.
qqnorm(ofinal) # A little curvy but otherwise ok.

# Final results.
anova(ofinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of median grain size and there is NO significant effect of date sampled, core section, or sampling site on estuarine S/V signatures. Random intercepts by site were included as well as a variance term for sampling date.

# Equation: S/V = 1.88 + 0.005[Median Diameter] + random + var

# BONUS : Tukey's HSD Post Hoc

# NA

```

The final model took the form : S.V ~ Diameter + 1|LTER_Site/Replicate/Core + var(Group)

This translated to a formula of S/V = 1.88 + 0.005[Median Diameter] + random + var.

Post hoc results: NA.

##C/V (estuarine)

```{r C/V estuary, include=FALSE}
### Data Exploration - boxplots and pairplots

boxplot(C.V ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(C.V ~ Group, data = estuarine) # Date boxplot. Fixed effect.
boxplot(C.V ~ Core, data = estuarine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), Diameter, and Core (section) as fixed and Site/Replicate/Core as a random variable.

cvest <- estuarine %>%
  dplyr::select(LTER_Site, Replicate, Core, Group, Diameter_50, C.V) %>%
  na.omit # Creates new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(cvest$C.V, groups = cvest$LTER_Site) # C/V versus Site.
par(op) # Looking ok.

ggpairs(cvest) # Pairs plot.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - C/V
# Explanatory variables - Group, Core, Diameter

p1 <- lm(C.V ~ Group + Core + Diameter_50, data = cvest) # Initial linear model.
rp1 <- rstandard(p1) # Assigns standardized residuals.
cvest <- cvest %>%
  mutate(rp1 = rp1) # Add residuals to dataframe for easier plotting.

ggplot(data = cvest, aes(x = LTER_Site, y = rp1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = cvest, aes(x = Group, y = rp1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals") # Going to need another variance structure here...

ggplot(data = cvest, aes(x = Core, y = rp1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Core", y = "Standardised residuals")

ggplot(data = cvest, aes(x = Replicate, y = rp1)) + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

p2 <- gls(C.V ~ Group + Core + Diameter_50, data = cvest) # Linear regression.
p3 <- lme(C.V ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, data = cvest) # First LMEM with random term.
anova(p2, p3) # Compares the two models. p2 preferred with an AIC value of 4.93375, but keeping random term in for replicate samplings sake.

# STEP 3: Decide on a variance structure.

plot(p3, col=1) # Plots residuals.

p4 <- lme(C.V ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, data = cvest,
          weights = varIdent(form =~1 | Group)) # Adding variance structure by date due to boxplots above.

anova(p3, p4) # Compares model with random effect and model with both random and variance effects. p4 preferred with an AIC value of -2.670802 so keep alternate variance structure in there.

# STEP 4: Fit the lme().

# Using p4 <- lme(C.V ~ Group + Core + Diameter_50, 
#          random =~1 | LTER_Site/Replicate/Core, data = cvest,
#          weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(p2, p4) # 4 definitely outperforms 2 with an AIC value of -2.670802.

# STEP 6: Everything ok? Check residuals.

plot(p4, col=1) # Residuals look better than they did.
qqnorm(p4) # Looks good.

# STEP 7/8: Step-wise Optimal Fixed Structure

p4_ml <- lme(C.V ~ Group + Core + Diameter_50,
             random =~1 | LTER_Site/Replicate/Core, 
             method = "ML", data = cvest,
             weights = varIdent(form =~1 | Group)) # ML model structure.
#p4sub1 <- update(p4_ml, .~. -Group) # Removes date sampled. Does not converge.
p4sub2 <- update(p4_ml, .~. -Core) # Removes core section.
p4sub3 <- update(p4_ml, .~. -Diameter_50) # Removes grain size.
anova(p4_ml, p4sub2, p4sub3) # Compares all models. p4sub2 preferred with and AIC value of -42.92230. Remove Core.

p5 <- lme(C.V ~ Group + Diameter_50,
             random =~1 | LTER_Site/Replicate/Core, 
             method = "ML", data = cvest,
             weights = varIdent(form =~1 | Group))
p5sub1 <- update(p5, .~. -Group) # Removes date sampled.
p5sub2 <- update(p5, .~. -Diameter_50) # Removes grain size.
anova(p5, p5sub1, p5sub2) # Compares all models. p5 preferred with an AIC value of -42.92230, so stop here.

# p5 is the final full model.

# STEP 9: Refit with REML

cvest <- cvest %>%
  mutate(Group = factor(Group))

pfinal <- lme(C.V ~ Group + Diameter_50, 
              random =~1 | LTER_Site/Replicate/Core, 
              method = "REML", data = cvest, 
              weights = varIdent(form =~1 | Group))

# Output of the model.
summary(pfinal)
plot(pfinal, col=1) # Checking residuals. Looking good!
qqnorm(pfinal) # Looks better than before - a little curvy, but OK.

anova(pfinal) # Output for the paper

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled on estuarine C/V signatures. Random intercepts by site were included as well as a variance term for sampling date.

# Equation: C/V = 0.21 + 0.12[GroupF] + 0.24[GroupH] + 0.26[GroupK] - 0.0003[Diameter] + random + variance

# BONUS : Tukey's HSD Post Hoc
pHSD <- glht(pfinal, linfct=mcp(Group="Tukey"))
summary(pHSD) # Results of post hoc: F - D, p < 0.001; H - D, p < 0.001; K - D, p = 0.00247; H - F, K - F, and K - H were p > 0.05.

```

The final model took the form : C.V ~ Group + Median Diameter + 1|LTER_Site/Replicate/Core + 1|Group(var)

This translated to a formula of C/V = 0.21 + 0.12[GroupF] + 0.24[GroupH] + 0.26[GroupK] - 0.0003[Diameter] + random + variance.

Post hoc results: April 2016 and July 2016, p < 0.001; April 2016 and April 2017, p < 0.001; April 2016 and June 2017, p = 0.00247.

## P/V+S (estuarine)

```{r P/V+S estuary, include=FALSE}

### Data Exploration - boxplots and pairplots
boxplot(P..V.S. ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(P..V.S. ~ Group, data = estuarine) # Date boxplot. Fixed effect.
boxplot(P..V.S. ~ Core, data = estuarine) # Core section boxplot. Fixed effect?

# So, based on boxplots, I move forward with Group (date sampled), Core (section) and Median Diameter as fixed variables and Site/Replicate/Core as a random variable.

pvsest <- estuarine %>%
  dplyr::select(LTER_Site, Replicate, Core, Group, Diameter_50, P..V.S.) %>% 
  na.omit # Create new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(pvsest$P..V.S., groups = pvsest$LTER_Site) # P/V+S versus Site.
par(op) # There's some outliers, but let's see how it goes without transformations.

ggpairs(pvsest) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - P/V+S
# Explanatory variables - Diameter, Group, Date

q1 <- lm(P..V.S. ~ Group + Core + Diameter_50, data = pvsest) # Initial linear model.
rq1 <- rstandard(q1) # Assigns standardized residuals to rq1.

pvsest <- pvsest %>%
  mutate(rq1 = rq1)

ggplot(data = pvsest, aes(x = LTER_Site, y = rq1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = pvsest, aes(x = Group, y = rq1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

ggplot(data = pvsest, aes(x = Core, y = rq1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "top/bottom of Core", y = "Standardised residuals")

ggplot(data = pvsest, aes(x = Replicate, y = rq1)) + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

q2 <- gls(P..V.S. ~ Group + Core + Diameter_50, data = pvsest) # Linear regression.
q3 <- lme(P..V.S. ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, data = pvsest) # First LMEM with random term.
anova(q2, q3)# Compares the two models. q2 preferred with an AIC value of -51.61108. But I'm going to keep the random term in for repeated measures accounting.

# STEP 3: Decide on a variance structure.

plot(q3, col=1) # Plots residuals. Yeah, we need one.

q4 <- lme(P..V.S. ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, data = pvsest,
          weights = varIdent(form =~1 | Group)) # Creates variance structure by sampling date.
anova(q3, q4) # Compares the two models. q4 is better with an AIC value of -62.50707.

# STEP 4: Fit the lme().

# Using q4 <- lme(P..V.S. ~ Group + Core + Diameter_50, 
#          random =~1 | LTER_Site/Replicate/Core, data = pvsest,
#          weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(q2,q4) # q4 still preferred with an AIC value of -62.50707.

# STEP 6: Everything ok? Check residuals.

plot(q4, col=1) # Residuals look far better.
qqnorm(q4) # Looks OK.

# STEP 7/8: Step-wise Optimal Fixed Structure

q4_ml <- lme(P..V.S. ~ Group + Core + Diameter_50, 
             random =~1 | LTER_Site/Replicate/Core, 
             method = "ML", data = pvsest,
             weights = varIdent(form =~1 | Group)) # ML model structure.
q4sub1 <- update(q4_ml, .~. -Group) # Removes date.
q4sub2 <- update(q4_ml, .~. -Core) # Removes core section.
q4sub3 <- update(q4_ml, .~. -Diameter_50) # Removes grain size.
anova(q4_ml, q4sub1, q4sub2, q4sub3) # Compares all models. q4sub3 is preferred with an AIC value of -118.51985, so remove grain size.

q5 <- lme(P..V.S. ~ Group + Core, 
             random =~1 | LTER_Site/Replicate/Core, 
          method = "ML", data = pvsest,
             weights = varIdent(form =~1 | Group))
q5sub1 <- update(q5, .~. -Group) # Removes date.
q5sub2 <- update(q5, .~. -Core) # Removes core section.
anova(q5, q5sub1, q5sub2) # Compares all models. q5 preferred with an AIC value of -118.5199.

# STEP 9: Refit with REML

pvsest <- pvsest %>%
  mutate(Group = factor(Group)) %>%
  mutate(Core = factor(Core, levels = c("B", "T")))

qfinal <- lme(P..V.S. ~ Group + Core,
              random =~1 | LTER_Site/Replicate/Core,
              method = "REML", data = pvsest, 
              weights = varIdent(form =~1 | Group))

# Output of the model.
summary(qfinal)
plot(qfinal, col=1) # Checking residuals.
qqnorm(qfinal) # Look pretty good considering low # of samples.

# Final Results.
anova(qfinal) # Output for the paper

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled AND section of core on P/V+S signatures of a given estuarine sediment sample. Random intercept by nested sample site/replicate/core was also included as well as a variance term for water depth.

# Equation: P/V+S = 0.19 - 0.03[GroupF] - 0.12[GroupH] - 0.09[GroupK] + 0.04[CoreT] + random + variance

# BONUS : Tukey's HSD Post Hoc
qHSD_Core <- glht(qfinal, linfct=mcp(Core="Tukey"))
summary(qHSD_Core) # Top and bottom significantly different, p < 0.0001.

qHSD_Group <- glht(qfinal, linfct=mcp(Group="Tukey"))
summary(qHSD_Group) # H - D, p < 0.001; K - D, p < 0.001, H - F, p = 0.03214, H - K, p = 0.00578.

```

The final model took the form : P/V+S ~ Group + Core + 1|LTER_Site/Replicate/Core + 1|Group(var)

This translated to a formula of P/V+S = 0.19 - 0.03[GroupF] - 0.12[GroupH] - 0.09[GroupK] + 0.04[CoreT] + random + variance.

Post hoc results: Top & Bottom, p < 0.0001 ; Apr16 & Mar/Apr17, p < 0.001; Apr16 & Jun17, p < 0.001; Jun16 & Mar/Apr17, p = 0.03214; Mar/Apr17 & Jun17, p = 0.00578.

## 3,5Bd/V (estuarine)

```{r 35Bd/V estuary, include=FALSE}

### Data Exploration

boxplot(Bd.V ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(Bd.V ~ Group, data = estuarine) # Date boxplot. Fixed effect.
boxplot(Bd.V ~ Core, data = estuarine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), Median Diameter (grain size), and Core (section) and Site/Replicate/Core as a nested random effect.

bdvest <- estuarine %>%
  dplyr::select(LTER_Site, Replicate, Core, Group, Diameter_50, Bd.V) %>%
  na.omit # Create new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(bdvest$Bd.V, groups = bdvest$LTER_Site) # 3,5Bd/V versus Site.
par(op) # Looking ok - two major outliers here.

ggpairs(bdvest) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - 3,5-Bd/V
# Explanatory variables - Group, Core, Diameter

r1 <- lm(Bd.V ~ LTER_Site + Group + Core + Diameter_50, data = bdvest) # Initial linear model.
rr1 <- rstandard(r1) # Assigns standardized residuals to rr1.
bdvest <- bdvest %>%
  mutate(rr1 = rr1)

ggplot(data = bdvest, aes(x = LTER_Site, y = rr1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = bdvest, aes(x = Group, y = rr1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals") # Plots said residuals.

ggplot(data = bdvest, aes(x = Core, y = rr1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Core", y = "Standardised residuals") 

ggplot(data = bdvest, aes(x = Replicate, y = rr1)) + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals") 

#### STEP 2: Fit the lm() with GLS and compare to lme().

r2 <- gls(Bd.V ~ Group + Core + Diameter_50, data = bdvest) # Linear regression.
r3 <- lme(Bd.V ~ Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Replicate/Core, 
          data = bdvest) # First LMEM with random term.
anova(r2, r3) # Compares the two models. r2 preferred with an AIC value of -9.402051, but I'm going to keep the random structure in.

# STEP 3: Decide on a variance structure.

plot(r3, col=1) # Plots residuals. I'm going to add in a variance structure in the hopes that it will help smooth out the difference between those two additional outliers.

r4 <- lme(Bd.V ~ Group + Core + Diameter_50,  
          random =~1 | LTER_Site/Replicate/Core, data = bdvest,
          weights = varIdent(form =~1 | Group)) 

anova(r3,r4) # Compares the two models. r4 preferred with an AIC value of -14.482463.

# STEP 4: Fit the lme().

# Using r4 <- lme(Bd.V ~ Group + Core + Diameter_50,  
#          random =~1 | LTER_Site/Replicate/Core, data = bdvest,
#          weights = varIdent(form =~1 | Group)) 

# STEP 5: Compare the lm() and lme().

anova(r2,r4) # r4 preferred with an AIC value of -14.482463.

# STEP 6: Everything ok? Check residuals.

plot(r4, col=1) # Residuals look OK.
qqnorm(r4) # Looks ok, a little curvy.

# STEP 7/8: Step-wise Optimal Fixed Structure

r4_ml <- lme(Bd.V ~ Group + Core + Diameter_50, 
             random =~1 | LTER_Site/Replicate/Core, 
             method = "ML", data = bdvest, 
            weights = varIdent(form =~1 | Group))  # ML structure.
r4sub1 <- update(r4_ml, .~. -Group) # Removes date.
r4sub2 <- update(r4_ml, .~. -Core) # Removes core section.
r4sub3 <- update(r4_ml, .~. -Diameter_50) # Removes grain size.
anova(r4_ml, r4sub1, r4sub2, r4sub3) # Compares all models. r4sub1 is preferred with an AIC value of -60.10167. So, remove date.

r5_ml <- lme(Bd.V ~ Core + Diameter_50, 
             random =~1 | LTER_Site/Replicate/Core, 
             method = "ML", data = bdvest, 
             weights = varIdent(form =~1 | Group))
r5sub1 <- update(r5_ml, .~. -Core) # Removes core section.
r5sub2 <- update(r5_ml, .~. -diameter_50) # Removes grain size.
anova(r5_ml, r5sub1, r5sub2) # r5sub1 preferred with an AIC value of -60.52865 - remove core.

r6_ml <- lme(Bd.V ~ Diameter_50, 
             random =~1 | LTER_Site/Replicate/Core, 
             method = "ML", data = bdvest, 
             weights = varIdent(form =~1 | Group))
r6sub1 <- update(r6_ml, .~. -Diameter_50) # Removes grain size.
anova(r6_ml, r6sub1) # r6 preferred with an AIC value of -60.52865 - so stop here.

# STEP 9: Refit with REML

rfinal <- lme(Bd.V ~ Diameter_50, 
              random =~1 | LTER_Site/Replicate/Core,
              method = "REML", data = bdvest, 
              weights = varIdent(form =~1 | Group))

# Output of the model.
summary(rfinal)
plot(rfinal, col=1) # Checking residuals.
qqnorm(rfinal) # Looks pretty good.

# Final Results.
anova(rfinal) # Output for the paper

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of median diameter/grain size on 3,5Bd/V signatures of a given estuarine sediment sample. A nested random intercept by sample site/replicate/core was also included as well as a variance term accounting for date sampled.

# BONUS : Tukey's HSD Post Hoc

# NA

```

The final model took the form : 3,5Bd/V ~ Diameter_50 + 1|LTER_Site/Replicate/Core + 1|Group(var)

This translated to a formula of 3,5-Bd/V = 0.16 + 0.0003[Diameter] + random + variance.

Post hoc results: NA.

# Marine data

```{r marine data, include=FALSE}

# For the following code chunks, I'll use this same dataset since I've not added in any additional info like I did with the stream data.

reef <- mained %>%
  filter(mained$Environment=="Reef")

# Ok, but in the following code, unless I create a separate dataset, all of the stream/marine site levels, for example, will still be in there, which I don't want for modeling purposes. So I'm going to do the following:

#write.csv(reef,"marine.csv") # Export the data.
marine <- read_csv("marine.csv") # Load the data back in.
#str(marine) # Check to make sure its in the format I want. Perfect!

# And now to make some final edits to be sure the factors are indeed factors:
marine$Depthf <- as.factor(marine$Depthf) # Makes the water depth column a series of factors.
marine$Group_3f <- as.factor(marine$Group_3f) # Makes the regional column a series of factors.

```

## Sigma 8 (marine)

```{r Sigma marine, include=FALSE}

### Data Exploration

boxplot(Sigma8 ~ Type, data = marine) # Distance from stream boxplot. Fixed effect. 
boxplot(Sigma8 ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(Sigma8 ~ Group, data = marine) # Date boxplot. Fixed effect.
boxplot(Sigma8 ~ Depth, data = marine) # Water depth boxplot. Fixed effect.
boxplot(Sigma8 ~ Core, data = marine) # Core boxplot. Fixed effect.

sigmar <- marine %>%
  dplyr::select(Type, LTER_Site, Replicate, Depthf, Core, Group, `Diameter_50.00.`, Sigma8) %>%
  mutate(Diameter_50 = `Diameter_50.00.`) %>%
  na.omit # Creates new dataset.

ggpairs(sigmar) # Pairs plot. So, I'm going to investigate all four as fixed effects at first, but I think the Site should go in as a random effect too.

sigmar$Type <- factor(sigmar$Type, levels = c("MarineRunoff", "Marine")) # Relevels.

#### STEP 1: Create a linear regression and check residuals.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(sigmar$Sigma8, groups = sigmar$Site) # Sigma8 versus Site on right with outliers removed.
par(op) # Eh, doesn't look that much better. So, I'm going to log transform it. Meh.

sigmar$logSigma8 <- log10(sigmar$Sigma8) # Log transform into new column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(sigmar$Sigma8, groups = sigmar$Site) # Sigma8 versus Site on left with outliers removed.
dotchart(sigmar$logSigma8, groups = sigmar$Site) # LogSigma8 versus Site on righ.
par(op) # Muuuuuuch better.

ggpairs(sigmar)

# Based on boxplots & pairplots : 
# Response variables - logSigma8
# Explanatory variables - Type, Depthf, Group, Core, Diameter_50

s1 <- lm(logSigma8 ~ Type + Depthf + Group + Core + Diameter_50, data = sigmar) # Initial linear model.
rs1 <- rstandard(s1) # Assigns standardized residuals to rs1.
sigmar <- sigmar %>%
  mutate(rs1 = rs1)

ggplot(data = sigmar, aes(x = LTER_Site, y = rs1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = sigmar, aes(x = Group, y = rs1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

ggplot(data = sigmar, aes(x = Depthf, y = rs1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Water Depth", y = "Standardised residuals") # May need to allow for different variances based on water depth sampled.

ggplot(data = sigmar, aes(x = Core, y = rs1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Section of Core", y = "Standardised residuals")

ggplot(data = sigmar, aes(x = Type, y = rs1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Distance from Stream", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

s2 <- gls(logSigma8 ~ Type + Depthf + Group + Core + Diameter_50, data = sigmar) # Linear regression since it has no additional calls. Removed Site as a fixed effect because it resulted in an error message.

s3 <- lme(logSigma8 ~ Type + Depthf + Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          data = sigmar) # Creates the first LMEM with a random term so the lme() function works.

anova(s2, s3) # Compares the two models. s3 preferred with an AIC value of 240.3016.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(s3, col=1) # Check the residuals before jumping right in to applying variance transformation.
qqnorm(s3) # This actually looks pretty good - so I'm going to skip the added variance structure.

# STEP 4: Fit the lme().

# Using s3 <- lme(logSigma8 ~ Type + Depthf + Group + Core + Diameter_50, random =~1|LTER_Site/Depthf/Replicate/Core, data = sigmar) 

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

s3_ml <- lme(logSigma8 ~ Type + Depthf + Group + Core + Diameter_50, 
             random =~1 | LTER_Site/Depthf/Replicate/Core,
             method = "ML", data = sigmar) # ML model structure.

s3sub1 <- update(s3_ml, .~. -Type) # Removes Type.
s3sub2 <- update(s3_ml, .~. -Depthf) # Removes Depth.
s3sub3 <- update(s3_ml, .~. -Group) # Removes Group.
s3sub4 <- update(s3_ml, .~. -Core) # Removes Core.
s3sub5 <- update(s3_ml, .~. -Diameter_50) # Removes Diameter.

anova(s3_ml, s3sub1, s3sub2, s3sub3, s3sub4, s3sub5) # Compare the models. s3_ml preferred with an AIC value of 395.4894, so keep everything in.

# s3_ml is the final full model!!!

# STEP 9: Refit with REML

sigmar <- sigmar %>%
  mutate(Core = factor(Core, levels = c("B", "T"))) %>%
  mutate(Group = factor(Group))

sfinal <- lme(logSigma8 ~ Type + Depthf + Group + Core + Diameter_50, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "REML", data = sigmar) # YIPEE!!!

# Output of the model.
summary(sfinal)

# Checking residuals.
plot(sfinal, col=1) # Not perfect, but no pattern.
qqnorm(sfinal) # This makes me feel pretty good.

# Final results.
anova(sfinal)

# STEP 10: What does this mean in WORDS?

# My model suggests there is NO significant effect of ecosystem type (marine sites near and far from stream mouths) on Sigma 8 concentrations of a given sediment sample. However, Date, Depth (10m/20m), Core Section (Top/Bottom section), and Median Diameter were significant.

# Equation: log(Sigma 8) = -0.54 - 0.28[Marine] + 0.57[20m] - 0.19[Top] + 0.02[GroupE] - 0.07[GroupG] + 0.07[GroupJ] - 0.001[Diameter] + random

# BONUS POST HOC:

sHSD_Depth <- glht(sfinal, linfct=mcp(Depthf="Tukey")) # Tukey's post hoc analysis on fDepth factor.
summary(sHSD_Depth) # 20 and 10 m are significantly different from one another (p = 0.00115).

sHSD_Core <- glht(sfinal, linfct=mcp(Core="Tukey")) # Tukey's post hoc analysis on Core factor.
summary(sHSD_Core) # Top and bottom core sections are significantly different (p < 0.0001).

sHSD_Group <- glht(sfinal, linfct=mcp(Group="Tukey")) # Tukey's post hoc analysis on Date factor.
summary(sHSD_Group) # June 2017 (J) and March 2017 (G) were significantly different (p = 0.0007).

# Value calculations for manuscript:

sigmarmeans <- sigmar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanSig = mean(Sigma8, na.rm = TRUE), sdSig = sd(Sigma8, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : logSigma8 ~ Type + Depthf + Core + Group + Diameter_50 + 1|LTER_Site/Depthf/Replicate/Core

This translated to a formula of log(Sigma 8) = -0.54 - 0.28[Marine] + 0.57[20m] - 0.19[Top] + 0.02[GroupE] - 0.07[GroupG] + 0.07[GroupJ] - 0.001[Diameter] + random.

Post hoc results: 20M - 10M, p = 0.00115; Top - Bottom, p < 0.0001; March 2017 - June 2017, p = 0.0007.

## Lambda (marine)

```{r Lambda marine, include=FALSE}

### Data Exploration

boxplot(Lambda ~ Type, data = marine) # Distance from stream boxplot.
boxplot(Lambda ~ LTER_Site, data = marine) # Site boxplot. 
boxplot(Lambda ~ Group, data = marine) # Date boxplot. 
boxplot(Lambda ~ Depthf, data = marine) # Depth boxplot. 
boxplot(Lambda ~ Core, data = marine) # Core section boxplot.
plot(Lambda ~ `Diameter_50.00.`, data = marine) # Core section boxplot.

lammar <- marine %>%
  dplyr::select(Type, LTER_Site, Replicate, Depthf, Core, Group, `Diameter_50.00.`, Lambda) %>%
  mutate(Diameter_50 = `Diameter_50.00.`) %>%
  na.omit # Creates new dataset.

ggpairs(lammar) # Pairs plot.

lammar$Type <- factor(lammar$Type, levels = c("MarineRunoff", "Marine")) # Relevels for simpler labeling later.

#### STEP 1: Create a linear regression and check residuals.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(lammar$Lambda, groups = lammar$Site) # Lambda versus Site.
par(op) # Looks pretty good, save a few outliers still.

# Based on boxplots & pairplots : 
# Response variables - Lambda
# Explanatory variables - Type, Depthf, Group, Core, Diameter_50

t1 <- lm(Lambda ~ Type + Depthf + Group + Core + Diameter_50, data = lammar) # Initial linear model.
rt1 <- rstandard(t1) # Assigns standardized residuals to rt1.
lammar <- lammar %>%
  mutate(rt1 = rt1)

ggplot(data = lammar, aes(x = LTER_Site, y = rt1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals. Definitely needs to be a random effect.

ggplot(data = lammar, aes(x = Group, y = rt1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

ggplot(data = lammar, aes(x = Core, y = rt1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Core Section", y = "Standardised residuals")

ggplot(data = lammar, aes(x = Depthf, y = rt1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Water Depth (m)", y = "Standardised residuals")

ggplot(data = lammar, aes(x = Type, y = rt1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Distance from stream", y = "Standardised residuals")

ggplot(data = lammar, aes(x = Replicate, y = rt1)) + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

t2 <- gls(Lambda ~ Type + Depthf + Group + Core + Diameter_50, data = lammar) # Effectively a linear regression.
t3 <- lme(Lambda ~ Type + Depthf + Group + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          data = lammar) # First LMEM.
anova(t2, t3) # Compares the two models. t3 preferred with an AIC value of 703.9073.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(t3, col=1) # We check the residuals before jumping right in to applying variance transformation.
qqnorm(t3) # I'm going to add in a variance structure.

# Looks like we should add in the varIden() variance structure for the observations (based on boxplots) collected on different dates.

t4 <- lme(Lambda ~ Type + Depthf + Group + Core + Diameter_50,
           random =~1 | LTER_Site/Depthf/Replicate/Core, 
           data = lammar, 
           weights = varIdent(form =~1 | Depthf)) 
anova(t3, t4) # Compares both models. t4 is better with an AIC value of 703.9197.

plot(t4, col=1) 
qqnorm(t4) # Residuals look identical. I'm going to go back to t3, because it's simpler and I feel like does the same thing. I think the issue here may be lack of log() transformation, but I'm hesitant to do that since I didn't do it in treating the entire dataset.

# STEP 4: Fit the lme().

# Using t3 <- lme(Lambda ~ Type + Depthf + Group + Core + Diameter_50, random =~1 | LTER_Site/Depthf/Replicate/Core, data = lammar)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3. 

# STEP 7/8: Step-wise Optimal Fixed Structure

t3_ml <- lme(Lambda ~ Type + Depthf + Group + Core + Diameter_50, 
             random =~1 | LTER_Site/Depthf/Replicate/Core,
             method = "ML", 
             data = lammar) # ML model structure.

t3sub1 <- update(t3_ml, .~. -Type) # Removes Type.
t3sub2 <- update(t3_ml, .~. -Depthf) # Removes Depth.
t3sub3 <- update(t3_ml, .~. -Core) # Removes Core.
t3sub4 <- update(t3_ml, .~. -Group) # Removes Group.
t3sub5 <- update(t3_ml, .~. -Diameter_50) # Removes grain size.

anova(t3_ml, t3sub1, t3sub2, t3sub3, t3sub4, t3sub5) # Compare the models. t3_ml preferred with an AIC value of 671.8920, so keep everything in!

# STEP 9: Refit with REML

lammar <- lammar %>%
  mutate(Core = factor(Core)) %>%
  mutate(Group = factor(Group))

tfinal <- lme(Lambda ~ Type + Depthf + Group + Core + Diameter_50, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "REML", 
              data = lammar)

# Output of the model.
summary(tfinal)

# Checking residuals.
plot(tfinal, col=1) # Not perfect, but no huge pattern.
qqnorm(tfinal) # Looking ok.

# Final results.
anova(tfinal)

# STEP 10: What does this mean in WORDS?

# My model suggests there is NO significant effect of ecosystem type (marine sites near and far from stream mouths) on Lambda concentrations of a given sediment sample. Group (date sampled), Depthf (water depth sampled), Core (top v. bottom), and Diameter_50 (median grain size) were significant.

# Equation: Lambda = 1.00 - 0.42[Marine] + 0.46[20m] - 0.26[Top] + 0.28[GroupE] + 0.28[GroupG] + 0.44[GroupJ] - 0.0002[Diameter_50] + random

# BONUS POST HOC:

tHSD_Depth <- glht(tfinal, linfct=mcp(Depthf="Tukey")) # Tukey's post hoc analysis on fDepth factor.
summary(tHSD_Depth) # 20 and 10 m are significantly different from one another (p = 0.033).

tHSD_Core <- glht(tfinal, linfct=mcp(Core="Tukey")) # Tukey's post hoc analysis on Core factor.
summary(tHSD_Core) # Top and bottom core sections are significantly different (p < 0.0001).

tHSD_Group <- glht(tfinal, linfct=mcp(Group="Tukey")) # Tukey's post hoc analysis on Date factor.
summary(tHSD_Group) # Dec 2015 (A) and June 2017 (J) were significantly different (p < 0.001), as were A & E (p = 0.0268) and A & G (p = 0.0103).

# Value calculations for manuscript:

lammarmeans <- lammar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanLam = mean(Lambda, na.rm = TRUE), sdLam = sd(Lambda, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : Lambda ~ Type + Depth + Core + Group +Diameter_50 + 1|LTER_Site/Depthf/Replicate/Core

This translated to a formula of Lambda = 1.00 - 0.42[Marine] + 0.46[20m] - 0.26[Top] + 0.28[GroupE] + 0.28[GroupG] + 0.44[GroupJ] - 0.0002[Diameter_50] + random.

Post hoc results: 20M - 10M, p = 0.033; Top - Bottom, p < 0.0001; December 2015 (A) - June 2017 (J), p < 0.001; December 2015 (A) - June 2016 (E), p = 0.0268; December 2015 (A) - March 2017 (G), p = 0.0103 (all others NS).

## S/V (marine)

```{r S/V marine, include=FALSE}

### Data Exploration - boxplots and pairplots

boxplot(S.V ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(S.V ~ Group, data = marine) # Date boxplot. Fixed effect?
boxplot(S.V ~ Depth, data = marine) # Depth boxplot. Fixed effect.
boxplot(S.V ~ Core, data = marine) # Core section boxplot. Fixed effect.
boxplot(S.V ~ Type, data = marine) # Distance from stream boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), (Water) Depth, Core Section, Type (Near/Far from Runoff), and Diameter_50 (grain size) as fixed and Site/Depth/Replicate/Core as a nested random effect.

svmar <- marine %>%
  dplyr::select(Type, LTER_Site, Replicate, Depthf, Core, Group, `Diameter_50.00.`, S.V) %>%
  mutate(Diameter_50 = `Diameter_50.00.`) %>%
  na.omit# Create new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(svmar$S.V, groups = svmar$LTER_Site) # S/V versus Site.
par(op) # Looking ok. Going to keep moving forward without transformations.

ggpairs(svmar) # Quick pairs plot to check correlated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - S/V
# Explanatory variables - Type, Depthf, Group, Core, Diameter_50

u1 <- lm(S.V ~ Type + Group + Depthf + Core + Diameter_50, data = svmar) # Initial linear model.
ru1 <- rstandard(u1) # Assigns standardized residuals.
svmar <- svmar %>%
  mutate(ru1 = ru1)

ggplot(data = svmar, aes(x = LTER_Site, y = ru1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = svmar, aes(x = Group, y = ru1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

ggplot(data = svmar, aes(x = Depthf, y = ru1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Water Depth (m)", y = "Standardised residuals")

ggplot(data = svmar, aes(x = Type, y = ru1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Distance from Stream", y = "Standardised residuals")

ggplot(data = svmar, aes(x = Core, y = ru1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Core Section", y = "Standardised residuals")

ggplot(data = svmar, aes(x = Replicate, y = ru1)) + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

u2 <- gls(S.V ~ Type + Group + Depthf + Core + Diameter_50, data = svmar) # Linear regression.
u3 <- lme(S.V ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          data = svmar) # First LMEM with random term.
anova(u2, u3) # Compares the two models. u3 preferred with an AIC value of 1240.367.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(u3, col=1) # Plots residuals before immediately applying variance transformation.

u4 <- lme(S.V ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          data = svmar,
          weights = varIdent(form =~1 | Depthf)) # Adding in a variance structure by depth - based on boxplots. Depth appeared to have a greater difference in variances.

anova(u3, u4) # Compares model with random effect and model with both random and variance effects. u4 preferred with an AIC value of 1128.906.

plot(u4, col=1) # Residuals look much better in this instance.

# STEP 4: Fit the lme().

# Using u4 <- lme(S.V ~ Type + Group + Depthf + Core + Diameter_50, 
#          random =~1 | LTER_Site/Depthf/Replicate/Core, 
#          data = SV_marine,
#          weights = varIdent(form =~1 | Depthf))

# STEP 5: Compare the lm() and lme().

anova(u2, u4) # 4 definitely outperforms 2.

# STEP 6: Everything ok? Check residuals.

plot(u4, col=1) # Residuals look better than they did.
qqnorm(u4) # Looks pretty good.

# STEP 7/8: Step-wise Optimal Fixed Structure

u4_ml <- lme(S.V ~ Type + Group + Depthf + Core + Diameter_50, 
             random =~1 | LTER_Site/Depthf/Replicate/Core,
             method = "ML", data = svmar,
             weights = varIdent(form =~1 | Depthf)) # Creates current model using ML structure.

u4sub1 <- update(u4_ml, .~. -Group) # Removes date sampled.
u4sub2 <- update(u4_ml, .~. -Depthf) # Removes water depth.
u4sub3 <- update(u4_ml, .~. -Type) # Removes near/far classification.
u4sub4 <- update(u4_ml, .~. -Core) # Removes core section.
u4sub5 <- update(u4_ml, .~. -Diameter_50) # Removes grain size.

anova(u4_ml, u4sub1, u4sub2, u4sub3, u4sub4, u4sub5) # Compares all models. u4_ml preferred with an AIC value of 1105.797. Stop here.

# STEP 9: Refit with REML

svmar <- svmar %>%
  mutate(Group = factor(Group))

ufinal <- lme(S.V ~ Type + Group + Depthf + Core + Diameter_50, 
              random =~1 | LTER_Site/Depthf/Replicate/Core,
              method = "REML", data = svmar, 
              weights = varIdent(form =~1 | Depthf))

# Output of the model.
summary(ufinal)
plot(ufinal, col=1) # Checking residuals. Looking good!
qqnorm(ufinal) # Looks a little curvy, but OK I think.

# Final results.
anova(ufinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of water depth and date sampled on marine S/V signatures, but not core section, grain size, or classification as distance from stream. Random effects by site/depth/replicate/core were included as well as a variance term for water depth.

# Equation: S/V = 3.84 - 1.00[Depthf20] + 0.18[Top] + 0.22[GroupE] + 0.56[GroupG] + 0.30[GroupJ] - 0.56[MarineRunoff] - 0.003[Diameter_50] + random + variance

# BONUS : Tukey's HSD Post Hoc
uHSD_Depth <- glht(ufinal, linfct=mcp(Depthf="Tukey"))
summary(uHSD_Depth) # Significant different between 10 and 20m (p = 0.00807).

uHSD_Group <- glht(ufinal, linfct=mcp(Group="Tukey"))
summary(uHSD_Group) # Significant different between Dec 2015 (A) and March 2017 (G) (p < 0.001).

# Value calculations for manuscript:

svmarmeans <- svmar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanSV = mean(S.V, na.rm = TRUE), sdSV = sd(S.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : S.V ~ Type + Depth + Group + Core + Diameter_50 + 1|LTER_Site/Depthf/Replicate/Core + 1|Depthf(var)

This translated to a formula of S/V = 3.84 - 1.00[Depthf20] + 0.18[Top] + 0.22[GroupE] + 0.56[GroupG] + 0.30[GroupJ] - 0.56[MarineRunoff] - 0.003[Diameter_50] + random + variance.

Post hoc results: 20m & 10m, p = 0.00807; Dec 2015 & Mar 2017, p < 0.001

## C/V (marine)

```{r C/V marine, include=FALSE}

### Data Exploration - boxplots and pairplots

boxplot(C.V ~ Type, data = marine) # Distance from stream boxplot. Fixed effect.
boxplot(C.V ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(C.V ~ Group, data = marine) # Date boxplot. Fixed effect.
boxplot(C.V ~ Depthf, data = marine) # Depth boxplot. Fixed effect.
boxplot(C.V ~ Core, data = marine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Type (near/far from runoff), Group (date sampled), (water) Depth, Diameter_50 (median grain size), and Core (section) as fixed variables and Site/Depthf/Replicate/Core as a nested random variable.

cvmar <- marine %>%
  dplyr::select(Type, LTER_Site, Replicate, Depthf, Core, Group, `Diameter_50.00.`, C.V) %>%
  mutate(Diameter_50 = `Diameter_50.00.`) %>%
  na.omit # Create new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(cvmar$C.V, groups = cvmar$LTER_Site) # C/V versus Site.
par(op) # A few outliers.

ggpairs(cvmar) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - C/V
# Explanatory variables - Type, Group, Depth, Core, Diameter

v1 <- lm(C.V ~ Type + Group + Depthf + Core + Diameter_50, data = cvmar)# Initial linear model.
rv1 <- rstandard(v1) # Assigns standardized residuals.
cvmar <- cvmar %>%
  mutate(rv1 = rv1)

ggplot(data = cvmar, aes(x = LTER_Site, y = rv1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals") # Plots said residuals.

ggplot(data = cvmar, aes(x = Group, y = rv1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

ggplot(data = cvmar, aes(x = Depthf, y = rv1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Water Depth (m)", y = "Standardised residuals")

ggplot(data = cvmar, aes(x = Core, y = rv1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Section", y = "Standardised residuals")

ggplot(data = cvmar, aes(x = Replicate, y = rv1)) + 
  geom_point() +
  labs(x = "Replicate", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

v2 <- gls(C.V ~ Type + Group + Depthf + Core + Diameter_50, data = cvmar) # Linear regression.
v3 <- lme(C.V ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          data = cvmar) # Creates the first LMEM with random term.
anova(v2, v3) # Compares the models. v3 preferred with an AIC value of -627.7649 so keep random effect.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(v3, col=1) # Plots residuals before immediately applying variance transformation. Looks like a variance term may be necessary.

v4 <- lme(C.V ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          data = cvmar,
          weights = varIdent(form =~1 | Depthf)) # Adds in term to account for difference variances by depth sampled based on boxplots.

anova(v3,v4) # looks like v4 is preferred with an AIC value of -660.9837.

plot(v4, col=1) # The residuals look better.

# STEP 4: Fit the lme().

# Using v4 <- lme(C.V ~ Type + Group + Depthf + Core + Diameter_50, 
#         random =~1 | LTER_Site/Depthf/Replicate/Core,
#         data = cvmar,
#         weights = varIdent(form =~1 | Depthf))

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(v4, col=1) # Fine for our purposes.
qqnorm(v4) # Looks curved, but so did the SV qq plot.

# STEP 7/8: Step-wise Optimal Fixed Structure

v4_ml <- lme(C.V ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "ML", 
          data = cvmar,
          weights = varIdent(form =~1 | Depthf)) # ML model structure.

v4sub1 <- update(v4_ml, .~. -Type) # Removes near/far classification.
v4sub2 <- update(v4_ml, .~. -Group) # Removes date sampled.
v4sub3 <- update(v4_ml, .~. -Depthf) # Removes water depth sampled.
v4sub4 <- update(v4_ml, .~. -Core) # Removes core section sampled.
v4sub5 <- update(v4_ml, .~. -Diameter_50) # Removes median grain size.

anova(v4_ml, v4sub1, v4sub2, v4sub3, v4sub4, v4sub5) # Compares all models. v4sub4 preferred with an AIC value of -731.3113 so remove Core section.

v5 <- lme(C.V ~ Type + Group + Depthf + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "ML", 
          data = cvmar,
          weights = varIdent(form =~1 | Depthf)) # ML model structure.

v5sub1 <- update(v5, .~. -Type) # Removes near/far classification.
v5sub2 <- update(v5, .~. -Group) # Removes date sampled.
v5sub3 <- update(v5, .~. -Depthf) # Removes water depth sampled.
v5sub4 <- update(v5, .~. -Diameter_50) # Removes median grain size.

anova(v5, v5sub1, v5sub2, v5sub3, v5sub4) # Compares all models. v5sub3 preferred with an AIC value of -732.0207 so remove depth.

v6 <- lme(C.V ~ Type + Group + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "ML", 
          data = cvmar,
          weights = varIdent(form =~1 | Depthf)) # ML model structure.

v6sub1 <- update(v6, .~. -Group) # Removes date sampled.
v6sub2 <- update(v6, .~. -Type) # Removes site classification sampled.
v6sub3 <- update(v6, .~. -Diameter_50) # Removes median grain size.

anova(v6, v6sub1, v6sub2, v6sub3) # Compares all models. v6 preferred with an AIC value of -732.0207 so keep everything else in.
# v6 is the final full model.

# STEP 9: Refit with REML

cvmar <- cvmar %>%
  mutate(Group = factor(Group))

vfinal <- lme(C.V ~ Type + Group + Diameter_50,  
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "REML", 
          data = cvmar,
          weights = varIdent(form =~1 | Depthf))

# Output of the model.
summary(vfinal)
plot(vfinal, col=1) # Checking residuals. Looking ok!
qqnorm(vfinal) # Looks meh, but I'm going to leave it.

# Final results.
anova(vfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled on marine C/V signatures. Random nested intercepts by site/depth/replicate/core were included.

# Equation: C/V = 0.10 - 0.06[GroupE] - 0.04[GroupG] - 0.03[GroupJ] + 0.0002[Diameter_50] + 0.02[MarineRunoff] + random + variance

# BONUS : Tukey's HSD Post Hoc
vHSD_Group <- glht(vfinal, linfct=mcp(Group="Tukey")) 
summary(vHSD_Group) # Significant different between Jun 16 (E) & Dec 15 (A) (p < 0.001), Mar 17 (G) & Dec 15 (A) (p < 0.001), Jun 17 (J) & Dec 15 (A) (p = 0.0117), and Jun 17 (J) & Jun 16 (E) (p = 0.046).

# Value calculations for manuscript:

cvmarmeans <- cvmar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanCV = mean(C.V, na.rm = TRUE), sdCV = sd(C.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : C.V ~ Type + Group + Diameter_50 + 1|LTER_Site/Depthf/Replicate/Core + + 1|Depthf(var)

This translated to a formula of C/V = 0.10 - 0.06[GroupE] - 0.04[GroupG] - 0.03[GroupJ] + 0.0002[Diameter_50] + 0.02[MarineRunoff] + random + variance

Post hoc results: Dec15 & Jun16, p < 0.001 ; Dec15 & Mar17, p < 0.001; Dec15 & Jun17, p = 0.01; Jun16 & Jun17, p = 0.046.

## P/V+S (marine)

```{r P/V+S marine, include=FALSE}

### Data Exploration - boxplots and pairplots
boxplot(P..V.S. ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(P..V.S. ~ Group, data = marine) # Date boxplot. Fixed effect.
boxplot(P..V.S. ~ Depth, data = marine) # Depth boxplot. Fixed effect.
boxplot(P..V.S. ~ Type, data = marine) # Distance from stream boxplot. Fixed effect.
boxplot(P..V.S. ~ Core, data = marine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group, Depthf, Core, Diameter_50 and Type as fixed variables and Site/Depthf/Replicate/Core as a nested random variable.

pvsmar <- marine %>%
  dplyr::select(Type, LTER_Site, Replicate, Depthf, Core, Group, `Diameter_50.00.`, P..V.S.) %>%
  mutate(Diameter_50 = `Diameter_50.00.`) %>%
  na.omit # Create new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(pvsmar$P..V.S., groups = pvsmar$LTER_Site) # P/V+S versus Site.
par(op) # There's two pretty big outliers, so I'm going to log-transform as I did for the entire dataset.

pvsmar$logPVS <- log10(pvsmar$P..V.S.) # Makes log-transformed column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(pvsmar$P..V.S., groups = pvsmar$LTER_Site) # P/V+S versus Site.
dotchart(pvsmar$logPVS, groups = pvsmar$LTER_Site) # log(P/V+S) versus Site.
par(op) # Looking MUCH better. 

ggpairs(pvsmar) # Quick pairs plot to check correlated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - P/V+S
# Explanatory variables - Type, Group, Depthf, Core, Diameter

w1 <- lm(logPVS ~ Type + Group + Depthf + Core + Diameter_50, data = pvsmar) # Initial linear model.
rw1 <- rstandard(w1) # Assigns standardized residuals to rw1.
pvsmar <- pvsmar %>%
  mutate(rw1 = rw1)

ggplot(data = pvsmar, aes(x = LTER_Site, y = rw1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals")

ggplot(data = pvsmar, aes(x = Group, y = rw1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

ggplot(data = pvsmar, aes(x = Depthf, y = rw1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Depth", y = "Standardised residuals")

ggplot(data = pvsmar, aes(x = Core, y = rw1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Core", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

w2 <- gls(logPVS ~ Type + Group + Depthf + Core + Diameter_50, data = pvsmar) # Linear regression.
w3 <- lme(logPVS ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, data = pvsmar ) # First LMEM with random term.
anova(w2, w3) # Compares the two models. w3 preferred with AIC value of 19.08849.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(w3, col=1) # Plots residuals.

w4 <- lme(logPVS ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          data = pvsmar,
          weights = varIdent(form =~1 | Depthf)) # Creates structure including different variance allowed by water depth based on the variances displayed by boxplots above.

anova(w3, w4) # Compares the two models. w4 is better with an AIC value of 4.149848.

# STEP 4: Fit the lme().

# Using w4 <- lme(logPVS ~ Type + Group + Depthf + Core + Diameter_50, 
#         random =~1 | LTER_Site/Depthf/Replicate/Core,
#         data = pvsmar,
#         weights = varIdent(form =~1 | Depthf))

# STEP 5: Compare the lm() and lme().

anova(w2,w4) # w4 still preferred.

# STEP 6: Everything ok? Check residuals.

plot(w4, col=1) # Residuals look better.
qqnorm(w4) # Looks fine.

# STEP 7/8: Step-wise Optimal Fixed Structure

w4_ml <- lme(logPVS ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          data = pvsmar, method = "ML",
          weights = varIdent(form =~1 | Depthf)) # ML model structure.
w4sub1 <- update(w4_ml, .~. -Type) # Removes near/far classification.
w4sub2 <- update(w4_ml, .~. -Group) # Removes date.
w4sub3 <- update(w4_ml, .~. -Depthf) # Removes water depth.
w4sub4 <- update(w4_ml, .~. -Core) # Removes water depth.
w4sub5 <- update(w4_ml, .~. -Diameter_50) # Removes median grain size.

anova(w4_ml, w4sub1, w4sub2, w4sub3, w4sub4, w4sub5) # Compares all models. w4 is preferred with an AIC value of -42.63358, so keep everything in.

# STEP 9: Refit with REML

pvsmar <- pvsmar %>%
  mutate(Group = factor(Group)) %>%
  mutate(Core = factor(Core)) %>%
  mutate(Type = factor(Type))

wfinal <- lme(logPVS ~ Type + Group + Depthf + Core + Diameter_50,
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "REML", data = pvsmar, 
          weights = varIdent(form =~1 | Depthf))

# Output of the model.
summary(wfinal)
plot(wfinal, col=1) # Checking residuals.
qqnorm(wfinal) # Look pretty good considering low # of samples.

# Find Results.
anova(wfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of location near/far from stream, date sampled, core section, median grain size, AND water depth on P/V+S signatures of a given marine sediment sample. Random intercept by sample site/depth/replicate/core was also included as well as a variance term for water depth.

# Equation: log(P/V+S) = - 0.49 - 0.21[MarineRunoff] - 0.07[GroupE] - 0.15[GroupG] - 0.44[GroupJ] - 0.23[Depth20] + 0.08[Top] + 0.0008[Diameter_50] + random + variance

# BONUS : Tukey's HSD Post Hoc
wHSD_Type <- glht(wfinal, linfct=mcp(Type="Tukey"))
summary(wHSD_Type) # p = 0.00868.

wHSD_Group <- glht(wfinal, linfct=mcp(Group="Tukey"))
summary(wHSD_Group) # All significantly different except A & E and E & G (see below for details).

wHSD_Depth <- glht(wfinal, linfct=mcp(Depthf="Tukey"))
summary(wHSD_Depth) # p = 0.00265.

wHSD_Core <- glht(wfinal, linfct=mcp(Core="Tukey"))
summary(wHSD_Core) # p = 0.000704.

# Value calculations for manuscript:

pvsmarmeans <- pvsmar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanPVS = mean(P..V.S., na.rm = TRUE), sdPVS = sd(P..V.S., na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : log(P/V+S) ~ Type + Group + Depthf + Core + Diameter_50 + 1|LTER_Site/Depthf/Replicate/Core + 1|Depth(var)

This translated to a formula of log(P/V+S) = -0.49 - 0.21[MarineRunoff] - 0.07[GroupE] - 0.15[GroupG] - 0.44[GroupJ] - 0.23[Depth20] + 0.08[Top] + 0.0008[Diameter_50] + random + variance.

Post hoc results: Marine & MarineRunoff, p = 0.00868 ; Top & Bottom, p = 0.000704; Dec15 & Mar17, p < 0.001; Dec15 & Jun17, p < 0.001; Jun16 & Jun17, p < 0.001; Mar17 & Jun17, p < 0.001; 20m & 10m, p = 0.00265.

## 3,5Bd/V (marine)

```{r 35Bd/V marine, include=FALSE}

### Data Exploration - boxplots and pairplots

boxplot(Bd.V ~ Type, data = marine) # Distance from stream boxplot. Fixed effect.
boxplot(Bd.V ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(Bd.V ~ Group, data = marine) # Date boxplot. Fixed effect?
boxplot(Bd.V ~ Depthf, data = marine) # Depth boxplot. Fixed effect.
boxplot(Bd.V ~ Core, data = marine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Type (near/far), Group (date sampled), Core (section), Diameter_50, and (water) Depth as fixed variables and Site/Depthf/Replicate/Core as a random effect.

bdvmar <- marine %>%
  dplyr::select(Type, LTER_Site, Replicate, Depthf, Core, Group, `Diameter_50.00.`,Bd.V) %>%
  mutate(Diameter_50 = `Diameter_50.00.`) %>%
  na.omit # Create new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(bdvmar$Bd.V, groups = bdvmar$LTER_Site) # 3,5Bd/V versus Site.
par(op) # I'm going to log-transform as I did with PVS.

bdvmar$logBDV <- log10(bdvmar$Bd.V) # Makes log-transformed column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(bdvmar$Bd.V, groups = bdvmar$LTER_Site) # 3,5Bd/V versus Site.
dotchart(bdvmar$logBDV, groups = bdvmar$LTER_Site) # log(3,5Bd/V) versus Site.
par(op) # Looks much better.

ggpairs(bdvmar) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - 3,5-Bd/V
# Explanatory variables - Type, Group, Depth, Core, Diameter

x1 <- lm(logBDV ~ Type + Group + Depthf + Core + Diameter_50, data = bdvmar) # Initial linear model.
rx1 <- rstandard(x1) # Assigns standardized residuals to rx1.
bdvmar <- bdvmar %>%
  mutate(rx1 = rx1)

ggplot(data = bdvmar, aes(x = LTER_Site, y = rx1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Site", y = "Standardised residuals")

ggplot(data = bdvmar, aes(x = Group, y = rx1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Date", y = "Standardised residuals")

ggplot(data = bdvmar, aes(x = Core, y = rx1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Core", y = "Standardised residuals")

ggplot(data = bdvmar, aes(x = Type, y = rx1)) + 
  geom_boxplot() + 
  geom_point() +
  labs(x = "Distance from Stream", y = "Standardised residuals")

#### STEP 2: Fit the lm() with GLS and compare to lme().

x2 <- gls(logBDV ~ Type + Group + Depthf + Core + Diameter_50, data = bdvmar) # Linear regression.
x3 <- lme(logBDV ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          data = bdvmar) # First LMEM with random term.
anova(x2, x3) # Compares the two models. x3 preferred with an AIC value of -36.34122.

# STEP 3: Decide on a variance structure.

plot(x3, col=1) # Plots residuals before immediately applying variance transformation. No need.
qqnorm(x3) # Looks just fine.

# STEP 4: Fit the lme().

# Using x3 <- lme(logBDV ~ Type + Group + Depthf + Core + Diameter_50,
#          random =~1 | LTER_Site/Depthf/Replicate/Core,
#          data = bdvmar)  

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

x3_ml <- lme(logBDV ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core, 
          method = "ML", 
          data = bdvmar)  # ML model structure.
x3sub1 <- update(x3_ml, .~. -Type) # Removes near/far from stream classification.
x3sub2 <- update(x3_ml, .~. -Group) # Removes date.
x3sub3 <- update(x3_ml, .~. -Depthf) # Removes water depth.
x3sub4 <- update(x3_ml, .~. -Core) # Removes core section.
x3sub5 <- update(x3_ml, .~. -Diameter_50) # Removes core section.
anova(x3_ml, x3sub1, x3sub2, x3sub3, x3sub4, x3sub5) # Compares all models. x4 is preferred with an AIC value of -82.15663. So, stop here.

# STEP 9: Refit with REML

bdvmar <- bdvmar %>%
  mutate(Group = factor(Group)) %>%
  mutate(Core = factor(Core))

xfinal <- lme(logBDV ~ Type + Group + Depthf + Core + Diameter_50, 
          random =~1 | LTER_Site/Depthf/Replicate/Core,
          method = "REML", 
          data = bdvmar) # Yay!! LAST ONE!!!

# Output of the model.
summary(xfinal)
plot(xfinal, col=1) # Checking residuals.
qqnorm(xfinal) # Looks fine.

# Final results.
anova(xfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled, core section, grain size, and water depth on 3,5Bd/V signatures of a given marine sediment sample. Random intercept by sample/depth/replicate/core site was also included.

# Equation: log(3,5-Bd/V) = - 0.31 + 0.16[GroupE] + 0.18[GroupG] + 0.24[GroupJ] - 0.34[Depth20] + 0.06[CoreT] - 0.18[MarineRunoff] + 0.0009[Diameter_50] + random

# BONUS : Tukey's HSD Post Hoc
xHSD_Group <- glht(xfinal, linfct=mcp(Group="Tukey"))
summary(xHSD_Group) # A&E, A&G, and A&J significantly different.

xHSD_Depth <- glht(xfinal, linfct=mcp(Depthf="Tukey"))
summary(xHSD_Depth) # 20m and 10m significantly different.

xHSD_Core <- glht(xfinal, linfct=mcp(Core="Tukey"))
summary(xHSD_Core) # Top and Bottom significantly different.

```

The final model took the form : log(3,5Bd/V) ~ Type + Group + Depth + Core + Diameter_50 + 1|LTER_Site/Depthf/Replicate/Core

This translated to a formula of log(3,5-Bd/V) = - 0.31 + 0.16[GroupE] + 0.18[GroupG] + 0.24[GroupJ] - 0.34[Depth20] + 0.06[CoreT] - 0.18[MarineRunoff] + 0.0009[Diameter_50] + random.

Post hoc results: Dec15 & Jun16, p < 0.001; Dec15 & Mar17, p < 0.001; Dec15 & Jun17, p < 0.001; 20m & 10m, p = 0.00251; Top & Bottom, p = 0.00334.

This is the end of the RMarkdown document.