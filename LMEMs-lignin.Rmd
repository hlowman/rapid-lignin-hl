---
title: "LMEMs-lignin"
author: "Heili Lowman"
date: "1/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Linear Mixed Effect Models

This document was last updated on JANUARY 26, 2020.

This is an R Markdown document that will walk through all of the LMEMs run for Chapter 3 of my dissertation and the resulting manuscript.

Model creation begins with fixed effects and random effects using a random intercept structure. Then, model selection follows the protocol outlined by Zuur et al. (2009, Chapter 5), beginning with a linear model, accounting for variance structure, optimizing the fixed structure, and validating best model fit using distribution of residuals and AIC values. All 24 of the below models follow the same format.

**Shortcut Note: For future use, if you want to select and change multiple mentions of the same variable, hold CTRL + SHFT + ALT + M while highlighting the chosen variable and it will select all mentions within the document.**

```{r data and packages, include=FALSE}

master <- read.csv("RAPID_Master_Datasheet_add_region_streamcode.csv") # Loads the newly updated dataset, as of April 8, 2019. 

#Some of the column headers have been changed, including the ones containing the "micro" symbol, which R apparently cannot process. 
#LTER_Site column - added so that naming convention is consistent, especially among stream sites which were entered differently in the "Site" column.
#Group_2 column - added to split reef sites into groupings near and far from streams by date. 
#Group_3 column - added to create regions from west to east as discussed with Matthieu.
# In addition, all NDs from Matthieu's original reports are replaced as NAs.

library(tidyverse)
library(nlme)
library(multcomp)
library(lsmeans)

```

First, I reviewed all of the columns that were added manually to the original dataset to make data grouping by date easier.

Next, I am going to review the data in the tidyverse and make sure everything is in the correct numerical format and remove outliers for the *entirety* of the dataset.

```{r tidying up, include=FALSE}

# Format

str(master) # Shows the format of each of the columns in the dataset.

# Need to make Depth and Group_3 factors and convert C.N, C, and P numeric.

master$Depthf <- as.factor(master$Depth) # Makes the water depth column a series of factors.

master$Group_3f <- as.factor(master$Group_3) # Makes the regional column a series of factors.

# I don't actually use the following columns in the analysis, but figured it's best to make these transformations just in case.

master$C.Nnum <- as.numeric(master$C.N) # Makes the C:N column a series of numbers.

master$Cnum <- as.numeric(master$C) # Makes the cinnamyl column a series of numbers.

master$Pnum <- as.numeric(master$P) # Makes the p-phenol column a series of numbers.

# NAs and 0s

# The only "<0.01"s appear to be in the "C" column, so going to leave those since this column is not being analyzed in this code.

# Upon further inspection of the dataset, I feel it makes the most sense to only alter those columns that are needed for the below analysis, so that's what I'll do. See below:

# See e-mail correspondence with Matthieu on 1/22/2020: "ND does not mean 0. When doing analytical measurements using GC/MS or others detectors you never can say that you have 0. Indeed, due to analytical issues you have limits of quantification and limits of detection. To summarize, when you are under LOD, it does not mean that you do not have the presence of the analyte but that you cannot decipher it from the background."

# So, all NAs that were previously NDs will be left as such since they are not actually a 0 value.

# Outliers based on past models. I'm going to work through these and take a more conservative approach with removing outliers from the whole dataset.

# full (6)
# Sigma8 - 66
# Lambda - 164, 238 (choosing to keep in 161)
# S/V - 387 (choosing to keep in 282, 299, 301, 443)
# C/V - 389
# PVS - (choosing to keep in 21, 23)
# BdV - 300

# marine (1)
# Sigma8 - 56, 172 (238), (choosing to keep in 301 (367))
# Lambda - 172 (238) (choosing to keep in 374 (454))

# stream (0)
# Sigma8 - 2 (66)

# estuary (0)
# CV - 47 (389)

# Alright, so the seven outliers I'm removing will be 56, 66, 164, 238, 300, 387, and 389 from the original dataset. I'll work backwards to preserve line numbers.

mastered <- master[ -c(56, 66, 164, 238, 300, 387, 389), ] # Starts with the original dataset and then removes desired rows.

```

These models will be organized in this file as they are listed in Appendix 4 of the manuscript.

# Entire Dataset

## Sigma 8

```{r Sigma, include=FALSE}

### Data Exploration

# I'm examining Region, Ecosystem Type (Stream, Estuarine, and Marine), Site, and Date as factors influencing lignin oxidation results. Here are the boxplots and pairplots necessary.

boxplot(Sigma8 ~ Group_3f, data = mastered) # Boxplot by region. In past iterations, this was determined not to be a significant factor, but I am going to keep it in the workflow as a potential fixed effect for now.
boxplot(Sigma8 ~ Environment, data = mastered) # Boxplot by environment. Fixed effect.
boxplot(Sigma8 ~ LTER_Site, data = mastered) # Boxplot by site. Random effect.
boxplot(Sigma8 ~ Group, data = mastered) # Boxplot by sampling date. Group lumps everything sampled on a single date together - the HUGE problem with this sampling design is that the sampling dates are SUPER closely correlated with Environment. Random effect (since there may be an effect across time, but one that may be indistiguishable from Environment).

# New dataset.

sig <- mastered %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Group, Sigma8) %>%
  na.omit # remove NAs and create new dataset.

pairs(sig) # Pairs plot.

sig$Environment <- factor(sig$Environment, levels = c("Stream", "Estuary", "Reef")) # Relevels for simpler labeling later.

#### STEP 1: Create a linear regression and check residuals.

# Reasoning for log-transforming Sigma values: per Chapter 19 of Zuur et al. 2009, I'm going to log transform the Sigma data because otherwise (using different variance structures) you are giving up lots of degrees of freedom and make GLS estimation unstable. And I KNOW homogeneity is an issue based on past attempts and the sheer spread of values. I know that this changes the values, but this will give me more flexibility in exploring explanatory variables, which I think is more important that the values themselves.

sig$logSigma8 <- log10(sig$Sigma8) # Log transform data to make heterogeneity of residuals a non-issue (hopefully).

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(sig$Sigma8, groups = sig$LTER_Site) # Sigma8 versus Site on left.
dotchart(sig$logSigma8, groups = sig$LTER_Site) # Log(Sigma8) versus Site on right.
par(op) # Looking better! And I've deemed the negative values to be A-OK since it's not a Poisson distribution (according to Ana MtK).

# Based on boxplots & pairplots : 
# Response variables - logSigma8
# Explanatory (fixed) variables - Group_3f, Environment

a1 <- lm(logSigma8 ~ Group_3f + Environment, data = sig) # Creates the initial linear model with both fixed variables.
ra1 <- rstandard(a1) # Assigns standardized residuals to eeee.
plot(ra1 ~ sig$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Since some boxplots are totally above/below zero, there is within-site correlation, so it WILL be used as a random effect as part of the random intercept model structure.

plot(ra1 ~ sig$Group, xlab = "Date",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Group looks less important so removing sampling date as a random effect.

#### STEP 2: Fit the lm() with GLS and compare to lme().

a2 <- gls(logSigma8 ~ Group_3f + Environment, data = sig) # This is effectively a linear regression since it has no additional calls.
a3 <- lme(logSigma8 ~ Group_3f + Environment, random =~1 | LTER_Site, data = sig) # Creates the first LMEM with nested random term.
anova(a2, a3) # Compares the two models. a3 preferred with AIC value of 741.60.

# STEP 3: Decide on a variance structure (aka random terms).

plot(a3, col=1) # Check the residuals before jumping right to applying a variance transformation.
qqnorm(a3) # This actually looks pretty good - so I'm going to skip the added variance structure. (This is likely thanks to the log transformation.)

# SIDE NOTE: KEEP IN MIND, log-transforming from the start is more powerful than adding in a variance component on the back end!!!

# STEP 4: Fit the lme().

# Using a3 <- lme(logSigma8 ~ Group_3f + Environment, random =~1 | LTER_Site, data = sig)

# STEP 5: Compare the lm() and lme().

anova(a2, a3) # 3 definitely outperforms 2.

# STEP 6: Everything ok? Check residuals.

# See results of Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

a3_ml <- lme(logSigma8 ~ Group_3f + Environment, 
             random =~1 | LTER_Site, method = "ML", data = sig) # Switch over to ML for fixed component editing portion.

a4 <- lme(logSigma8 ~ Environment, 
          random =~1 | LTER_Site, method = "ML", data = sig) # Remove Region as a fixed factor.

a5 <- lme(logSigma8 ~ Group_3f, 
          random =~1 | LTER_Site, method = "ML", data = sig) # Remove Environment as a fixed factor.

anova(a3_ml, a4, a5) # Compare the three models. a4 preferred with AIC value of 725.70, so remove Region.

a4full <- lme(logSigma8 ~ Environment, 
              random =~1 | LTER_Site, method = "ML", data = sig)

a4sub1 <- update(a4full, .~. -Environment) # Removes only term.

anova(a4full, a4sub1) # a4full preferred with AIC value of 725.70, so a4full is the final full model!!!

# STEP 9: Refit with REML

afinal <- lme(logSigma8 ~ Environment, 
              random =~1 | LTER_Site, method = "REML", data = sig) # YIPEE!!!

# Output of the model.
summary(afinal)

# Checking residuals.
plot(afinal, col=1) # Not perfect, but no pattern.
qqnorm(afinal) # This makes me feel pretty good.
qqnorm(afinal, ~ranef (.), col = 1) # I'll take it given that we've already log-transformed the data.

# Show intervals.
intervals(afinal)

# Final results.
anova(afinal)

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested with multiple samples (4+) taken from each site (18) on multiple occasions (2+). My model suggests there is a significant effect of ecosystem/environment type (stream, estuarine, marine) on Sigma 8 concentrations of a given sediment sample. Group (date sampled) and fGroup_3 (region sampled) were not included in the model due to variable selection using AIC values. Random intercepts by site were added.

# Equation: log(Sigma 8) = 0.66 - 0.67[Estuary] - 1.25[Reef] + random[Site]

# BONUS POST HOC:

aHSD <- glht(afinal, linfct=mcp(Environment="Tukey")) # Run a Tukey's post hoc analysis on Environment factor.
summary(aHSD) # All groups significantly different from one another. Note : Use the results of the first run on this function.

# Quick stats calculation of Sigma8 values by environment for the manuscript:

sigmeans <- sig %>%
  group_by(Environment) %>%
  summarize(meanSig8 = mean(Sigma8, na.rm = TRUE), sdSig8 = sd(Sigma8, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : logSigma8 ~ Environment + 1|LTER_Site.

This translates to a formula of log(Sigma8) = 0.66 - 0.67(Estuary) - 1.25(Reef).

Post hoc results: Stream - Estuary, p = 0.0020; Estuary - Reef, p = 0.0016; Stream - Reef, p < 0.001

## Lambda

```{r Lambda, include=FALSE}

### Data Exploration - boxplots and pairplots

boxplot(Lambda ~ Group_3f, data = mastered) # Boxplot by region. Fixed effect.
boxplot(Lambda ~ Environment, data = mastered) # Boxplot by environment. Fixed effect.
boxplot(Lambda ~ LTER_Site, data = mastered) # Boxplot by sampling site. Random effect.
boxplot(Lambda ~ Group, data = mastered) # Boxplot by sampling site. Random effect.

# So, based on boxplots and Sigma model, I move forward with Group_3f (region) and Environment as fixed variables and Group (date sampled) and Site as random NESTED variables.

lambda <- mastered %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Group, Lambda) %>%
  na.omit # remove NAs and create new dataset.

lambda$Environment <- factor(lambda$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(lambda$Lambda, groups = lambda$LTER_Site) # Lambda versus Site on left from original dataset.
par(op) # Looking ok, but we're trying to keep outlier removal to a minimum, so moving on...

pairs(lambda) # Quick pairs plot to check correllated variables. Trends look similar to Sigma 8, and I think I'm on the right path with the fixed/random variables I've chosen.

#### STEP 1: Create a linear regression and check residuals.

# Since the lambda data is normalized to organic carbon content, these values are much more normally distributed than the Sigma8 data. So, I've chosen not to transform the data in any way.

# Response variables - Lambda
# Explanatory variables - Group_3f, Environment

b1 <- lm(Lambda ~ Group_3f + Environment, data = lambda) # Creates the initial linear model.
rb1 <- rstandard(b1) # Assigns standardized residuals to rb1.
plot(rb1 ~ lambda$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # There looks like there's very little within site correlation, so that will be interesting when it comes time to decide on a random structure.

plot(rb1 ~ lambda$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Took a look at date sampled, and it looks similar to site, so I will move forward with only site as part of the random structure (need to account for repeat sampling in some way still).

#### STEP 2: Fit the lm() with GLS and compare to lme().

b2 <- gls(Lambda ~ Group_3f + Environment, data = lambda) # This is effectively a linear regression since it has no additional calls.
b3 <- lme(Lambda ~ Group_3f + Environment, 
          random =~1 | LTER_Site, data = lambda) # Creates the first LMEM with random term.
anova(b2, b3) # Compares the two models. b3 preferred based on AIC value of 1110.23.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(b3, col=1) # Plots residuals before immediately applying variance transformation.

# Looks like we should add in the varIden() variance structure for the observations in different Ecosystem Types. I am also advocating for this to hopefully address the remaining outlier in this data.

b4 <- lme(Lambda ~ Group_3f + Environment, 
          random =~1 | LTER_Site, data = lambda, 
          weights = varIdent(form =~1 | Environment)) # Allowing for different variance by Ecosystem.

anova(b3, b4) # Compares both models. b4 is better based on an AIC value of 1075.53.

plot(b4, col=1) # Residuals looking better.

# STEP 4: Fit the lme().

# Using b4 <- lme(Lambda ~ Group_3f + Environment, random =~1 | LTER_Site, data = lambda, weights = varIdent(form =~1 | Environment))

# STEP 5: Compare the lm() and lme().

anova(b2, b4) # 4 definitely outperforms 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

b4_ml <- lme(Lambda ~ Group_3f + Environment, 
             random =~1 | LTER_Site, method = "ML", data = lambda, 
             weights = varIdent(form =~1 | Environment)) # Creates model using ML structure.

b5 <- lme(Lambda ~ Environment, 
          random =~1 | LTER_Site, method = "ML", data = lambda, 
          weights = varIdent(form =~1 | Environment)) # Removes region.

b6 <- lme(Lambda ~ Group_3f, 
          random =~1 | LTER_Site, method = "ML", data = lambda, 
          weights = varIdent(form =~1 | Environment)) # Removes ecosystem.

anova(b4_ml, b5, b6) # Compares all three models. b5 is preferred with AIC value of 1063.45. So, we take out region.

b5full <- lme(Lambda ~ Environment, 
              random =~1 | LTER_Site, method = "ML", data = lambda, 
              weights = varIdent(form =~1 | Environment))

b5sub1 <- update(b5full, .~. -Environment) # Removes only term. Just checking...

anova(b5full, b5sub1) # First term needs to be in there.

# b5full is the final full model!!!

# STEP 9: Refit with REML

bfinal <- lme(Lambda ~ Environment, 
              random =~1 | LTER_Site, method = "REML", data = lambda, 
              weights = varIdent(form =~1 | Environment))

# Output of the model.
summary(bfinal)
plot(bfinal, col=1) # Checking residuals.
qqnorm(bfinal) # A little curvy, but ok.
qqnorm(bfinal, ~ranef (.), col = 1) # Good enough.
intervals(bfinal) # Show intervals.

# Final results.
anova(bfinal)

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of ecosystem type (stream, estuarine, marine) on lambda concentrations of a given sediment sample. fGroup_3 (region sampled) was not included in the model due to variable selection using AIC values. A random intercept by site was added, and variance was treated as varying by Ecosystem Type.

# Equation: Lambda = 2.13 + 0.03[Estuary] - 1.07[Reef] + random + variance

# BONUS : Tukey's HSD Post Hoc
bHSD <- glht(bfinal, linfct=mcp(Environment="Tukey"))

summary(bHSD) # No significant difference between Stream & Estuarine samples.

# Quick stats calculation of Lambda values by environment for the manuscript:

lammeans <- lambda %>%
  group_by(Environment) %>%
  summarize(meanLam = mean(Lambda, na.rm = TRUE), sdLam = sd(Lambda, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : Lambda ~ Environment + 1|LTER_Site + varIdent(Environment)

This translated to a formula of Lambda = 2.13 + 0.03(Estuary) - 1.07(Reef).

Post hoc results: Stream - Estuary, p = 0.994 (NS); Estuary - Reef, p < 0.0001; Stream - Reef, p < 0.0001.

## S/V

```{r S/V, include=FALSE}

### Data Exploration

boxplot(S.V ~ Group_3f, data = mastered) # Boxplot by region. Fixed effect.
boxplot(S.V ~ Environment, data = mastered) # Boxplot by environment. Fixed effect.
boxplot(S.V ~ LTER_Site, data = mastered) # Boxplot by site. Random effect.
boxplot(S.V ~ Group, data = mastered) # Boxplot by date. Random effect.

# So, based on boxplots and Sigma model, I move forward with Group_3f (region) and Environment as fixed variables and Group (date sampled) and Site as random NESTED variables.

sv <- mastered %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Group, S.V) %>%
  na.omit # remove NAs and create new dataset.

sv$Environment <- factor(sv$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(sv$S.V, groups = sv$LTER_Site) # S/V versus Site.
par(op) # Looking ok.

pairs(sv) # Quick pairs plot to check correllated variables. Yep, variable choices still look good.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - S/V
# Explanatory variables - Group_3f, Environment

c1 <- lm(S.V ~ Group_3f + Environment, data = sv) # Creates the linear model.
rc1 <- rstandard(c1) # Assigns standardized residuals to rc1.

plot(rc1 ~ sv$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Some within site correlation, so it will definitely be part of a random structure.

plot(rc1 ~ sv$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not quite as extreme as Site, but I still want to include it in my random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

c2 <- gls(S.V ~ Group_3f + Environment, data = sv) # Linear regression.
c3 <- lme(S.V ~ Group_3f + Environment, 
          random =~1 | LTER_Site / Group, data = sv) # Creates the first LMEM with random term.
anova(c2, c3) # Compares the two models. c3 preferred with AIC value of 1550.227.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

c4 <- lme(S.V ~ Group_3f + Environment, random =~1 | Group, data = sv) # Remove Site from random term.
c5 <- lme(S.V ~ Group_3f + Environment, random =~1 | LTER_Site, data = sv) # Remove Date sampled from random term.

anova(c3, c4, c5) # Compares all three models. c3 is still preferred with AIC value of 1517.886.

plot(c3, col=1) # Plots residuals before immediately applying variance transformation. I don't think we need an additional variance structure here.

# STEP 4: Fit the lme().

# Using c3 <- lme(S.V ~ Group_3f + Environment, random =~1 | LTER_Site / Group, data = sv)

# STEP 5: Compare the lm() and lme().

anova(c2, c3) # 3 definitely outperforms 2.

# STEP 6: Everything ok? Check residuals.

plot(c3, col=1) # Residuals look pretty good.
qqnorm(c3) # Looks a little curvy, but not terrible.

# STEP 7/8: Step-wise Optimal Fixed Structure

c3_ml <- lme(S.V ~ Group_3f + Environment, 
             random =~1 | LTER_Site / Group, method = "ML", data = sv) # Creates current model using ML structure.
c6 <- lme(S.V ~ Environment, 
          random =~1 | LTER_Site / Group, method = "ML", data = sv) # Removes region.
c7 <- lme(S.V ~ Group_3f, 
          random =~1 | LTER_Site / Group, method = "ML", data = sv) # Removes ecosystem.
anova(c3_ml, c6, c7) # Compares all three models. c6 preferred with AIC value of 1511.511. So remove region.

c6full <- lme(S.V ~ Environment, 
              random =~1 | LTER_Site / Group, method = "ML", data = sv)
c6sub1 <- update(c6full, .~. -Environment) # Just checking...
anova(c6full, c6sub1) # c6sub1 preferred, with AIC value of 1510.745, but I'm going to keep Environment in to have a structure of comparison.
# c6full is the final full model!!!

# STEP 9: Refit with REML

cfinal <- lme(S.V ~ Environment, 
              random =~1 | LTER_Site / Group, method = "REML", data = sv)

# Output of the model.
summary(cfinal)
plot(cfinal, col=1) # Checking residuals.
qqnorm(cfinal) # I'll take it.
#qqnorm(cfinal, ~ranef (.), col = 1) # Plot of random effect residuals not working, but residuals of the general model look good, so I'm going to go ahead with it.
intervals(cfinal) # Show intervals.

# Final results.
anova(cfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of either ecosystem type (stream, estuarine, marine) or Region (west to east) on S/V signatures of a given sediment sample. Random nested intercepts by date sampled and site were included.

# Equation: S/V = 2.45 + 0.26[Estuary] + 0.56[Reef] + random

# BONUS : Tukey's HSD Post Hoc
cHSD <- glht(cfinal, linfct=mcp(Environment="Tukey"))
summary(cHSD) # No significant difference between any samples by environment.

# Value calculations for manuscript:

svmeans <- mastered %>% # Takes the original dataset and then ...
  group_by(Environment) %>%     # Groups data and then ...
  summarize(meanSV = mean(S.V, na.rm = TRUE), sdSV = sd(S.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : S.V ~ Environment + 1|LTER_Site / Group

This translated to a formula of S/V = 2.45 + 0.26[Estuary] + 0.56[Reef] + random.

Post hoc results: All Environment comparisons, p > 0.05 (NS).

## C/V

```{r C/V, include=FALSE}

### Data Exploration

boxplot(C.V ~ Group_3f, data = mastered) # Regional boxplot. Fixed effect.
boxplot(C.V ~ Environment, data = mastered) # Environmental boxplot. Fixed effect.
boxplot(C.V ~ LTER_Site, data = mastered) # Site boxplot. Random effect.
boxplot(C.V ~ Group, data = mastered) # Date boxplot. Fixed + random effect?

# So, based on boxplots and Sigma model, I move forward with Group_3 (region), Environment, and Group (date sampled) as fixed variables and Group (date sampled) and Site as random NESTED variables, as with S/V.

cv <- mastered %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Group, C.V) %>%
  na.omit # Create new dataset.

cv$Environment <- factor(cv$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(cv$C.V, groups = cv$LTER_Site) # C/V versus Site on left from original dataset.
par(op) # Ok, leaving this for now, and we'll see how the residuals look.

pairs(cv) # Quick pairs plot to check correllated variables. Yep, variable choices still look good. It really looks like there's a trend across time in C.V (suggesting fresher material), but we can't use Group because I think it's too correlated with Environment still.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - C/V
# Explanatory variables - Group_3f, Environment

d1 <- lm(C.V ~ Group_3f + Environment, data = cv) # Initial linear model.
rd1 <- rstandard(d1) # Assigns standardized residuals to rd1.

plot(rd1 ~ cv$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Some within site correlation, so it will definitely be part of a random structure.

plot(rd1 ~ cv$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Some within sampling date correlation, so it will also be in random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

d2 <- gls(C.V ~ Group_3f + Environment, data = cv) # Linear regression.
d3 <- lme(C.V ~ Group_3f + Environment, 
          random =~1 | LTER_Site / Group, data = cv) # Creates the first LMEM with random term.
anova(d2, d3) # Compares the two models. d3 preferred with AIC value of -711.45.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

d4 <- lme(C.V ~ Group_3f + Environment, 
          random =~1 | Group, data = cv) # Remove Site from random term.
d5 <- lme(C.V ~ Group_3f + Environment, 
          random =~1 | LTER_Site, data = cv) # Remove Date sampled from random term.
anova(d3, d4, d5) # Compares all three models. d3 is still preferred.

plot(d3, col=1) # Plots residuals before immediately applying variance transformation. We need an additional variance structure.

# Looks like we should add in the varIden() variance structure for the observations in different Ecosystem Types.

d6 <- lme(C.V ~ Group_3f + Environment, 
          random =~1 | LTER_Site / Group, data = cv, 
          weights = varIdent(form =~1 | Environment)) # Adding in a variance structure to allow for different variance by ecosystem.
anova(d3, d6) # Compares both models. d6 is better with AIC value of -746.236.

plot(d6, col=1) # Residuals honestly don't look that different.

# I tried this same varident() form with different variances by date, but the "iteration limit reached without convergence" so for simplicity's sake, I'm going to move forward without the additional variance structure.

# STEP 4: Fit the lme().

# Using d3 <- lme(C.V ~ Group_3f + Environment, random =~1 | LTER_Site / Group, data = cv)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(d3, col=1) # A little trendy <0.1, but I'm going to leave it.
qqnorm(d3) # Looks pretty curvy. But I'm going to move forward without a log-transformation.

# STEP 7/8: Step-wise Optimal Fixed Structure

d3_ml <- lme(C.V ~ Group_3f + Environment, 
             random =~1 | LTER_Site / Group, method = "ML", data = cv) # Creates current model using ML structure.
d7 <- lme(C.V ~ Environment, 
          random =~1 | LTER_Site / Group, method = "ML", data = cv) # Removes region.
d8 <- lme(C.V ~ Group_3f, 
          random =~1 | LTER_Site / Group, method = "ML", data = cv) # Removes ecosystem.
anova(d3_ml, d7, d8) # Compares all three models. d7 is preferred with AIC value of -742.7207. So, I will remove region.

d7full <- lme(C.V ~ Environment, 
              random =~1 | LTER_Site / Group, method = "ML", data = cv)
d7sub1 <- update(d7full, .~. -Environment) # Is Environment necessary?
anova(d7full, d7sub1) # d7full is preferred with an AIC value of -742.7207 so yes!
# d7full is the final full model!!!

# STEP 9: Refit with REML

dfinal <- lme(C.V ~ Environment, 
              random =~1 | LTER_Site / Group, method = "REML", data = cv) # Yay!! 

# Output of the model.
summary(dfinal)
plot(dfinal, col=1) # Checking residuals.
qqnorm(dfinal) # I'll take it.
#qqnorm(dfinal, ~ranef (.), col = 1) # Plot of random effect residuals not working, but residuals of the general model look good, so I'm going to go ahead with it.
intervals(dfinal) # Show intervals.

# Final results.
anova(dfinal) # Output for the paper

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of ecosystem type (stream, estuarine, marine) but not Region (west to east) on C/V signatures of a given sediment sample. Date appeared as if it could be significant, but I was unable to test *both* environment and date simultaneously. So, I settled with focusing on environment given that it was significant for other full dataset measure analyses. Random nested intercepts by date sampled and site were included.

# Equation: C/V = 0.27 + 0.06[Estuary] - 0.17[Reef] + random

# BONUS : Tukey's HSD Post Hoc
dHSD <- glht(dfinal, linfct=mcp(Environment="Tukey"))
summary(dHSD) # No significant difference between Stream & Estuary, but significant between Stream & Reef (p<0.0001) and Estuary & Reef (p<0.0001).

# Value calculations for manuscript:

cvmeans <- mastered %>% # Takes the original dataset and then ...
  group_by(Environment) %>%     # Groups data and then ...
  summarize(meanCV = mean(C.V, na.rm = TRUE), sdCV = sd(C.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : C.V ~ Environment + 1|LTER_Site / Group

This translated to a formula of C/V = 0.27 + 0.07[Estuary] - 0.17[Reef] + random.

Post hoc results: Stream - Estuary, p = 0.241 (NS); Stream - Reef, p < 0.0001; Estuary - Reef, p < 0.0001.

##P/V+S

```{r P/V+S, include=FALSE}

### Data Exploration

boxplot(P..V.S. ~ Group_3f, data = mastered) # Regional boxplot. Fixed effect
boxplot(P..V.S. ~ Environment, data = mastered) # Environment boxplot. Fixed effect.
boxplot(P..V.S. ~ LTER_Site, data = mastered) # Site boxplot. Random effect.
boxplot(P..V.S. ~ Group, data = mastered) # Sampling date boxplot. Random effect. Again, looks like there may be a temporal trend, but I am going to focus on differentiating between environments for now, since I do not feel I can do both.

# So, based on boxplots, I move forward with Group_3f (region) and Environment as fixed variables and Group (date sampled) and Site as random NESTED variables.

pvs <- mastered %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Group, P..V.S.) %>%
  na.omit # Create new dataset.

pvs$Environment <- factor(pvs$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(pvs$P..V.S., groups = pvs$LTER_Site) # P/V+S versus Site.
par(op) # Looking ok - I think I'm going to log transform since I'm not taking out any more outliers.

pvs$logPVS <- log10(pvs$P..V.S.) # Makes log-transformed column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(pvs$P..V.S., groups = pvs$LTER_Site) # P/V+S versus Site on left from created dataset.
dotchart(pvs$logPVS, groups = pvs$LTER_Site) # log(P/V+S) versus Site on right from created dataset.
par(op) # Looking way better!!

pairs(pvs) # Quick pairs plot to check correllated variables. Yep, variable choices still look good. Again, looks like there's a trend in time...I'm making the executive decision to focus on investigating between environmental differences for the entire dataset. I will drill down into temporal changes in future models.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - P/V+S
# Explanatory variables - Group_3f, Environment

e1 <- lm(logPVS ~ Group_3f + Environment, data = pvs) # Creates the initial linear model.
re1 <- rstandard(e1) # Assigns standardized residuals to e.j.

plot(re1 ~ pvs$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Removing from random structure.

plot(re1 ~ pvs$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Including it in my random structure. Again seeing this trend.

#### STEP 2: Fit the lm() with GLS and compare to lme().

e2 <- gls(logPVS ~ Group_3f + Environment, data = pvs) # Linear regression.
e3 <- lme(logPVS ~ Group_3f + Environment, 
          random =~1 | Group, data = pvs) # Creates the first LMEM with random term.
anova(e2, e3) # Compares the two models. e3 preferred with an AIC value of 105.2018.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(e3, col=1) # Plots residuals before immediately applying variance transformation.

e4 <- lme(logPVS ~ Group_3f + Environment, 
          random =~1 | Group, data = pvs,
          weights = varIdent(form =~1 | Environment)) # Adding in a variance structure to allow for different variance by ecosystem - based on boxplots.

anova(e3, e4) # Compares models. e4 is preferred based on AIC value of 79.24088.

plot(e4, col=1) # Made the slightest difference in residuals.

# I'm going back to the simpler structure of e3.

# STEP 4: Fit the lme().

# Using e3 <- lme(logPVS ~ Group_3f + Environment, random =~1 | Group, data = pvs)

# STEP 5: Compare the lm() and lme().

# See Step #2.

# STEP 6: Everything ok? Check residuals.

plot(e3, col=1) # Residuals look pretty good.
qqnorm(e3) # Looks really quite good!

# STEP 7/8: Step-wise Optimal Fixed Structure

e3_ml <- lme(logPVS ~ Group_3f + Environment, 
             random =~1 | Group, method = "ML", data = pvs) # Creates model using ML structure.
e5 <- lme(logPVS ~ Environment, 
          random =~1 | Group, method = "ML", data = pvs) # Removes region.
e6 <- lme(logPVS ~ Group_3f, 
          random =~1 | Group, method = "ML", data = pvs) # Removes ecosystem.
anova(e3_ml, e5, e6) # Compares all three models. e6 is slightly preferred with an AIC value of 84. 97723. So, remove Environment.

e6full <- lme(logPVS ~ Group_3f, 
              random =~1 | Group, method = "ML", data = pvs)
e6sub1 <- update(e6full, .~. -Group_3f) # Just checking...
anova(e6full, e6sub1) # So removing both fixed variables, e6sub1, is preferred with an AIC value of 81.95200.

#To stick with our "Environment" as a fixed effect theme, I'm going to use e5 going forward.

# STEP 9: Refit with REML

efinal <- lme(logPVS ~ Environment, 
              random = ~1 | Group, method = "REML", data = pvs)

# Output of the model.
summary(efinal)
plot(efinal, col=1) # Checking residuals.
qqnorm(efinal) # I'll take it.
qqnorm(efinal, ~ranef (.), col = 1) # I'm going to go ahead with it.
intervals(efinal) # Show intervals.

# Final results.
anova(efinal) # Output for the paper

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of either ecosystem type (stream, estuarine, marine) or Region (west to east) on P/V+S signatures of a given sediment sample. Random nested intercepts by date sampled.

# Equation: log(P/V+S) = -0.76 - 0.15[Estuary] - 0.07[Reef] + random

# BONUS : Tukey's HSD Post Hoc

# NA.

# Value calculations for manuscript:

pvsmeans <- mastered %>% # Takes the original dataset and then ...
  group_by(Environment) %>%     # Groups data and then ...
  summarize(meanPVS = mean(P..V.S., na.rm = TRUE), sdPVS = sd(P..V.S., na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : log(PVS) ~ Environment + 1|Group

This translated to a formula of P/V+S = -0.76 - 0.15[Estuary] - 0.07[Reef] + random.

Post hoc results: NA.

##3,5Bd/V

```{r 35Bd/V, include=FALSE}

### Data Exploration

boxplot(Bd.V ~ Group_3f, data = mastered) # Regional boxplot. Fixed effect.
boxplot(Bd.V ~ Environment, data = mastered) # Environmental boxplot. Fixed effect.
boxplot(Bd.V ~ LTER_Site, data = mastered) # Site boxplot. Random effect.
boxplot(Bd.V ~ Group, data = mastered) # Date boxplot. Random effect.

# So, based on boxplots, I move forward with Group_3f (region) and Environment as fixed variables and Group (date sampled) and Site as random NESTED variables.

bdv <- mastered %>%
  dplyr::select(Group_3f, Environment, LTER_Site, Group, Bd.V) %>%
  na.omit # Creates a final dataset with no outliers or NAs. 

bdv$Environment <- factor(bdv$Environment, levels = c("Stream", "Estuary", "Reef")) # Puts stream first.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(bdv$Bd.V, groups = bdv$LTER_Site) # Bd/V versus Site on left from original dataset.
par(op) # Looking ok - I think I'm going to log transform again.

bdv$logBDV <- log10(bdv$Bd.V) # Makes log-transformed column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(bdv$Bd.V, groups = bdv$LTER_Site) # Bd/V versus Site on left from created dataset.
dotchart(bdv$logBDV, groups = bdv$LTER_Site) # log(Bd/V) versus Site on right from created dataset.
par(op) # Looking way better!!

pairs(bdv) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - 3,5-Bd/V
# Explanatory variables - Group_3f, Environment

f1 <- lm(logBDV ~ Group_3f + Environment, data = bdv) # Creates the initial linear model with both fixed variables.
rf1 <- rstandard(f1) # Assigns standardized residuals to rf1.
plot(rf1 ~ bdv$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Keeping it as part of a random structure.

plot(rf1 ~ bdv$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not quite as extreme as Site, but I still want to include it in my random structure. This will probably come out...

#### STEP 2: Fit the lm() with GLS and compare to lme().

f2 <- gls(logBDV ~ Group_3f + Environment, data = bdv) # Linear regression.
f3 <- lme(logBDV ~ Group_3f + Environment, 
          random =~1 | LTER_Site / Group, data = bdv) # Creates the first LMEM.
anova(f2, f3) # Compares the two models. f3 preferred with AIC value of 165.1639.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

f4 <- lme(logBDV ~ Group_3f + Environment, 
          random =~1 | Group, data = bdv) # Remove Site from random term.
f5 <- lme(logBDV ~ Group_3f + Environment, 
          random =~1 | LTER_Site, data = bdv) # Remove Date sampled from random term.
anova(f3, f4, f5) # Compares all three models. f3 is preferred, so keep random term as is.

plot(f3, col=1) # Plots residuals before immediately applying variance transformation. I don't think we need an additional variance structure.

# STEP 4: Fit the lme().

# Using f3 <- lme(logBDV ~ Group_3f + Environment, random =~1 | LTER_Site / Group, data = bdv)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(f3, col=1) # Residuals look good.
qqnorm(f3) # Looks good!!

# STEP 7/8: Step-wise Optimal Fixed Structure

f3_ml <- lme(logBDV ~ Group_3f + Environment, 
             random =~1 | LTER_Site / Group, method = "ML", data = bdv) # Creates current model using ML structure.
f6 <- lme(logBDV ~ Environment, 
          random =~1 | LTER_Site / Group, method = "ML", data = bdv) # Removes region.
f7 <- lme(logBDV ~ Group_3f, 
          random =~1 | LTER_Site / Group, method = "ML", data = bdv) # Removes ecosystem.
anova(f3_ml, f6, f7) # Compares all three models. f6 is preferred with an AIC value of 143.6322. So, remove Region.

f6full <- lme(logBDV ~ Environment, 
              random =~1 | LTER_Site / Group, method = "ML", data = bdv)
f6sub1 <- update(f6full, .~. -Environment) # Just checking...
anova(f6full, f6sub1) # So keep Environment. f6full has an AIC value of 143.6322.

# STEP 9: Refit with REML

ffinal <- lme(logBDV ~ Environment, 
              random =~1 | LTER_Site / Group, method = "REML", data = bdv) # Final full model.

# Output of the model.
summary(ffinal)
plot(ffinal, col=1) # Checking residuals.
qqnorm(ffinal) # I'll take it.
intervals(ffinal) # Show intervals.

# Final results.
anova(ffinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of ecosystem type (stream, estuarine, marine) on 3,5-Bd/V signatures of a given sediment sample. Random nested intercepts by date sampled and site were also included.

# Equation: log(3,5-Bd/V) = -0.77 + 0.009[Estuary] + 0.40[Reef] + random

# BONUS : Tukey's HSD Post Hoc
fHSD <- glht(ffinal, linfct=mcp(Environment="Tukey"))
summary(fHSD) # Significantly different (p<0.0001): Stream & Reef and Estuary & Reef

# Value calculations for manuscript:

bdvmeans <- mastered %>% # Takes the original dataset and then ...
  group_by(Environment) %>%     # Groups data and then ...
  summarize(meanBdv = mean(Bd.V, na.rm = TRUE), sdBdv = sd(Bd.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : log(PVS) ~ Environment + 1|LTER_Site / Group

This translated to a formula of log(P/V+S) = -0.77 + 0.009[Estuary] + 0.40[Reef] + random.

Post hoc results: Stream - Estuary, p = 0.996 (NS); Stream - Reef, p < 0.0001; Estuary - Reef, p < 0.0001.

#Stream Data

```{r stream data, include=FALSE}

stream <- read.csv("stream_only_ed.csv") # This imports a stream-data only dataset with watershed characteristics added in (watershed area, land cover, etc.)

streamed <- stream[ -2, ]# Removes the necessary outliers.

```

##Sigma 8 (stream)

```{r Sigma stream, include=FALSE}

### Data Exploration

sigstream <- streamed %>%
  dplyr::select(LTER_Site, Area, Land_Cover, Group, Sigma8) %>%
  na.omit # Create new dataset. Not testing region any longer since I've decided it's arbitrary.

boxplot(Sigma8 ~ LTER_Site, data = sigstream) # Site boxplot. Random effect.
boxplot(Sigma8 ~ Group, data = sigstream) # Date boxplot. Fixed effect.
boxplot(Sigma8 ~ Area, data = sigstream) # Watershed area boxplot. Fixed effect?
boxplot(Sigma8 ~ Land_Cover, data = sigstream) # Land cover boxplot. Fixed effect.

pairs(sigstream) # Pairs plot. So, I'm going to investigate all three as fixed effects at first, but Site should go in as a random effect too.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - Sigma8
# Explanatory variables - Group, Land_Cover, Watershed Area

g1 <- lm(Sigma8 ~ Group + Land_Cover + Area, data = sigstream) # Creates the initial linear model with all fixed variables.
rg1 <- rstandard(g1) # Assigns standardized residuals to rg1.

plot(rg1 ~ sigstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Site WILL be used as a random effect.

plot(rg1 ~ sigstream$Group, xlab = "Date",
     ylab = "Standardised residuals") 
abline(0,0) # Group looks all about zero, so removing as a random effect.

plot(rg1 ~ sigstream$Area, xlab = "Watershed Size",
     ylab = "Standardised residuals") 
abline(0,0) # Watershed size looks all about zero.

plot(rg1 ~ sigstream$Land_Cover, xlab = "Land Use",
     ylab = "Standardised residuals") 
abline(0,0) # Same here.

#### STEP 2: Fit the lm() with GLS and compare to lme().

g2 <- gls(Sigma8 ~ Group + Land_Cover + Area, data = sigstream)

g3 <- lme(Sigma8 ~ Group + Land_Cover + Area, 
          random =~1 | LTER_Site, data = sigstream) # Creates the first LMEM.

anova(g2, g3) # Compares the two models. g3 preferred with AIC of 122.1638.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(g3, col=1) # Check the residuals.
qqnorm(g3) # This is ok...

# No additional variance structure necessary.

# STEP 4: Fit the lme().

# Using g3 <- lme(Sigma8 ~ Group + Land_Cover + Area, random =~1 | LTER_Site, data = sigstream)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

g3_ml <- lme(Sigma8 ~ Group + Land_Cover + Area, 
             random =~1 | LTER_Site, method = "ML", data = sigstream)
# Need to switch over to ML for the fixed component editing portion.

g3sub1 <- update(g3_ml, .~. -Group) # Removes Group.
g3sub2 <- update(g3_ml, .~. -Land_Cover) # Removes Land_Cover.
g3sub3 <- update(g3_ml, .~. -Area) # Removes Area.

anova(g3_ml, g3sub1, g3sub2, g3sub3) # Compare the models. sub3 preferred with and AIC value of 130.9081, so remove Area.

g4 <- lme(Sigma8 ~ Group + Land_Cover, 
          random =~1 | LTER_Site, method = "ML", data = sigstream)

g4sub1 <- update(g4, .~. -Group) # Removes Group.
g4sub2 <- update(g4, .~. -Land_Cover) # Removes Land_Cover.

anova(g4, g4sub1, g4sub2) # Compares the models. g4 preferred with an AIC value of 130.9081, so keep them both in.

g4full <- lme(Sigma8 ~ Group + Land_Cover, 
              random =~1 | LTER_Site, method = "ML", data = sigstream) # the final full model!!!

# STEP 9: Refit with REML

gfinal <- lme(Sigma8 ~ Group + Land_Cover, 
              random =~1 | LTER_Site, method = "REML", data = sigstream)

# Output of the model.
summary(gfinal)

# Checking residuals.
plot(gfinal, col=1) # No pattern.
qqnorm(gfinal) # This makes me feel pretty good.
intervals(gfinal) # Show intervals.

# Final results.
anova(gfinal)

# STEP 10: What does this mean in WORDS?

# My model suggests there is NO significant effect of sampling date OR land use/cover on Sigma 8 concentrations of a given stream sediment sample.

# Equation: Sigma 8 = 2.59 + 1.91[GroupC] + 3.39[GroupI] - 1.12[Undeveloped] + 3.09[Urban] + random

# POST HOC: NA


```

The final model took the form : Sigma ~ Group + Land_Cover + 1|LTER_Site

This translated to a formula of Sigma 8 = 2.59 + 1.91[GroupC] + 3.39[GroupI] - 1.12[Undeveloped] + 3.09[Urban] + random

Post hoc results: NA.

## Lambda (stream)

```{r Lambda stream, include=FALSE}

### Data Exploration

lamstream <- streamed %>%
  dplyr::select(LTER_Site, Area, Land_Cover, Group, Lambda) %>%
  na.omit # Create new dataset.

boxplot(Lambda ~ LTER_Site, data = lamstream) # Site boxplot. Random effect.
boxplot(Lambda ~ Group, data = lamstream) # Date boxplot. Fixed effect.
boxplot(Lambda ~ Area, data = lamstream) # Watershed area boxplot. Fixed effect?
boxplot(Lambda ~ Land_Cover, data = lamstream) # Land cover boxplot. Fixed effect?

pairs(lamstream) # Pairs plot. So, I'm going to investigate all three as fixed effects at first, but Site should go in as a random effect too.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - Lambda
# Explanatory variables - Group, Land_Cover, Watershed Area

h1 <- lm(Lambda ~ Group + Land_Cover + Area, data = lamstream) # Initial linear model.
rh1 <- rstandard(h1) # Assigns standardized residuals to rh1.

plot(rh1 ~ lamstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Site WILL be used as a random effect.

#### STEP 2: Fit the lm() with GLS and compare to lme().

h2 <- gls(Lambda ~ Group + Land_Cover + Area, data = lamstream)

h3 <- lme(Lambda ~ Group + Land_Cover + Area, 
          random =~1 | LTER_Site, data = lamstream) # Creates the first LMEM.

anova(h2, h3) # Compares the two models. h2 preferred with an AIC value of 60.67366.

#### STEP 3: Decide on a variance structure (aka random terms).
# I'm deciding to keep a random term in to acknowledge the repeated measurement structure of the project design.

plot(h3, col=1) # Check the residuals.
qqnorm(h3) # This actually looks ok...

# Going to skip the extra variance structure.

# STEP 4: Fit the lme().

# Using h3 <- lme(Lambda ~ Group + Land_Cover + Area, random =~1 | LTER_Site, data = lamstream)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3. 

# STEP 7/8: Step-wise Optimal Fixed Structure

h3_ml <- lme(Lambda ~ Group + Land_Cover + Area, 
             random =~1 | LTER_Site, method = "ML", data = lamstream) # Need to switch over to ML for the fixed component editing portion.
h3sub1 <- update(h3_ml, .~. -Group) # Removes Group.
h3sub2 <- update(h3_ml, .~. -Land_Cover) # Removes Land_Cover.
h3sub3 <- update(h3_ml, .~. -Area) # Removes Area.

anova(h3_ml, h3sub1, h3sub2, h3sub3) # Compare the models. sub2 preferred with an AIC value of 49.25669, so remove Land Cover.

h4 <- lme(Lambda ~ Group + Area, 
          random =~1 | LTER_Site, method = "ML", data = lamstream)
h4sub1 <- update(h4, .~. -Group) # Removes Group.
h4sub2 <- update(h4, .~. -Area) # Removes Area.

anova(h4, h4sub1, h4sub2) # Compares the models. h4 preferred with an AIC value of 49.25669, so keep both terms in.

h4full <- lme(Lambda ~ Group + Area, 
              random =~1 | LTER_Site, method = "ML", data = lamstream)

# STEP 9: Refit with REML

hfinal <- lme(Lambda ~ Group + Area, 
              random =~1 | LTER_Site, method = "REML", data = lamstream)

# Output of the model.
summary(hfinal)

# Checking residuals.
plot(hfinal, col=1) # No pattern.
qqnorm(hfinal) # This looks good.

# Show intervals.
intervals(hfinal)
anova(hfinal)

# STEP 10: What does this mean in WORDS?

# My model suggests there is a significant effect of sampling date but not watershed size on Lambda concentrations of a given stream sediment sample.

# Equation: Lambda = 1.72 + 0.44[GroupC] + 1.87[GroupI] - 0.02[Area] + random

# BONUS POST HOC:

hHSD <- glht(hfinal, linfct=mcp(Group="Tukey"))
summary(hHSD) # Significant different between Jan 2016 and Jan 2017 (p < 0.0001) as well as March 2016 and Jan 2017 (p < 0.0001).

```

The final model took the form : Lambda ~ Group + Area + 1|LTER_Site

This translated to a formula of Lambda = 1.72 + 0.44[GroupC] + 1.87[GroupI] - 0.02[Area] + random

Post hoc results: Mar 16 (C) - Jan 16 (B), p = 0.253 (NS); Jan 17 (I) - Jan 16 (B), p < 0.0001; Jan 17 (I) - Mar 16 (C), p < 0.0001.

## S/V (stream)

```{r S/V stream, include=FALSE}

### Data Exploration

boxplot(S.V ~ LTER_Site, data = streamed) # Site boxplot. Random effect.
boxplot(S.V ~ Group, data = streamed) # Date boxplot. Fixed effect.
boxplot(S.V ~ Area, data = streamed) # Watershed area boxplot. Fixed effect.
boxplot(S.V ~ Land_Cover, data = streamed) # Land cover boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), Area and Land_Cover as fixed variables and Group (date sampled) and Site as random NESTED variables.

svstream <- streamed %>%
  dplyr::select(LTER_Site, Group, Area, Land_Cover, S.V) %>%
  na.omit # Create new dataset.

svstream$Land_Cover <- factor(svstream$Land_Cover, levels = c("UND", "AGR", "URB")) # Relevels the land cover categories.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(svstream$S.V, groups = svstream$LTER_Site) # S/V versus Site.
par(op) # Looking ok so no need to log-transform, and likely will not need an additional variance structure.

pairs(svstream) # Pairs plot. Yep, variable choices still look good.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - S/V
# Explanatory variables - Group, Area, Land_Cover

i1 <- lm(S.V ~ Group + Area + Land_Cover, data = svstream) # Initial linear model.
ri1 <- rstandard(i1) # Assigns standardized residuals to ri1.
plot(ri1 ~ svstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Some within site correlation, so keep in random structure.

plot(ri1 ~ svstream$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not quite as extreme , so taking it out of random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

i2 <- gls(S.V ~ Group + Area + Land_Cover, data = svstream) # Linear regression.
i3 <- lme(S.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = svstream) # First LMEM with random term.

anova(i2, i3) # Compares the two models. i2 preferred with AIC value of 65.11196. But, I want to keep the random term in to account for repeated measures' sake.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(i3, col=1) # Plots residuals before immediately applying variance transformation. Looks like we may still need one.

i4 <- lme(S.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = svstream,
          weights = varIdent(form =~1 | Group)) # Adds variance structure by date.

anova(i3, i4) # Compares models. i4 is best with an AIC value of 54.03685.

# STEP 4: Fit the lme().

# Using i4 <- lme(S.V ~ Group + Area + Land_Cover, random =~1 | LTER_Site, data = svstream, weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(i2, i4) # 4 definitely outperforms 2 with an AIC value of 54.03685.

# STEP 6: Everything ok? Check residuals.

plot(i4, col=1) # Residuals look pretty good.
qqnorm(i4) # Looks a little weird, but it's a small dataset.

# STEP 7/8: Step-wise Optimal Fixed Structure

i4_ml <- lme(S.V ~ Group + Area + Land_Cover, 
             random =~1 | LTER_Site, method = "ML", data = svstream, 
             weights = varIdent(form =~1 | Group)) # Creates ML structure model.
# Using the shorter syntax to save space since I've got so many variables.
i4sub1 <- update(i4_ml, .~. -Group) # Removes date sampled.
i4sub2 <- update(i4_ml, .~. -Area) # Removes watershed area.
i4sub3 <- update(i4_ml, .~. -Land_Cover) # Removes land use type.

anova(i4_ml, i4sub1, i4sub2, i4sub3) # Compares all models. i4sub3 preferred with an AIC value of 29.90527, so remove land cover.

i5 <- lme(S.V ~ Group + Area, 
          random =~1 | LTER_Site, method = "ML", data = svstream, 
          weights = varIdent(form =~1 | Group))

i5sub1 <- update(i5, .~. -Group) # Removes date sampled.
i5sub2 <- update(i5, .~. -Area) # Removes watershed area.

anova(i5, i5sub1, i5sub2) # Compares all models. i5 preferred with AIC value of 29.90527.

# i5 is the final full model!!!

# STEP 9: Refit with REML

ifinal <- lme(S.V ~ Group + Area, 
              random =~1 | LTER_Site, method = "REML", data = svstream, 
              weights = varIdent(form =~1 | Group)) # Yay!!

# Output of the model.
summary(ifinal)
plot(ifinal, col=1) # Checking residuals. Looking good!
qqnorm(ifinal) # Looks better than before - blippy at the start, but OK I think.
qqnorm(ifinal, ~ranef (.), col = 1) # Plot of random effect residuals looks good!
intervals(ifinal) # Show intervals.

# Final results.
anova(ifinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled and watershed area on stream S/V signatures. Random intercepts by site were included as well as a variance term for date.

# Equation: S/V = 1.49 + 1.41[GroupC] + 0.57[GroupI] + 0.013[Area] + random + variance

# BONUS : Tukey's HSD Post Hoc
iHSD <- glht(ifinal, linfct=mcp(Group="Tukey"))
summary(iHSD) # Significant different between B&C (p = 0.00143), B&I (p < 0.001), but not between C&I (p = 0.07674).

```

The final model took the form : S.V ~ Group + Area + 1|LTER_Site + 1|Group(var)

This translated to a formula of S/V = 1.49 + 1.41[GroupC] + 0.57[GroupI] + 0.013[Area] + random + variance.

Post hoc results: Jan16 & Mar16, p = 0.00143 ; Jan16 & Jan17, p < 0.001; Mar16 & Jan 17, p = 0.07674 (NS).

## C/V (stream)

```{r C/V stream, include=FALSE}

### Data Exploration.

boxplot(C.V ~ LTER_Site, data = streamed) # Site boxplot. Random effect.
boxplot(C.V ~ Group, data = streamed) # Date boxplot. Fixed effect.
boxplot(C.V ~ Area, data = streamed) # Watershed area boxplot. Fixed effect?
boxplot(C.V ~ Land_Cover, data = streamed) # Land cover boxplot. Fixed effect?

# So, based on boxplots, I move forward with Group (date sampled), Area and Land_Cover as fixed variables and Group and Site as random NESTED variables.

cvstream <- streamed %>%
  dplyr::select(LTER_Site, Group, Area, Land_Cover, C.V) %>%
  na.omit# Create new dataset.

cvstream$Land_Cover <- factor(cvstream$Land_Cover, levels = c("UND", "AGR", "URB")) # Relevels the land cover categories.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(cvstream$C.V, groups = cvstream$LTER_Site) # C/V versus Site.
par(op) # Looking very evenly dispersed.

pairs(cvstream) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - C/V
# Explanatory variables - Group, Area, Land_Cover

j1 <- lm(C.V ~ Group + Area + Land_Cover, data = cvstream) # Initial linear model.
rj1 <- rstandard(j1) # Assigns standardized residuals to rji.
plot(rj1 ~ cvstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Some within site correlation, so part of random structure.

plot(rj1 ~ cvstream$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not quite as extreme , so removing from my random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

j2 <- gls(C.V ~ Group + Area + Land_Cover, data = cvstream) # Linear regression.
j3 <- lme(C.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = cvstream) # First LMEM with random term.
anova(j2, j3) # Compares the two models. j2 preferred with AIC value of -1.6875. But, I want to keep the random term in to account for repeated measures' sake.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(j3, col=1) # Plots residuals before immediately applying variance transformation. I don't believe there is a variance term necessary.

# STEP 4: Fit the lme().

# Using j3 <- lme(C.V ~ Group + Area + Land_Cover, random =~1 | LTER_Site, data = cvstream)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(j3, col=1) # Residuals look pretty good save that one kind of outlier that I believe is inevitable given the small size of the dataset.
qqnorm(j3) # Looks a little weird, but likely due to same reasoning as above.

# STEP 7/8: Step-wise Optimal Fixed Structure

j3_ml <- lme(C.V ~ Group + Area + Land_Cover, 
             random =~1 | LTER_Site, method = "ML", data = cvstream) # ML model structure.

j3sub1 <- update(j3_ml, .~. -Group) # Removes date sampled.
j3sub2 <- update(j3_ml, .~. -Area) # Removes watershed area.
j3sub3 <- update(j3_ml, .~. -Land_Cover) # Removes land cover.
anova(j3_ml, j3sub1, j3sub2, j3sub3) # Compares all models. j3sub3 preferred with an AIC value of -34.85286, so remove land cover.

j4 <- lme(C.V ~ Group + Area, 
          random =~1 | LTER_Site, method = "ML", data = cvstream)

j4sub1 <- update(j4, .~. -Group) # Removes date sampled.
j4sub2 <- update(j4, .~. -Area) # Removes watershed area.
anova(j4, j4sub1, j4sub2) # Compares all models. j4sub2 preferred with an AIC value of -35.59545, so remove area.

j5 <- lme(C.V ~ Group, 
          random =~1 | LTER_Site, method = "ML", data = cvstream)

j5sub1 <- update(j5, .~. -Group) # Removes date sampled.

anova(j5, j5sub1) # Compares all models. j5 preferred with an AIC value of -35.59545.
# j5 is the final full model!!!

# STEP 9: Refit with REML

jfinal <- lme(C.V ~ Group, 
              random =~1 | LTER_Site, method = "REML", data = cvstream)

# Output of the model.
summary(jfinal)
plot(jfinal, col=1) # Checking residuals. Looking ok other than that one outlier!
qqnorm(jfinal) # Looks OK.
qqnorm(jfinal, ~ranef (.), col = 1) # Plot of random effect residuals looks good!
intervals(jfinal) # Show intervals.

# Final results.
anova(jfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled on stream C/V signatures. Random intercepts by site were included.

# Equation: C/V = 0.12 - 0.10[GroupC] + 0.08[GroupI] + random

# BONUS : Tukey's HSD Post Hoc
jHSD <- glht(jfinal, linfct=mcp(Group="Tukey"))
summary(jHSD) # Significant different between B&I (p = 0.0003), C&I (p = 0.0002), but not between B&C (p = 0.9978).

```

The final model took the form : C.V ~ Group + 1|LTER_Site

This translated to a formula of C/V = 0.12 - 0.10[GroupC] + 0.08[GroupI] + random.

Post hoc results: Jan16 & Mar16, p = 0.9978 (NS) ; Jan16 & Jan17, p = 0.0003; Mar16 & Jan 17, p = 0.0002.

## P/V+S (stream)

```{r P/V+S stream, include=FALSE}

### Data Exploration.

boxplot(P..V.S. ~ LTER_Site, data = streamed) # Site boxplot. Random effect.
boxplot(P..V.S. ~ Group, data = streamed) # Date boxplot. Fixed effect.
boxplot(P..V.S. ~ Area, data = streamed) # Area boxplot. Fixed effect?
boxplot(P..V.S. ~ Land_Cover, data = streamed) # Land cover boxplot. Fixed effect?

# So, based on boxplots, I move forward with Group (date sampled), Area and Land_Cover as fixed variables and Group and Site as random NESTED variables.

pvsstream <- streamed %>%
  dplyr::select(LTER_Site, Group, Area, Land_Cover, P..V.S.) %>%
  na.omit# Create new dataset.

pvsstream$Land_Cover <- factor(pvsstream$Land_Cover, levels = c("UND", "AGR", "URB")) # Relevels the land cover categories.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(pvsstream$P..V.S., groups = pvsstream$LTER_Site) # P/V+S versus Site.
par(op) # Looking good.

pairs(pvsstream) # Quick pairs plot to check correllated variables. Yep, variable choices still look good, and it looks like date is again going to drive the relationship here.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - P/V+S
# Explanatory variables - Group, Area, Land Cover

k1 <- lm(P..V.S. ~ Group + Area + Land_Cover, data = pvsstream) # Linear model.
rk1 <- rstandard(k1) # Assigns standardized residuals to rk1.

plot(rk1 ~ pvsstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # It will definitely be part of a random structure.

plot(rk1 ~ pvsstream$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Removing from random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

k2 <- gls(P..V.S. ~ Group + Area + Land_Cover, data = pvsstream) # Linear regression.
k3 <- lme(P..V.S. ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = pvsstream ) # First LMEM with random term.

anova(k2, k3) # Compares the two models. k2 preferred with an AIC value of -25.61488, but I'm keeping the random term in for repeated measures sake.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(k3, col=1) # Plots residuals before immediately applying variance transformation. I don't think we need an additional variance structure.

# STEP 4: Fit the lme().

# k3 <- lme(P..V.S. ~ Group + Area + Land_Cover, random =~1 | LTER_Site, data = pvsstream)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(k3, col=1) # Residuals look really quite good.
qqnorm(k3) # Looks fine.

# STEP 7/8: Step-wise Optimal Fixed Structure

k3_ml <- lme(P..V.S. ~ Group + Area + Land_Cover, 
             random =~1 | LTER_Site, method = "ML", data = pvsstream) # ML model structure.

k3sub1 <- update(k3_ml, .~. -Group) # Removes date.
k3sub2 <- update(k3_ml, .~. -Area) # Removes watershed area.
k3sub3 <- update(k3_ml, .~. -Land_Cover) # Removes land use.

anova(k3_ml, k3sub1, k3sub2, k3sub3) # Compares all models. k3sub2 is preferred with an AIC value of -68.42672. So, remove area.

k4 <- lme(P..V.S. ~ Group + Land_Cover, 
          random =~1 | LTER_Site, method = "ML", data = pvsstream)

k4sub1 <- update(k4, .~. -Group) # Removes date.
k4sub2 <- update(k4, .~. -Land_Cover) # Removes land use.

anova(k4, k4sub1, k4sub2) # k4sub2 preferred with AIC value of -69.13217; remove land use.

k5 <- lme(P..V.S. ~ Group, 
          random =~1 | LTER_Site, method = "ML", data = pvsstream)

k5sub1 <- update(k5, .~. -Group) # Just checking...

anova(k5, k5sub1) # k5 preferred with an AIC value of -69.13217, so keep Group in.

# STEP 9: Refit with REML

kfinal <- lme(P..V.S. ~ Group, 
              random =~1 | LTER_Site, method = "REML", data = pvsstream)

# Output of the model.
summary(kfinal)
plot(kfinal, col=1) # Checking residuals.They're fine.
qqnorm(kfinal) # Look pretty good considering low # of samples.
qqnorm(kfinal, ~ranef (.), col = 1) # Plot of random effect residuals, looks good.
intervals(kfinal) # Show intervals.

# Final results.
anova(kfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of region, watershed area, or land use on P/V+S signatures of a given sediment sample, but DATE has a significant effect. Random intercept by sample site was also included.

# Equation: P/V+S = 0.30 - 0.08[C] - 0.22[I] + random

# BONUS : Tukey's HSD Post Hoc
kHSD <- glht(kfinal, linfct=mcp(Group="Tukey"))
summary(kHSD) # All significantly different.

```

The final model took the form : P..V.S. ~ Group + 1|LTER_Site

This translated to a formula of P/V+S = 0.30 - 0.08[C] - 0.22[I] + random.

Post hoc results: Jan16 (B) & Mar16 (C), p = 0.0004 ; Jan16 (B) & Jan17 (I), p < 0.0001; Mar16 (C) & Jan 17 (I), p < 0.0001.

# 3,5Bd/V (stream)

```{r 35Bd/V stream, include=FALSE}

### Data Exploration 

boxplot(Bd.V ~ LTER_Site, data = streamed) # Site boxplot. Random effect.
boxplot(Bd.V ~ Group, data = streamed) # Date boxplot. Fixed effect.
boxplot(Bd.V ~ Area, data = streamed) # Watershed area. Fixed effect? These really look random, but I'm choosing to keep them in for reasoning purposes - it doesn't really make sense for them to be part of the random effect structure AND it was found to be significant in Lambda stream values so...
boxplot(Bd.V ~ Land_Cover, data = streamed) # Land cover boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), Area and Land_Cover as fixed variables and Group and Site as random NESTED variables.

bdvstream <- streamed %>%
  dplyr::select(LTER_Site, Group, Area, Land_Cover, Bd.V) %>%
  na.omit# Create new dataset.

bdvstream$Land_Cover <- factor(bdvstream$Land_Cover, levels = c("UND", "AGR", "URB")) # Relevels the land cover categories.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(bdvstream$Bd.V, groups = bdvstream$LTER_Site) # P/V+S versus Site.
par(op) # Looking ok. There's definitely an outlier, but I'm not taking any more out.

pairs(bdvstream) # Pairs plot. Variable choices look good, and land cover may play a role!

#### STEP 1: Create a linear regression and check residuals.

# Response variables - 3,5-Bd/V
# Explanatory variables - Group, Area, Land Cover

l1 <- lm(Bd.V ~ Group + Area + Land_Cover, data = bdvstream) # Initial linear model.
rl1 <- rstandard(l1) # Assigns standardized residuals to rl1.

plot(rl1 ~ bdvstream$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Within site correlation, so it will definitely be part of a random structure.

plot(rl1 ~ bdvstream$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Taking it out of my random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

l2 <- gls(Bd.V ~ Group + Area + Land_Cover, data = bdvstream) # Linear regression.
l3 <- lme(Bd.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site / Group, data = bdvstream ) # First LMEM with random term.

anova(l2, l3) # Compares the two models. l2 preferred with an AIC value of -18.67473, but I'm keeping the random term in for repeated measures sake.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(l3, col=1) # Plots residuals before immediately applying variance transformation. We definitely need a transformation, so I'll make it by date.

l4 <- lme(Bd.V ~ Group + Area + Land_Cover, 
          random =~1 | LTER_Site, data = bdvstream,
          weights = varIdent(form =~1 | Group))

anova(l3, l4) # Compares models. l4 is best with an AIC value of -15.35811.

# STEP 4: Fit the lme().

# Using l4 <- lme(Bd.V ~ Group + Area + Land_Cover, random =~1 | LTER_Site, data = bdvstream, weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(l2,l4) # l2 still preferred, but I'm keeping the random term in.

# STEP 6: Everything ok? Check residuals.

plot(l4, col=1) # Residuals look pretty good.
qqnorm(l4) # Looks GOOD.

# STEP 7/8: Step-wise Optimal Fixed Structure

l4_ml <- lme(Bd.V ~ Group + Area + Land_Cover, 
             random =~1 | LTER_Site, method = "ML", data = bdvstream,
             weights = varIdent(form =~1 | Group))  # ML model structure.

l4sub1 <- update(l4_ml, .~. -Group) # Removes date.
l4sub2 <- update(l4_ml, .~. -Area) # Removes watershed area.
l4sub3 <- update(l4_ml, .~. -Land_Cover) # Removes land use.

anova(l4_ml, l4sub1, l4sub2, l4sub3) # Compares all models. l4sub1 is preferred with an AIC value of -59.31871. So, remove sampling date.

l5 <- lme(Bd.V ~ Area + Land_Cover, 
          random =~1 | LTER_Site, method = "ML", data = bdvstream,
          weights = varIdent(form =~1 | Group))

l5sub1 <- update(l5, .~. -Area) # Removes watershed area.
l5sub2 <- update(l5, .~. -Land_Cover) # Removes land cover.

anova(l5, l5sub1, l5sub2) # l5sub1 preferred with an AIC value of -61.01911 - remove area.

l6 <- lme(Bd.V ~ Land_Cover, 
          random =~1 | LTER_Site, method = "ML", data = bdvstream,
          weights = varIdent(form =~1 | Group))

l6sub1 <- update(l6, .~. -Land_Cover) # Removes land cover.

anova(l6, l6sub1) # l6 preferred with AIC value of -61.01911. Keep it in.

# STEP 9: Refit with REML

lfinal <- lme(Bd.V ~ Land_Cover, 
              random =~1 | LTER_Site, method = "REML", data = bdvstream,
              weights = varIdent(form =~1 | Group))

# Output of the model.
summary(lfinal)
plot(lfinal, col=1) # Checking residuals.
qqnorm(lfinal) # Looks better than before.
qqnorm(lfinal, ~ranef (.), col = 1) # Plot of random effect residuals, looks ok.
#intervals(lfinal) # Show intervals.

# Final results.
anova(lfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of date sampled, watershed area, or land use on 3,5Bd/V signatures of a given sediment sample. A random intercept term by sample site and a variance term by sampling date were also included.

# Equation: 3,5Bd/V = 0.23 - 0.05[AGR] - 0.07[URB] + random + variance

```

The final model took the form : Bd.V ~ Land_Cover + 1|LTER_Site + varIdent(Group)

This translated to a formula of 3,5Bd/V = 0.23 - 0.05[AGR] - 0.07[URB] + random + variance.

Post hoc results: NA.

# Estuarine data

```{r estuarine data, include=FALSE}

# For the following code chunks, I'll use this same dataset since I've not added in any additional info like I did with the stream data.

estuary <- mastered %>%
  filter(mastered$Environment=="Estuary")

# Ok, but in the following code, unless I create a separate dataset, all of the stream/marine site levels, for example, will still be in there, which I don't want for modeling purposes. So I'm going to do the following:

#write.csv(estuary,"estuary.csv") # Export the data.
estuarine <- read.csv("estuary.csv") # Load the data back in.
#str(estuarine) # Check to make sure its in the format I want. Perfect!

```

## Sigma 8 (estuarine)

```{r Sigma estuary, include=FALSE}

### Data Exploration
# Not testing region since I've decided it's arbitrary.
boxplot(Sigma8 ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(Sigma8 ~ Group, data = estuarine) # Date boxplot. Fixed effect.
boxplot(Sigma8 ~ Core, data = estuarine) # Core section boxplot. Fixed effect?

# So, based on boxplots, I move forward with Site, Group (date sampled), and Core as fixed variables and Group and Site as random NESTED variables.

sigest <- estuarine %>%
  dplyr::select(LTER_Site, Group, Core, Sigma8) %>%
  na.omit# Create new dataset.

pairs(sigest) # Pairs plot. I'm going to investigate all three as fixed effects.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - Sigma8
# Explanatory variables - Site, Group, Core

m1 <- lm(Sigma8 ~ LTER_Site + Group + Core, data = sigest) # Initial linear model.
rm1 <- rstandard(m1) # Assigns standardized residuals to rm1.

plot(rm1 ~ sigest$LTER_Site, xlab = "Site",
       ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # This appears as if it may not be needed as a random effect. But I am still going to use it for replicate sampling's sake.

plot(rm1 ~ sigest$Group, xlab = "Date",
       ylab = "Standardised residuals") 
abline(0,0) # Group looks all about zero so removing from random term.

plot(rm1 ~ sigest$Core, xlab = "Core Section",
       ylab = "Standardised residuals") 
abline(0,0) # Section looks all about zero too. Yes, also taking it out.

#### STEP 2: Fit the lm() with GLS and compare to lme().

m2 <- gls(Sigma8 ~ LTER_Site + Group + Core, data = sigest)

m3 <- lme(Sigma8 ~ LTER_Site + Group + Core, 
          random =~1 | LTER_Site, data = sigest) # First LMEM.

anova(m2, m3) # Compares the two models. m2 is preferred with an AIC value of 246.2134, but I want to keep the random term in.

#### STEP 3: Decide on a variance structure (aka random terms).
# I'm deciding to keep a random term in to acknowledge the repeated measurement structure of the project design.

plot(m3, col=1) # Check the residuals.
qqnorm(m3) # Ok...skipping a variance term.

# STEP 4: Fit the lme().

# m3 <- lme(Sigma8 ~ LTER_Site + Group + Core, random =~1 | LTER_Site, data = sigest)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

m3_ml <- lme(Sigma8 ~ LTER_Site + Group + Core, 
          random =~1 | LTER_Site, method = "ML", data = sigest) # ML model.

m3sub1 <- update(m3_ml, .~. -LTER_Site) # Removes LTER_Site.
m3sub2 <- update(m3_ml, .~. -Group) # Removes Group.
m3sub3 <- update(m3_ml, .~. -Core) # Removes Core Section.

anova(m3_ml, m3sub1, m3sub2, m3sub3) # Compare the models. m3sub2 preferred with an AIC value of 252.3266, so remove Group.

m4 <- lme(Sigma8 ~ LTER_Site + Core, 
          random =~1 | LTER_Site, method = "ML", data = sigest)

m4sub1 <- update(m4, .~. -LTER_Site) # Removes Site.
m4sub2 <- update(m4, .~. -Core) # Removes Core Section.

anova(m4, m4sub1, m4sub2) # Compares the models. m4sub1 preferred with an AIC value of 250.3485, so take out Site.

m5 <- lme(Sigma8 ~ Core, 
          random =~1 | LTER_Site, method = "ML", data = sigest)

m5sub1 <- update(m5, .~. -Core) # Removes Core Section.

anova(m5, m5sub1) # Compares the models. m5sub1 preferred, so take out Core Section.

# no final full model!!!

# STOPPING HERE SINCE NOTHING IS SIGNIFICANT.

# STEP 10: What does this mean in WORDS?

# My model suggests there is NO significant effect of sampling date, section of core, or sampling site on Sigma 8 concentrations of a given estuarine sediment sample.

# Equation: NA

# BONUS POST HOC:

# NOT NECESSARY

```

The final model took the form : Sigma8 ~ NA

This translated to a formula of Sigma 8 = NA.

Post hoc results: NA.

##Lambda (estuarine)

```{r Lambda estuary, include=FALSE}

### Data Exploration

boxplot(Lambda ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect?
boxplot(Lambda ~ Group, data = estuarine) # Date boxplot. Fixed effect.
boxplot(Lambda ~ Core, data = estuarine) # Core section boxplot. Fixed effect.

lamest <- estuarine %>%
  dplyr::select(LTER_Site, Core, Group, Lambda) %>%
  na.omit # Creates new dataset.

pairs(lamest) # Pairs plot. Doesn't look like any of these will be significant...

#### STEP 1: Create a linear regression and check residuals.

# Response variables - Lambda
# Explanatory variables - Group, Site, Core

n1 <- lm(Lambda ~ Group + LTER_Site + Core, data = lamest) # Initial linear model.
rn1 <- rstandard(n1) # Assigns standardized residuals to rn1.
plot(rn1 ~ lamest$LTER_Site, xlab = "Site",
       ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # It doesn't appear to need to be a random effect, but I am going to use it for replicate sampling's sake.

plot(rn1 ~ lamest$Group, xlab = "Date",
       ylab = "Standardised residuals") 
abline(0,0) # Group looks all about zero. Not including in random effect term.

plot(rn1 ~ lamest$Core, xlab = "Core Section",
       ylab = "Standardised residuals") 
abline(0,0) # Section looks all about zero too so removing from random effect.

#### STEP 2: Fit the lm() with GLS and compare to lme().

n2 <- gls(Lambda ~ Group + LTER_Site + Core, data = lamest)
n3 <- lme(Lambda ~ Group + LTER_Site + Core, 
          random =~1 | LTER_Site, data = lamest) # First LMEM with a random term.

anova(n2, n3) # Compares the two models. n2 is preferred with an AIC value of 178.7976, but I want to keep the random term in.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(n3, col=1) # Check the residuals. AWESOME.
qqnorm(n3) # Pretty good. Going to skip the variance term.

# STEP 4: Fit the lme().

# Using n3 <- lme(Lambda ~ Group + LTER_Site + Core, random =~1 | LTER_Site, data = lamest)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

n3_ml <- lme(Lambda ~ Group + LTER_Site + Core, 
          random =~1 | LTER_Site, method = "ML", data = lamest) # ML model format.

n3sub1 <- update(n3_ml, .~. -Group) # Removes Group.
n3sub2 <- update(n3_ml, .~. -LTER_Site) # Removes Site.
n3sub3 <- update(n3_ml, .~. -Core) # Removes Core Section.

anova(n3_ml, n3sub1, n3sub2, n3sub3) # Compare the models. n3sub1 preferred with an AIC value of 174.4099, so remove Group.

n4 <- lme(Lambda ~ LTER_Site + Core, 
          random =~1 | LTER_Site, method = "ML", data = lamest)

n4sub1 <- update(n4, .~. -LTER_Site) # Removes Site.
n4sub2 <- update(n4, .~. -Core) # Removes Core Section.

anova(n4, n4sub1, n4sub2) # Compares the models. n4sub1 preferred with an AIC value of 172.4169, so take out Site.

n5 <- lme(Lambda ~ Core, 
          random =~1 | LTER_Site, method = "ML", data = lamest)

n5sub1 <- update(n5, .~. -Core) # Removes Core Section.

anova(n5, n5sub1) # Compares the models. n5 preferred with an AIC value of 172.4169, so leave in Core Section.

# n5 is the final full model!

# STEP 9: Refit with REML

nfinal <- lme(Lambda ~ Core, 
              random =~1 | LTER_Site, method = "REML", data = lamest)

# Output of the model.
summary(nfinal)
plot(nfinal, col=1) # Checking residuals.They're fine.
qqnorm(nfinal) # A little curvy but otherwise ok.
qqnorm(nfinal, ~ranef (.), col = 1) # Hah, two points.
#intervals(nfinal) # Show intervals.

# Final results.
anova(nfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of sampling site, sampling date, or core section on Lambda signatures of a given sediment sample. A random intercept by sample site was also included.

# Equation: Lambda = 1.93 - 0.51[Top] + random

# BONUS : Tukey's HSD Post Hoc

# NOT NECESSARY

```

The final model took the form : Lambda ~ Core + 1|LTER_Site

This translated to a formula of Lambda = 1.93 - 0.51[Top] + random.

Post hoc results: NA.

## S/V (estuarine)

```{r S/V estuary, include=FALSE}
### Data Exploration - boxplots and pairplots

boxplot(S.V ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(S.V ~ Group, data = estuarine) # Date boxplot. Fixed effect?
boxplot(S.V ~ Core, data = estuarine) # Core boxplot. Fixed effect?

svest <- estuarine %>%
  dplyr::select(LTER_Site, Group, Core, S.V) %>%
  na.omit # Creates new dataset.

# So, based on boxplots, I move forward with Site, Group, and Core as fixed effects and Site as a random variable.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(svest$S.V, groups = svest$LTER_Site) # S/V versus Site.
par(op) # A few outliers, but not taking out any more data.

pairs(svest) # Pairs plot. Hard to discern patterns here honestly.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - S/V
# Explanatory variables - Group, Site, Core

o1 <- lm(S.V ~ Group + Core + LTER_Site, data = svest) # Initial linear model.
ro1 <- rstandard(o1) # Assigns standardized residuals.
plot(ro1 ~ svest$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Doesn't look like site needs to be a random effect, but going to keep it in due to repeat sampling.

plot(ro1 ~ svest$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Removing from random structure.

plot(ro1 ~ svest$Core, xlab = "Water Depth Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Do not include as part of random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

o2 <- gls(S.V ~ Group + Core + LTER_Site, data = svest) # Linear regression.
o3 <- lme(S.V ~ Group + Core + LTER_Site, 
          random =~1 | LTER_Site, data = svest) # First LMEM with random term.

anova(o2, o3) # Compares the two models. o2 preferred with AIC value of 170.6228, but keeping random term in.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(o3, col=1) # Plots residuals before immediately applying variance transformation.

o4 <- lme(S.V ~ Group + Core + LTER_Site, 
          random =~1 | LTER_Site, data = svest,
          weights = varIdent(form =~1 | Group)) # Adding in a variance structure to allow for different variance by date - based on boxplots.

anova(o3, o4) # Compares model with random effect and model with both random and variance effects. o4 preferred with an AIC value of 154.6728 so keep alternate variance structure in there.

# STEP 4: Fit the lme().

# Using o4 <- lme(S.V ~ Group + Core + LTER_Site, 
#          random =~1 | LTER_Site, data = svest,
#          weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(o2, o4) # 4 definitely outperforms 2 with an AIC value of 154.6728.

# STEP 6: Everything ok? Check residuals.

plot(o4, col=1) # Residuals look better than they did.
qqnorm(o4) # Looks a little weird...but not terrible.

# STEP 7/8: Step-wise Optimal Fixed Structure

o4_ml <- lme(S.V ~ Group + Core + LTER_Site,
             random =~1 | LTER_Site, method = "ML", data = svest,
             weights = varIdent(form =~1 | Group)) # Creates current model using ML structure.

# Using the shorter syntax to save space.
o4sub1 <- update(o4_ml, .~. -Group) # Removes date sampled.
o4sub2 <- update(o4_ml, .~. -Core) # Removes core section.
o4sub3 <- update(o4_ml, .~. -LTER_Site) # Removes sampling site.
anova(o4_ml, o4sub1, o4sub2, o4sub3) # Compares all models. o4sub1 preferred with an AIC value of 146.7756. Remove Date sampled.

o5 <- lme(S.V ~ Core + LTER_Site,
             random =~1 | LTER_Site, method = "ML", data = svest,
             weights = varIdent(form =~1 | Group))
o5sub1 <- update(o5, .~. -Core) # Removes core section.
o5sub2 <- update(o5, .~. -LTER_Site) # Removes site sampled.
anova(o5, o5sub1, o5sub2) # Compares all models. o5sub1 preferred with an AIC value of 144.9788, so remove Core.

o6 <- lme(S.V ~ LTER_Site, 
          random =~1 | LTER_Site, method = "ML", data = svest,
          weights = varIdent(form =~1 | Group))
o6sub1 <- update(o6, .~. -LTER_Site) # Removes water depth.
anova(o6, o6sub1) # Compares all models. o6sub1 preferred with an AIC value of 143.3728, so remove Site..

# AND I'M DONE.

# STEP 9: Refit with REML

# NA

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is NO significant effect of date sampled, core section, or sampling site on estuarine S/V signatures. Random intercepts by site were included as well as a variance term for sampling date.

# Equation: S/V = NA

# BONUS : Tukey's HSD Post Hoc

# NA

```

The final model took the form : S.V ~ NA

This translated to a formula of S/V = NA

Post hoc results: NA.

##C/V (estuarine)

```{r C/V estuary, include=FALSE}
### Data Exploration - boxplots and pairplots

boxplot(C.V ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(C.V ~ Group, data = estuarine) # Date boxplot. Fixed effect.
boxplot(C.V ~ Core, data = estuarine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), Site, and Core (section) as fixed and Site as a random variable.

cvest <- estuarine %>%
  dplyr::select(LTER_Site, Group, Core, C.V) %>%
  na.omit # Creates new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(cvest$C.V, groups = cvest$LTER_Site) # C/V versus Site.
par(op) # Looking ok.

pairs(cvest) # Pairs plot; yes, variable choices still look good.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - C/V
# Explanatory variables - Group, Site, Core

p1 <- lm(C.V ~ Group + Core + LTER_Site, data = cvest) # Initial linear model.
rp1 <- rstandard(p1) # Assigns standardized residuals.

plot(rp1 ~ cvest$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Doesn't look like site needs to be a random effect, but going to keep it in due to repeat sampling.
# Checking other potential portions of the random effect as I've been doing above.
plot(rp1 ~ cvest$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Does not need to be in random structure.

plot(rp1 ~ cvest$Core, xlab = "Water Depth Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Does not need to be in random structure either.

#### STEP 2: Fit the lm() with GLS and compare to lme().

p2 <- gls(C.V ~ Group + Core + LTER_Site, data = cvest) # Linear regression.
p3 <- lme(C.V ~ Group + Core + LTER_Site, 
          random =~1 | LTER_Site, data = cvest) # First LMEM with random term.
anova(p2, p3) # Compares the two models. p2 preferred with an AIC value of -4.677118, but keeping random term in for replicate sampling sake.

# STEP 3: Decide on a variance structure.

plot(p3, col=1) # Plots residuals.

p4 <- lme(C.V ~ Group + Core + LTER_Site, 
          random =~1 | LTER_Site, data = cvest,
          weights = varIdent(form =~1 | Group)) # Adding variance structure by date.

anova(p3, p4) # Compares model with random effect and model with both random and variance effects. p4 preferred with an AIC value of -9.346233 so keep alternate variance structure in there.

# STEP 4: Fit the lme().

# Using p4 <- lme(C.V ~ Group + Core + LTER_Site, 
#          random =~1 | LTER_Site, data = cvest,
#          weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(p2, p4) # 4 definitely outperforms 2 with an AIC value of -9.346233.

# STEP 6: Everything ok? Check residuals.

plot(p4, col=1) # Residuals look better than they did.
qqnorm(p4) # Looks good.

# STEP 7/8: Step-wise Optimal Fixed Structure

p4_ml <- lme(C.V ~ Group + Core + LTER_Site,
             random =~1 | LTER_Site, method = "ML", data = cvest,
             weights = varIdent(form =~1 | Group)) # ML model structure.
p4sub1 <- update(p4_ml, .~. -Group) # Removes date sampled.
p4sub2 <- update(p4_ml, .~. -Core) # Removes core section.
p4sub3 <- update(p4_ml, .~. -LTER_Site) # Removes sampling site.
anova(p4_ml, p4sub1, p4sub2, p4sub3) # Compares all models. p4sub2 preferred with and AIC value of -38.75406. Remove Core.

p5 <- lme(C.V ~ Group + LTER_Site,
             random =~1 | LTER_Site, method = "ML", data = cvest,
             weights = varIdent(form =~1 | Group))
p5sub1 <- update(p5, .~. -LTER_Site) # Removes sampling site.
p5sub2 <- update(p5, .~. -Group) # Removes date sampled.
anova(p5, p5sub1, p5sub2) # Compares all models. p5sub1 preferred with an AIC value of -39.8869, so remove Site.

p6 <- lme(C.V ~ Group, 
          random =~1 | LTER_Site, method = "ML", data = cvest,
          weights = varIdent(form =~1 | Group))
p6sub1 <- update(p6, .~. -Group) # Removes date sampled.
anova(p6, p6sub1) # Compares all models. p6 preferred with an AIC value of -39.8869, so keep Group in there.

# p6 is the final full model!!!

# STEP 9: Refit with REML

pfinal <- lme(C.V ~ Group, 
              random =~1 | LTER_Site, method = "REML", data = cvest, 
              weights = varIdent(form =~1 | Group))

# Output of the model.
summary(pfinal)
plot(pfinal, col=1) # Checking residuals. Looking good!
qqnorm(pfinal) # Looks better than before - a little curvy, but OK I think.
qqnorm(pfinal, ~ranef (.), col = 1) # Plot of random effect residuals.
intervals(pfinal) # Show intervals.
anova(pfinal) # Output for the paper

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled on estuarine C/V signatures. Random intercepts by site were included as well as a variance term for sampling date.

# Equation: C/V = 0.19 + 0.11[GroupF] + 0.23[GroupH] + 0.27[GroupK] + random + variance

# BONUS : Tukey's HSD Post Hoc
pHSD <- glht(pfinal, linfct=mcp(Group="Tukey"))
summary(pHSD) # Results of post hoc: F - D, p = 0.0295; H - D, p = 0.00127; K - D, p = 0.00845; H - F, K - F, and K - H were p > 0.05.

```

The final model took the form : C.V ~ Group + 1|LTER_Site + 1|Group(var)

This translated to a formula of C/V = 0.19 + 0.11[GroupF] + 0.23[GroupH] + 0.27[GroupK] + random + variance.

Post hoc results: April 2016 and July 2016, p = 0.0295; April 2016 and April 2017, p = 0.00127; April 2016 and June 2017, p = 0.00845.

## P/V+S (estuarine)

```{r P/V+S estuary, include=FALSE}

### Data Exploration - boxplots and pairplots
boxplot(P..V.S. ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(P..V.S. ~ Group, data = estuarine) # Date boxplot. Fixed effect.
boxplot(P..V.S. ~ Core, data = estuarine) # Core section boxplot. Fixed effect?

# So, based on boxplots, I move forward with Group (date sampled), Core (section) and (sampling) Site as fixed variables and Site as a random variable.

pvsest <- estuarine %>%
  dplyr::select(LTER_Site, Group, Core, P..V.S.) %>% 
  na.omit # Create new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(pvsest$P..V.S., groups = pvsest$LTER_Site) # P/V+S versus Site.
par(op) # There's some outliers, but let's see how it goes without transformations.

pairs(pvsest) # Quick pairs plot to check correllated variables. Yep, variable choices still look good, and it looks like date is again going to drive the relationship here.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - P/V+S
# Explanatory variables - Site, Group, Date

q1 <- lm(P..V.S. ~ LTER_Site + Group + Core, data = pvsest) # Initial linear model.
rq1 <- rstandard(q1) # Assigns standardized residuals to rq1.
plot(rq1 ~ pvsest$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Similar to before, site may not be a random variable, but I'm going to keep it in to account for repeated measures.

plot(rq1 ~ pvsest$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Taking out of my random structure.

plot(rq1 ~ pvsest$Core, xlab = "Core Section",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Also not a random effect.

#### STEP 2: Fit the lm() with GLS and compare to lme().

q2 <- gls(P..V.S. ~ LTER_Site + Group + Core, data = pvsest) # Linear regression.
q3 <- lme(P..V.S. ~ LTER_Site + Group + Core, 
          random =~1 | LTER_Site, data = pvsest) # First LMEM with random term.
anova(q2, q3)# Compares the two models. q2 preferred with an AIC value of -58.78472. But I'm going to keep the random term in.

# STEP 3: Decide on a variance structure.

plot(q3, col=1) # Plots residuals. Yeah, we need one.

q4 <- lme(P..V.S. ~ LTER_Site + Group + Core, 
          random =~1 | LTER_Site, data = pvsest,
          weights = varIdent(form =~1 | Group)) # Creates variance structure by sampling date.
anova(q3, q4) # Compares the two models. q4 is better with an AIC value of -73.68188.

# STEP 4: Fit the lme().

# Using q4 <- lme(P..V.S. ~ LTER_Site + Group + Core, 
#          random =~1 | LTER_Site, data = pvsest,
#          weights = varIdent(form =~1 | Group))

# STEP 5: Compare the lm() and lme().

anova(q2,q4) # q4 still preferred with an AIC value of -73.68188.

# STEP 6: Everything ok? Check residuals.

plot(q4, col=1) # Residuals look far better.
qqnorm(q4) # Looks OK.

# STEP 7/8: Step-wise Optimal Fixed Structure

q4_ml <- lme(P..V.S. ~ LTER_Site + Group + Core, 
             random =~1 | LTER_Site, method = "ML", data = pvsest,
             weights = varIdent(form =~1 | Group)) # ML model structure.
q4sub1 <- update(q4_ml, .~. -LTER_Site) # Removes site.
q4sub2 <- update(q4_ml, .~. -Group) # Removes date.
q4sub3 <- update(q4_ml, .~. -Core) # Removes core section.
anova(q4_ml, q4sub1, q4sub2, q4sub3) # Compares all models. q4sub1 is preferred with an AIC value of -118.9703, so remove Site.

q5 <- lme(P..V.S. ~ Group + Core, 
             random =~1 | LTER_Site, method = "ML", data = pvsest,
             weights = varIdent(form =~1 | Group))
q5sub1 <- update(q5, .~. -Group) # Removes date.
q5sub2 <- update(q5, .~. -Core) # Removes core section.
anova(q5, q5sub1, q5sub2) # Compares all models. q5 preferred with an AIC value of -118.9703.

# STEP 9: Refit with REML

qfinal <- lme(P..V.S. ~ Group + Core,
              random =~1 | LTER_Site, method = "REML", data = pvsest, 
              weights = varIdent(form =~1 | Group))

# Output of the model.
summary(qfinal)
plot(qfinal, col=1) # Checking residuals.
qqnorm(qfinal) # Look pretty good considering low # of samples.
qqnorm(qfinal, ~ranef (.), col = 1) # Plot of random effect residuals.
intervals(qfinal) # Show intervals.

# Final Results.
anova(qfinal) # Output for the paper (which is all that people really care about ugh)

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled AND section of core on P/V+S signatures of a given estuarine sediment sample. Random intercept by sample site was also included as well as a variance term for water depth.

# Equation: P/V+S = 0.19 - 0.03[GroupF] - 0.13[GroupH] - 0.11[GroupK] + 0.04[CoreT] + random + variance

# BONUS : Tukey's HSD Post Hoc
qHSD_Core <- glht(qfinal, linfct=mcp(Core="Tukey"))
summary(qHSD_Core) # Top and bottom significantly different, p < 0.0001.

qHSD_Group <- glht(qfinal, linfct=mcp(Group="Tukey"))
summary(qHSD_Group) # H - D, p < 0.001; K - D, p < 0.001, H - F, p = 0.0116.

```

The final model took the form : P/V+S ~ Group + Core + 1|LTER_Site + 1|Group(var)

This translated to a formula of P/V+S = 0.19 - 0.03[GroupF] - 0.13[GroupH] - 0.11[GroupK] + 0.04[CoreT] + random + variance.

Post hoc results: Top & Bottom, p < 0.0001 ; Apr16 & Mar/Apr17, p < 0.001; Apr16 & Jun17, p < 0.001; Jun16 & Mar/Apr17, p = 0.0116.

## 3,5Bd/V (estuarine)

```{r 35Bd/V estuary, include=FALSE}

### Data Exploration

boxplot(Bd.V ~ LTER_Site, data = estuarine) # Site boxplot. Fixed effect.
boxplot(Bd.V ~ Group, data = estuarine) # Date boxplot. Fixed effect.
boxplot(Bd.V ~ Core, data = estuarine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), Site, and Core (section) and Site as a random effect.

bdvest <- estuarine %>%
  dplyr::select(LTER_Site, Group, Core, Bd.V) %>%
  na.omit # Create new dataset.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(bdvest$Bd.V, groups = bdvest$LTER_Site) # 3,5Bd/V versus Site.
par(op) # Looking ok - two major outliers here.

pairs(bdvest) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - 3,5-Bd/V
# Explanatory variables - Site, Group, Core

r1 <- lm(Bd.V ~ LTER_Site + Group + Core, data = bdvest) # Initial linear model.
rr1 <- rstandard(r1) # Assigns standardized residuals to rr1.

plot(rr1 ~ bdvest$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Yep, keep site as a random effect.

plot(rr1 ~ bdvest$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Group will not be a random effect.

plot(rr1 ~ bdvest$Core, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Core will not be a random effect.

#### STEP 2: Fit the lm() with GLS and compare to lme().

r2 <- gls(Bd.V ~ LTER_Site + Group + Core, data = bdvest) # Linear regression.
r3 <- lme(Bd.V ~ LTER_Site + Group + Core, 
          random =~1 | LTER_Site , data = bdvest) # First LMEM with random term.
anova(r2, r3) # Compares the two models. r2 preferred with an AIC value of -16.89324, but I'm going to keep the random structure in just in case.

# STEP 3: Decide on a variance structure.

plot(r3, col=1) # Plots residuals. I don't believe we need a variance structure, but I'm going to add one in in the hopes that it will help smooth out the difference between those two additional outliers.

r4 <- lme(Bd.V ~ LTER_Site + Group + Core,  
          random =~1 | LTER_Site, data = bdvest,
          weights = varIdent(form =~1 | Group)) 

anova(r3,r4) # Compares the two models. r4 preferred with an AIC value of -20.78922.

# STEP 4: Fit the lme().

# Using r4 <- lme(Bd.V ~ LTER_Site + Group + Core,  
#          random =~1 | LTER_Site, data = bdvest,
#          weights = varIdent(form =~1 | Group)) 

# STEP 5: Compare the lm() and lme().

anova(r2,r4) # zz4 preferred with an AIC value of -20.78922.

# STEP 6: Everything ok? Check residuals.

plot(r4, col=1) # Residuals look pretty good.
qqnorm(r4) # Looks ok, but not sure what more I could do here.

# STEP 7/8: Step-wise Optimal Fixed Structure

r4_ml <- lme(Bd.V ~ LTER_Site + Group + Core, 
             random =~1 | LTER_Site, method = "ML", data = bdvest, 
            weights = varIdent(form =~1 | Group))  # ML structure.
r4sub1 <- update(r4_ml, .~. -LTER_Site) # Removes site.
r4sub2 <- update(r4_ml, .~. -Group) # Removes date.
r4sub3 <- update(r4_ml, .~. -Core) # Removes core section.
anova(r4_ml, r4sub1, r4sub2, r4sub3) # Compares all models. r4sub2 is preferred with an AIC value of -55.27345. So, remove date.

r5_ml <- lme(Bd.V ~ LTER_Site + Core, 
             random =~1 | LTER_Site, method = "ML", data = bdvest, 
             weights = varIdent(form =~1 | Group))
r5sub1 <- update(r5_ml, .~. -LTER_Site) # Removes site.
r5sub2 <- update(r5_ml, .~. -Core) # Removes core.
anova(r5_ml, r5sub1, r5sub2) # r5sub1 preferred with an AIC value of -57.21403 - remove site.

r6_ml <- lme(Bd.V ~ Core, 
             random =~1 | LTER_Site, method = "ML", data = bdvest, 
             weights = varIdent(form =~1 | Group))
r6sub1 <- update(r6_ml, .~. -Core) # Removes core.
anova(r6_ml, r6sub1) # r6sub1 preferred with an AIC value of -58.84452 - so remove core.

# STEP 9: Refit with REML

# NA

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is no significant effect of date sampled, site, or core section on 3,5Bd/V signatures of a given estuarine sediment sample. Random intercept by sample site was also included as well as a variance term accounting for date sampled.

# BONUS : Tukey's HSD Post Hoc

# NA

```

The final model took the form : 3,5Bd/V ~ NA

This translated to a formula of 3,5-Bd/V = NA.

Post hoc results: NA.

# Marine data

```{r marine data, include=FALSE}

# For the following code chunks, I'll use this same dataset since I've not added in any additional info like I did with the stream data.

reef <- mastered %>%
  filter(mastered$Environment=="Reef")

# Ok, but in the following code, unless I create a separate dataset, all of the stream/marine site levels, for example, will still be in there, which I don't want for modeling purposes. So I'm going to do the following:

#write.csv(reef,"marine.csv") # Export the data.
marine <- read.csv("marine.csv") # Load the data back in.
#str(marine) # Check to make sure its in the format I want. Perfect!

# And now to make some final edits to be sure the factors are indeed factors:
marine$Depthf <- as.factor(marine$Depthf) # Makes the water depth column a series of factors.
marine$Group_3f <- as.factor(marine$Group_3f) # Makes the regional column a series of factors.

```

## Sigma 8 (marine)

```{r Sigma marine, include=FALSE}

### Data Exploration

boxplot(Sigma8 ~ Type, data = marine) # Distance from stream boxplot. Fixed effect. 
boxplot(Sigma8 ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(Sigma8 ~ Group, data = marine) # Date boxplot. Fixed effect.
boxplot(Sigma8 ~ Depth, data = marine) # Water depth boxplot. Fixed effect.
boxplot(Sigma8 ~ Core, data = marine) # Core boxplot. Fixed effect.

sigmar <- marine %>%
  dplyr::select(Type, LTER_Site, Depth, Core, Group, Sigma8) %>%
  na.omit # Creates new dataset.

pairs(sigmar) # Pairs plot. So, I'm going to investigate all four as fixed effects at first, but I think the Site should go in as a random effect too.

sigmar$Type <- factor(sigmar$Type, levels = c("MarineRunoff", "Marine")) # Relevels.
sigmar$fDepth <- as.factor(sigmar$Depth) # Make a new column with Depth as a factor.

#### STEP 1: Create a linear regression and check residuals.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(sigmar$Sigma8, groups = sigmar$Site) # Sigma8 versus Site on right with outliers removed.
par(op) # Eh, doesn't look that much better. So, I'm going to log transform it. Meh.

sigmar$logSigma8 <- log10(sigmar$Sigma8) # Log transform into new column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(sigmar$Sigma8, groups = sigmar$Site) # Sigma8 versus Site on left with outliers removed.
dotchart(sigmar$logSigma8, groups = sigmar$Site) # LogSigma8 versus Site on righ.
par(op) # Muuuuuuch better.

pairs(sigmar)

# Based on boxplots & pairplots : 
# Response variables - logSigma8
# Explanatory variables - Type, Site, Depth, Core, Group

s1 <- lm(logSigma8 ~ Type + LTER_Site + fDepth + Core + Group, data = sigmar) # Initial linear model.

rs1 <- rstandard(s1) # Assigns standardized residuals to rs1.
plot(rs1 ~ sigmar$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Since boxplots are all about zero, there is no within-site correlation, so it WILL NOT be used as a random effect.

plot(rs1 ~ sigmar$Group, xlab = "Date",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Group looks the same - all about zero.

plot(rs1 ~ sigmar$fDepth, xlab = "Depth",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Depth is exactly about zero.

plot(rs1 ~ sigmar$Core, xlab = "Core Section",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Core is exactly about zero.

# Ok, due to sampling structure, going to keep in LTER_Site as a random effect as I've done above.

#### STEP 2: Fit the lm() with GLS and compare to lme().

s2 <- gls(logSigma8 ~ Type + fDepth + Core + Group, data = sigmar) # Linear regression since it has no additional calls. Removed Site as a fixed effect because it resulted in an error message.

s3 <- lme(logSigma8 ~ Type + fDepth + Core + Group, random =~1 | LTER_Site, data = sigmar) # Creates the first LMEM with a random term so the lme() function works.

anova(s2, s3) # Compares the two models. s3 preferred with an AIC value of 421.9460.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(s3, col=1) # Check the residuals before jumping right in to applying variance transformation.
qqnorm(s3) # This actually looks pretty good - so I'm going to skip the added variance structure. (This is mostly likely due to log transformation.)

# STEP 4: Fit the lme().

# Using s3 <- lme(logSigma8 ~ Type + fDepth + Core + Group, random =~1 | LTER_Site, data = sigmar) 

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3.

# STEP 7/8: Step-wise Optimal Fixed Structure

s3_ml <- lme(logSigma8 ~ Type + fDepth + Core + Group, 
             random =~1 | LTER_Site, method = "ML", data = sigmar) # ML model structure.

s3sub1 <- update(s3_ml, .~. -Type) # Removes Type.
s3sub2 <- update(s3_ml, .~. -fDepth) # Removes Depth.
s3sub3 <- update(s3_ml, .~. -Core) # Removes Core.
s3sub4 <- update(s3_ml, .~. -Group) # Removes Group.

anova(s3_ml, s3sub1, s3sub2, s3sub3, s3sub4) # Compare the models. s3_ml preferred with an AIC value of 395.4894, so keep everything in.

# s3_ml is the final full model!!!

# STEP 9: Refit with REML

sfinal <- lme(logSigma8 ~ Type + fDepth + Core + Group, 
              random =~1 | LTER_Site, method = "REML", data = sigmar) # YIPEE!!!

# Output of the model.
summary(sfinal)

# Checking residuals.
plot(sfinal, col=1) # Not perfect, but no pattern.
qqnorm(sfinal) # This makes me feel pretty good.
qqnorm(sfinal, ~ranef (.), col = 1) # Looking good!
intervals(sfinal)# Show intervals.

# Final results.
anova(sfinal)

# STEP 10: What does this mean in WORDS?

# My model suggests there is NO significant effect of ecosystem type (marine sites near and far from stream mouths) on Sigma 8 concentrations of a given sediment sample. However, Date, Depth (10m/20m) and Core (Top/Bottom section) were significant.

# Equation: log(Sigma 8) = -0.70 - 0.26[Marine] + 0.6[20m] - 0.19[Top] + 0.01[GroupE] - 0.09[GroupG] + 0.06[GroupJ] + random

# BONUS POST HOC:

sHSD_Depth <- glht(sfinal, linfct=mcp(fDepth="Tukey")) # Tukey's post hoc analysis on fDepth factor.
summary(sHSD_Depth) # 20 and 10 m are significantly different from one another (p < 0.0001).

sHSD_Core <- glht(sfinal, linfct=mcp(Core="Tukey")) # Tukey's post hoc analysis on Core factor.
summary(sHSD_Core) # Top and bottom core sections are significantly different (p < 0.0001).

sHSD_Group <- glht(sfinal, linfct=mcp(Group="Tukey")) # Tukey's post hoc analysis on Date factor.
summary(sHSD_Group) # June 2017 (J) and March 2017 (G) were significantly different (p = 0.0187).

# Value calculations for manuscript:

sigmarmeans <- sigmar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanSig = mean(Sigma8, na.rm = TRUE), sdSig = sd(Sigma8, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : logSigma8 ~ Type + Depth + Core + Group + 1|LTER_Site

This translated to a formula of log(Sigma8) = -0.70 - 0.26[Marine] + 0.6[20m] - 0.19[Top] + 0.01[GroupE] - 0.09[GroupG] + 0.06[GroupJ] + random.

Post hoc results: 20M - 10M, p < 0.0001; Top - Bottom, p < 0.0001; March 2017 - June 2017, p = 0.0187.

## Lambda (marine)

```{r Lambda marine, include=FALSE}

### Data Exploration

boxplot(Lambda ~ Type, data = marine) # Distance from stream boxplot. Fixed effect. 
boxplot(Lambda ~ LTER_Site, data = marine) # Site boxplot. Random effect. (I'm not going to even try and include it as a fixed effect given what happened above.)
boxplot(Lambda ~ Group, data = marine) # Date boxplot. Fixed effect.
boxplot(Lambda ~ Depth, data = marine) # Depth boxplot. Fixed effect.
boxplot(Lambda ~ Core, data = marine) # Core section boxplot. Fixed effect.

lammar <- marine %>%
  dplyr::select(Type, LTER_Site, Group, Depth, Core, Lambda) %>%
  na.omit # Creates new dataset.

pairs(lammar) # Pairs plot.

lammar$Type <- factor(lammar$Type, levels = c("MarineRunoff", "Marine")) # Relevels for simpler labeling later.

#### STEP 1: Create a linear regression and check residuals.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(lammar$Lambda, groups = lammar$Site) # Lambda versus Site.
par(op) # Looks pretty good, save a few outliers still, but I'm not going to log().

# Based on boxplots & pairplots : 
# Response variables - Lambda
# Explanatory variables - Type, Depth, Core, Group

lammar$fDepth <- as.factor(lammar$Depth) # Converts Depth to a factor.

t1 <- lm(Lambda ~ Type + fDepth + Core + Group, data = lammar) # Initial linear model.
rt1 <- rstandard(t1) # Assigns standardized residuals to rt1.

plot(rt1 ~ lammar$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Yes, put in random term.

plot(rt1 ~ lammar$Group, xlab = "Date",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # No, keep out of random term.

plot(rt1 ~ lammar$Core, xlab = "Core Section",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # No, keep out of random term.

plot(rt1 ~ lammar$fDepth, xlab = "Water Depth",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # No, keep out of random term.

plot(rt1 ~ lammar$Type, xlab = "Distance from Stream",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # No, keep out of random term.

#### STEP 2: Fit the lm() with GLS and compare to lme().

t2 <- gls(Lambda ~ Type + fDepth + Core + Group, data = lammar) # Effectively a linear regression.
t3 <- lme(Lambda ~ Type + fDepth + Core + Group, random =~1 | LTER_Site, data = lammar) # First LMEM.
anova(t2, t3) # Compares the two models. t3 preferred with an AIC value of 775.1981.

#### STEP 3: Decide on a variance structure (aka random terms).

plot(t3, col=1) # We check the residuals before jumping right in to applying variance transformation.
qqnorm(t3) # This is actually meh - so I'm going to add in a variance structure.

# Looks like we should add in the varIden() variance structure for the observations in (based on boxplots) different Ecosystem Types (which I also chose based on past models).

t4 <- lme(Lambda ~ Type + fDepth + Core + Group,
           random =~1 | LTER_Site, data = lammar, 
           weights = varIdent(form =~1 | Type)) # Variance structure by Ecosystem.
anova(t3, t4) # Compares both models. t4 is much better with an AIC value of 762.3887.

plot(t4, col=1) 
qqnorm(t4) # Residuals look identical. I'm going to go back to t3, because it's simpler and I feel like does the same thing. I think the issue here may be lack of log() transformation, but I'm hesitant to do that since I didn't do it in treating the entire dataset.

# STEP 4: Fit the lme().

# Using t3 <- lme(Lambda ~ Type + fDepth + Core + Group, random =~1 | LTER_Site, data = lammar)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

# See Step 3. 

# STEP 7/8: Step-wise Optimal Fixed Structure

t3_ml <- lme(Lambda ~ Type + fDepth + Core + Group, 
              random =~1 | LTER_Site, method = "ML", data = lammar) # ML model structure.

t3sub1 <- update(t3_ml, .~. -Type) # Removes Type.
t3sub2 <- update(t3_ml, .~. -fDepth) # Removes Depth.
t3sub3 <- update(t3_ml, .~. -Core) # Removes Core.
t3sub4 <- update(t3_ml, .~. -Group) # Removes Group.

anova(t3_ml, t3sub1, t3sub2, t3sub3, t3sub4) # Compare the models. t3_ml preferred with an AIC value of 754.0156, so keep everything in!

# STEP 9: Refit with REML

tfinal <- lme(Lambda ~ Type + fDepth + Core + Group, 
              random =~1 | LTER_Site , method = "REML", data = lammar)

# Output of the model.
summary(tfinal)

# Checking residuals.
plot(tfinal, col=1) # Not perfect, but no huge pattern.
qqnorm(tfinal) # Looking ok.
qqnorm(tfinal, ~ranef (.), col = 1) # Looks good.
intervals(tfinal) # Show intervals.

# Final results.
anova(tfinal)

# STEP 10: What does this mean in WORDS?

# My model suggests there is NO significant effect of ecosystem type (marine sites near and far from stream mouths) on Lambda concentrations of a given sediment sample. Group (date sampled), fDepth (water depth sampled), and Core (top v. bottom) were significant.

# Equation: Lambda = 0.41 + 0.40[MarineRunoff] + 0.50[20m] - 0.26[Top] + 0.28[GroupE] + 0.25[GroupG] + 0.42[GroupJ] + random

# BONUS POST HOC:

tHSD_Depth <- glht(tfinal, linfct=mcp(fDepth="Tukey")) # Tukey's post hoc analysis on fDepth factor.
summary(tHSD_Depth) # 20 and 10 m are significantly different from one another (p < 0.0001).

tHSD_Core <- glht(tfinal, linfct=mcp(Core="Tukey")) # Tukey's post hoc analysis on Core factor.
summary(tHSD_Core) # Top and bottom core sections are significantly different (p = 0.0002).

tHSD_Group <- glht(tfinal, linfct=mcp(Group="Tukey")) # Tukey's post hoc analysis on Date factor.
summary(tHSD_Group) # Dec 2015 (A) and June 2017 (J) were significantly different (p < 0.001).

# Value calculations for manuscript:

lammarmeans <- lammar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanLam = mean(Lambda, na.rm = TRUE), sdLam = sd(Lambda, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : Lambda ~ Type + Depth + Core + Group + 1|LTER_Site

This translated to a formula of Lambda = 0.41 + 0.40[MarineRunoff] + 0.50[20m] - 0.26[Top] + 0.28[GroupE] + 0.25[GroupG] + 0.42[GroupJ] + random.

Post hoc results: 20M - 10M, p < 0.0001; Top - Bottom, p = 0.0002; December 2015 (A) - June 2017 (J), p < 0.001 (all others NS).

## S/V (marine)

```{r S/V marine, include=FALSE}

### Data Exploration - boxplots and pairplots

boxplot(S.V ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(S.V ~ Group, data = marine) # Date boxplot. Fixed effect?
boxplot(S.V ~ Depth, data = marine) # Depth boxplot. Fixed effect.
boxplot(S.V ~ Core, data = marine) # Core section boxplot. Fixed effect.
boxplot(S.V ~ Type, data = marine) # Distance from stream boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), (Water) Depth, Core Section, and Type (Near/Far from Runoff) as fixed and Site as a random effect.

svmar <- marine %>%
  dplyr::select(Type, LTER_Site, Group, Depth, Core, S.V) %>%
  na.omit # Create new dataset.

svmar$Depthf <- as.factor(svmar$Depth) # Makes a new column with depth represented as a factor.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(svmar$S.V, groups = svmar$LTER_Site) # S/V versus Site.
par(op) # Looking ok. Going to keep moving forward without transformations.

pairs(svmar) # Quick pairs plot to check correllated variables. Yep, variable choices still look good.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - S/V
# Explanatory variables - Type, Group, Depth, Core

u1 <- lm(S.V ~ Type + Group + Depthf + Core, data = svmar) # Initial linear model.
ru1 <- rstandard(u1) # Assigns standardized residuals.

plot(ru1 ~ svmar$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Boxplots don't appear to show a lot of within-site correlation, but I'm going to keep it as part of the random intercept model structure to account for repeat sampling format.

plot(ru1 ~ svmar$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # I'm going to take it out of my random structure.

plot(ru1 ~ svmar$Depthf, xlab = "Water Depth Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # I'm going to take it out of my random structure.

plot(ru1 ~ svmar$Type, xlab = "Distance from Stream",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # I'm going to take it out of my random structure.

plot(ru1 ~ svmar$Core, xlab = "Core Section",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Also not going to include this in the random structure.

# So, going forward our structure has Type, Group, Core and Depth as fixed and Site as random variables.

#### STEP 2: Fit the lm() with GLS and compare to lme().

u2 <- gls(S.V ~ Type + Group + Depthf + Core, data = svmar) # Linear regression.
u3 <- lme(S.V ~ Type + Group + Depthf + Core, 
          random =~1 | LTER_Site, data = svmar) # First LMEM with random term.
anova(u2, u3) # Compares the two models. u3 preferred with an AIC value of 1260.253.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(u3, col=1) # Plots residuals before immediately applying variance transformation.

u4 <- lme(S.V ~ Type + Group + Depthf + Core, 
          random =~1 | LTER_Site, data = svmar,
          weights = varIdent(form =~1 | Depthf)) # Adding in a variance structure by depth - based on boxplots. Depth appeared to have a greater difference in variances.

anova(u3, u4) # Compares model with random effect and model with both random and variance effects. u4 preferred with an AIC value of 1139.928.

plot(u4, col=1) # Residuals look much better in this instance.

# STEP 4: Fit the lme().

# Using u4 <- lme(S.V ~ Type + Group + Depthf + Core, 
#          random =~1 | LTER_Site, data = SV_marine,
#          weights = varIdent(form =~1 | Depthf))

# STEP 5: Compare the lm() and lme().

anova(u2, u4) # 4 definitely outperforms 2 with an AIC value of 1139.928.

# STEP 6: Everything ok? Check residuals.

plot(u4, col=1) # Residuals look better than they did.
qqnorm(u4) # Looks pretty good.

# STEP 7/8: Step-wise Optimal Fixed Structure

u4_ml <- lme(S.V ~ Type + Group + Depthf + Core, 
             random =~1 | LTER_Site, method = "ML", data = svmar,
             weights = varIdent(form =~1 | Depthf)) # Creates current model using ML structure.
u4sub1 <- update(u4_ml, .~. -Group) # Removes date sampled.
u4sub2 <- update(u4_ml, .~. -Depthf) # Removes water depth.
u4sub3 <- update(u4_ml, .~. -Type) # Removes near/far classification.
u4sub4 <- update(u4_ml, .~. -Core) # Removes core section.
anova(u4_ml, u4sub1, u4sub2, u4sub3, u4sub4) # Compares all models. u4sub3 preferred with an AIC value of 1124.780. Remove Type.

u5 <- lme(S.V ~ Group + Depthf + Core, 
          random =~1 | LTER_Site, method = "ML", data = svmar,
          weights = varIdent(form =~1 | Depthf))
u5sub1 <- update(u5, .~. -Depthf) # Removes water depth.
u5sub2 <- update(u5, .~. -Group) # Removes date sampled.
u5sub3 <- update(u5, .~. -Core) # Removes date sampled.
anova(u5, u5sub1, u5sub2, u5sub3) # Compares all models. u5 preferred with an AIC value of 1124.780, so keep everything in.

# STEP 9: Refit with REML

ufinal <- lme(S.V ~ Group + Depthf + Core, 
              random =~1 | LTER_Site, method = "REML", data = svmar, 
              weights = varIdent(form =~1 | Depthf))

# Output of the model.
summary(ufinal)
plot(ufinal, col=1) # Checking residuals. Looking good!
qqnorm(ufinal) # Looks a little curvy, but OK I think.
qqnorm(ufinal, ~ranef (.), col = 1) # Plot of random effect residuals looks OK!
intervals(ufinal) # Show intervals.

# Final results.
anova(ufinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of water depth and date sampled on marine S/V signatures, but not core section or classification as distance from stream. Random intercepts by site were included as well as a variance term for water depth.

# Equation: S/V = 3.20 - 0.91[Depthf20] + 0.15[Top] + 0.19[GroupE] + 0.47[GroupG] + 0.24[GroupJ] + random + variance

# BONUS : Tukey's HSD Post Hoc
uHSD_Depth <- glht(ufinal, linfct=mcp(Depthf="Tukey"))
summary(uHSD_Depth) # Significant different between 10 and 20m (p < 0.0001).

uHSD_Group <- glht(ufinal, linfct=mcp(Group="Tukey"))
summary(uHSD_Group) # Significant different between Dec 2015 (A) and March 2017 (G) (p = 0.0079).

# Value calculations for manuscript:

svmarmeans <- svmar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanSV = mean(S.V, na.rm = TRUE), sdSV = sd(S.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : S.V ~ Depth + Group + Core + 1|LTER_Site + 1|Depth(var)

This translated to a formula of S/V = 3.20 - 0.91[Depthf20] + 0.15[Top] + 0.19[GroupE] + 0.47[GroupG] + 0.24[GroupJ] + random + variance.

Post hoc results: 20m & 10m, p < 0.0001; Dec 2015 & Mar 2017, p = 0.0079

## C/V (marine)

```{r C/V marine, include=FALSE}

### Data Exploration - boxplots and pairplots

boxplot(C.V ~ Type, data = marine) # Distance from stream boxplot. Fixed effect.
boxplot(C.V ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(C.V ~ Group, data = marine) # Date boxplot. Fixed effect.
boxplot(C.V ~ Depth, data = marine) # Depth boxplot. Fixed effect.
boxplot(C.V ~ Core, data = marine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Type (near/far from runoff), Group (date sampled), (water) Depth, anc Core (section) as fixed variables and Site as a random variables.

cvmar <- marine %>%
  dplyr::select(Type, LTER_Site, Group, Depth, Core, C.V) %>%
  na.omit # Create new dataset.

cvmar$Depthf <- factor(cvmar$Depth) # Makes depth a factor.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(cvmar$C.V, groups = cvmar$LTER_Site) # C/V versus Site.
par(op) # A few outliers, but I'm going to leave it untransformed.

pairs(cvmar) # Quick pairs plot to check correllated variables. Yep, variable choices still look good.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - C/V
# Explanatory variables - Type, Group, Depth, Core

v1 <- lm(C.V ~ Type + Group + Depthf + Core, data = cvmar) # Initial linear model.
rv1 <- rstandard(v1) # Assigns standardized residuals.
plot(rv1 ~ cvmar$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Doesn't appear to have a lot of within site correlation, but I will keep it as part of a random structure.

plot(rv1 ~ cvmar$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not in my random structure.

plot(rv1 ~ cvmar$Depthf, xlab = "Water Depth Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not in random structure.

plot(rv1 ~ cvmar$Core, xlab = "Core Section",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Not in random structure.

#### STEP 2: Fit the lm() with GLS and compare to lme().

v2 <- gls(C.V ~ Type + Group + Depthf + Core, data = cvmar) # Linear regression.
v3 <- lme(C.V ~ Type + Group + Depthf + Core, 
          random =~1 | LTER_Site, data = cvmar) # Creates the first LMEM with random term.
anova(v2, v3) # Compares the models. v3 preferred with an AIC value of -642.6986 so keep random effect.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(v3, col=1) # Plots residuals before immediately applying variance transformation. Looks like a variance term may be necessary.

v4 <- lme(C.V ~ Type + Group + Depthf + Core, 
          random =~1 | LTER_Site, data = cvmar,
          weights = varIdent(form =~1 | Group)) # Adds in term to account for difference variances by date sampled based on boxplots.

anova(v3,v4) # looks like v4 is preferred with an AIC value of -662.0723.

plot(v4, col=1) # The residuals don't really look all that different, so to keep things simple, I'll stick with the model structure WITHOUT the added variance term.

# STEP 4: Fit the lme().

# Using v3 <- lme(C.V ~ Type + Group + Depthf + Core, 
#          random =~1 | LTER_Site, data = cvmar)

# STEP 5: Compare the lm() and lme().

# See Step 2.

# STEP 6: Everything ok? Check residuals.

plot(v3, col=1) # Fine for our purposes.
qqnorm(v3) # Looks curved, but so did the SV qq plot.
qqnorm(v4) # With variance structure looks no different, so moving on...

# STEP 7/8: Step-wise Optimal Fixed Structure

v3_ml <- lme(C.V ~ Type + Group + Depthf + Core, 
             random =~1 | LTER_Site, method = "ML", data = cvmar) # ML model structure.

v3sub1 <- update(v3_ml, .~. -Type) # Removes near/far classification.
v3sub2 <- update(v3_ml, .~. -Group) # Removes date sampled.
v3sub3 <- update(v3_ml, .~. -Depthf) # Removes water depth sampled.
v3sub4 <- update(v3_ml, .~. -Core) # Removes core section sampled.

anova(v3_ml, v3sub1, v3sub2, v3sub3, v3sub4) # Compares all models. v3sub4 preferred with an AIC value of -696.1887 so remove Core section.

v5 <- lme(C.V ~ Type + Group + Depthf, 
             random =~1 | LTER_Site, method = "ML", data = cvmar) # ML model structure.

v5sub1 <- update(v5, .~. -Type) # Removes near/far classification.
v5sub2 <- update(v5, .~. -Group) # Removes date sampled.
v5sub3 <- update(v5, .~. -Depthf) # Removes water depth sampled.

anova(v5, v5sub1, v5sub2, v5sub3) # Compares all models. v5sub1 preferred with an AIC value of -696.2471 so remove near/far classification.

v6 <- lme(C.V ~ Group + Depthf, 
             random =~1 | LTER_Site, method = "ML", data = cvmar) # ML model structure.

v6sub1 <- update(v6, .~. -Group) # Removes date sampled.
v6sub2 <- update(v6, .~. -Depthf) # Removes water depth sampled.

anova(v6, v6sub1, v6sub2) # Compares all models. v6 preferred with an AIC value of -696.2471 so keep everything else in.
# v6 is the final full model.

# STEP 9: Refit with REML

vfinal <- lme(C.V ~ Group + Depthf,  
              random =~1 | LTER_Site, method = "REML", data = cvmar)

# Output of the model.
summary(vfinal)
plot(vfinal, col=1) # Checking residuals. Looking ok!
qqnorm(vfinal) # Looks meh, but I'm going to leave it.
qqnorm(vfinal, ~ranef (.), col = 1) # Plot of random effect residuals looks good!
intervals(vfinal) # Show intervals.

# Final results.
anova(vfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled and water depth sampled on marine C/V signatures. Random intercepts by site were included.

# Equation: C/V = 0.14 - 0.06[GroupE] - 0.04[GroupG] - 0.02[GroupJ] - 0.02[Depth20] + random

# BONUS : Tukey's HSD Post Hoc
vHSD_Group <- glht(vfinal, linfct=mcp(Group="Tukey")) 
summary(vHSD_Group) # Significant different between Jun 16 (E) & Dec 15 (A) (p < 0.001), Mar 17 (G) & Dec 15 (A) (p = 0.00676), and Jun 17 (J) & Jun 16 (E) (p = 0.02117).

vHSD_Depth <- glht(vfinal, linfct=mcp(Depthf="Tukey"))
summary(vHSD_Depth) # Significant difference between 20 and 10m (p = 0.0384).

# Value calculations for manuscript:

cvmarmeans <- cvmar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanCV = mean(C.V, na.rm = TRUE), sdCV = sd(C.V, na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : C.V ~ Group + Depth + 1|LTER_Site

This translated to a formula of C/V = 0.14 - 0.06[GroupE] - 0.04[GroupG] - 0.02[GroupJ] - 0.02[Depth20] + random.

Post hoc results: Dec15 & Jun16, p < 0.001 ; Dec15 & Mar17, p = 0.00676; Jun16 & Jun17, p = 0.02117; 20 m & 10 m, p = 0.0384.

## P/V+S (marine)

```{r P/V+S marine, include=FALSE}

### Data Exploration - boxplots and pairplots
boxplot(P..V.S. ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(P..V.S. ~ Group, data = marine) # Date boxplot. Fixed effect.
boxplot(P..V.S. ~ Depth, data = marine) # Depth boxplot. Fixed effect.
boxplot(P..V.S. ~ Type, data = marine) # Distance from stream boxplot. Fixed effect.
boxplot(P..V.S. ~ Core, data = marine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Group (date sampled), (water) Depth, Core (section) and Type (near/far from stream) as fixed variables and Site as a random variable.

pvsmar <- marine %>%
  dplyr::select(Type, LTER_Site, Group, Depth, Core, P..V.S.) %>%
  na.omit # Create new dataset.

pvsmar$Depthf <- as.factor(pvsmar$Depth) # Makes depth a factor.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(pvsmar$P..V.S., groups = pvsmar$LTER_Site) # P/V+S versus Site.
par(op) # Looking ok. There's two pretty big outliers, so I'm going to log-transform as I did for the entire dataset up above.

pvsmar$logPVS <- log10(pvsmar$P..V.S.) # Makes log-transformed column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(pvsmar$P..V.S., groups = pvsmar$LTER_Site) # P/V+S versus Site.
dotchart(pvsmar$logPVS, groups = pvsmar$LTER_Site) # log(P/V+S) versus Site.
par(op) # Looking MUCH better. 

pairs(pvsmar) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - P/V+S
# Explanatory variables - Type, Group, Depth, Core

w1 <- lm(logPVS ~ Type + Group + Depthf + Core, data = pvsmar) # Initial linear model.
rw1 <- rstandard(w1) # Assigns standardized residuals to rw1.
plot(rw1 ~ pvsmar$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Keeping as part of random effect.

plot(rw1 ~ pvsmar$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Remove from random structure.

plot(rw1 ~ pvsmar$Depthf, xlab = "Depth Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Also not necessary as a random effect.

plot(rw1 ~ pvsmar$Core, xlab = "Depth Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Also not necessary as a random effect.

#### STEP 2: Fit the lm() with GLS and compare to lme().

w2 <- gls(logPVS ~ Type + Group + Depthf + Core, data = pvsmar) # Linear regression.
w3 <- lme(logPVS ~ Type + Group + Depthf + Core, 
          random =~1 | LTER_Site, data = pvsmar ) # First LMEM with random term.
anova(w2, w3) # Compares the two models. w3 preferred with AIC value of 24.77337.

# STEP 3: Decide on a variance structure (aka random terms and correlation structure if any).

plot(w3, col=1) # Plots residuals. Yeah, we need an additional variance structure.

w4 <- lme(logPVS ~ Type + Group + Depthf + Core, 
          random =~1 | LTER_Site, data = pvsmar,
          weights = varIdent(form =~1 | Depthf)) # Creates structure including different variance allowed by water depth based on the variances displayed by boxplots above.
anova(w3, w4) # Compares the two models. w4 is better with an AIC value of 4.798535.

# STEP 4: Fit the lme().

# Using w4 <- lme(P..V.S. ~ Type + Group + Depthf + Core, 
#          random =~1 | LTER_Site, data = pvsmar,
#          weights = varIdent(form =~1 | Depthf))

# STEP 5: Compare the lm() and lme().

anova(w2,w4) # w4 still preferred with an AIC value of 4.79854.

# STEP 6: Everything ok? Check residuals.

plot(w4, col=1) # Residuals look better. I've got those two outliers but oh well.
qqnorm(w4) # Looks fine.

# STEP 7/8: Step-wise Optimal Fixed Structure

w4_ml <- lme(logPVS ~ Type + Group + Depthf + Core, 
             random =~1 | LTER_Site, method = "ML", data = pvsmar,
             weights = varIdent(form =~1 | Depthf)) # ML model structure.
w4sub1 <- update(w4_ml, .~. -Type) # Removes near/far classification.
w4sub2 <- update(w4_ml, .~. -Group) # Removes date.
w4sub3 <- update(w4_ml, .~. -Depthf) # Removes water depth.
w4sub4 <- update(w4_ml, .~. -Core) # Removes water depth.
anova(w4_ml, w4sub1, w4sub2, w4sub3, w4sub4) # Compares all models. w4 is preferred with an AIC value of -30.33340, so keep everything in.

# STEP 9: Refit with REML

wfinal <- lme(logPVS ~ Type + Group + Depthf + Core,
              random =~1 | LTER_Site, method = "REML", data = pvsmar, 
              weights = varIdent(form =~1 | Depthf))

# Output of the model.
summary(wfinal)
plot(wfinal, col=1) # Checking residuals.
qqnorm(wfinal) # Look pretty good considering low # of samples.
qqnorm(wfinal, ~ranef (.), col = 1) # Plot of random effect residuals, looks ok...
intervals(wfinal) # Show intervals.

# Find Results.
anova(wfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of location near/far from stream, date sampled, core section, AND water depth on P/V+S signatures of a given marine sediment sample. Random intercept by sample site was also included as well as a variance term for water depth.

# Equation: P/V+S = - 0.48 - 0.14[MarineRunoff] - 0.07[GroupE] - 0.15[GroupG] - 0.45[GroupJ] - 0.22[Depth20] + 0.08[Top] + random + variance

# BONUS : Tukey's HSD Post Hoc
wHSD_Type <- glht(wfinal, linfct=mcp(Type="Tukey"))
summary(wHSD_Type) # All significantly different.

wHSD_Group <- glht(wfinal, linfct=mcp(Group="Tukey"))
summary(wHSD_Group) # All significantly different.

wHSD_Depth <- glht(wfinal, linfct=mcp(Depthf="Tukey"))
summary(wHSD_Depth) # All significantly different.

wHSD_Core <- glht(wfinal, linfct=mcp(Core="Tukey"))
summary(wHSD_Core) # All significantly different.

# Value calculations for manuscript:

pvsmarmeans <- pvsmar %>% # Takes the original dataset and then ...
  group_by(Type) %>%     # Groups data and then ...
  summarize(meanPVS = mean(P..V.S., na.rm = TRUE), sdPVS = sd(P..V.S., na.rm = TRUE)) %>% # Calculates summaries ...
  ungroup()

```

The final model took the form : log(P/V+S) ~ Type + Group + Depth + Core + 1|LTER_Site + 1|Depth(var)

This translated to a formula of log(P/V+S) = - 0.48 - 0.14[MarineRunoff] - 0.07[GroupE] - 0.15[GroupG] - 0.45[GroupJ] - 0.22[Depth20] + 0.08[Top] + random + variance.

Post hoc results: Marine & MarineRunoff, p = 0.0149 ; Top & Bottom, p = 0.000951; Dec15 & Mar17, p < 0.001; Dec15 & Jun17, p < 0.001; Jun16 & Jun17, p < 0.001; Mar17 & Jun17, p < 0.001; 20m & 10m, p < 0.0001.

## 3,5Bd/V (marine)

```{r 35Bd/V marine, include=FALSE}

### Data Exploration - boxplots and pairplots

boxplot(Bd.V ~ Type, data = marine) # Distance from stream boxplot. Fixed effect.
boxplot(Bd.V ~ LTER_Site, data = marine) # Site boxplot. Random effect.
boxplot(Bd.V ~ Group, data = marine) # Date boxplot. Fixed effect?
boxplot(Bd.V ~ Depth, data = marine) # Depth boxplot. Fixed effect.
boxplot(Bd.V ~ Core, data = marine) # Core boxplot. Fixed effect.

# So, based on boxplots, I move forward with Type (near/far), Group (date sampled), Core (section) and (water) Depth as fixed variables and Site as a random effect.

bdvmar <- marine %>%
  dplyr::select(Type, LTER_Site, Group, Depth, Core, Bd.V) %>%
  na.omit # Create new dataset.

bdvmar$Depthf <- as.factor(bdvmar$Depth) # Transforms depth into a factor.

op<- par(mfrow = c(1, 1), mar = c(3, 4, 1, 1))
dotchart(bdvmar$Bd.V, groups = bdvmar$LTER_Site) # 3,5Bd/V versus Site.
par(op) # Looking ok. I'm going to log-transform as I did with PVS.

bdvmar$logBDV <- log10(bdvmar$Bd.V) # Makes log-transformed column.

op<- par(mfrow = c(1, 2), mar = c(3, 4, 1, 1))
dotchart(bdvmar$Bd.V, groups = bdvmar$LTER_Site) # 3,5Bd/V versus Site.
dotchart(bdvmar$logBDV, groups = bdvmar$LTER_Site) # log(3,5Bd/V) versus Site.
par(op) # Looks much better.

pairs(bdvmar) # Quick pairs plot to check correllated variables.

#### STEP 1: Create a linear regression and check residuals.

# Response variables - 3,5-Bd/V
# Explanatory variables - Type, Group, Depth, Core

x1 <- lm(logBDV ~ Type + Group + Depthf + Core, data = bdvmar) # Initial linear model.
rx1 <- rstandard(x1) # Assigns standardized residuals to rx1.

plot(rx1 ~ bdvmar$LTER_Site, xlab = "Site",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Yep, keep site as a random effect.

plot(rx1 ~ bdvmar$Group, xlab = "Date Sampled",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Group will not be a random effect.

plot(rx1 ~ bdvmar$Core, xlab = "Core Section",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Core will not be a random effect.

plot(rx1 ~ bdvmar$Type, xlab = "Distance from Stream",
     ylab = "Standardised residuals") # Plots said residuals.
abline(0,0) # Type will not be a random effect.

#### STEP 2: Fit the lm() with GLS and compare to lme().

x2 <- gls(logBDV ~ Type + Group + Depthf + Core, data = bdvmar) # Linear regression.
x3 <- lme(logBDV ~ Type + Group + Depthf + Core, 
          random =~1 | LTER_Site , data = bdvmar) # First LMEM with random term.
anova(x2, x3) # Compares the two models. x3 preferred with an AIC value of 71.58302.

# STEP 3: Decide on a variance structure.

plot(x3, col=1) # Plots residuals before immediately applying variance transformation. We definitely need one.

x4 <- lme(logBDV ~ Type + Group + Depthf + Core,  
          random =~1 | LTER_Site, data = bdvmar,
          weights = varIdent(form =~1 | Depthf)) # Again this is based on the spread I saw in the boxplots, and it was greatest in the Depth data.

anova(x3,x4) # Compares the two models. x4 preferred with an AIC value of 8.60486.

# STEP 4: Fit the lme().

# Using x4 <- lme(logBDV ~ Type + Group + Depthf + Core,  
#          random =~1 | LTER_Site, data = bdvmar,
#          weights = varIdent(form =~1 | Depthf))  

# STEP 5: Compare the lm() and lme().

anova(x2,x4) # x4 still preferred with an AIC value of 8.60486.

# STEP 6: Everything ok? Check residuals.

plot(x4, col=1) # Residuals look pretty good. Better about the x axis than before.
qqnorm(x4) # Looks ok.

# STEP 7/8: Step-wise Optimal Fixed Structure

x4_ml <- lme(logBDV ~ Type + Group + Depthf + Core, 
             random =~1 | LTER_Site, method = "ML", data = bdvmar, 
             weights = varIdent(form =~1 | Depthf))  # ML model structure.
x4sub1 <- update(x4_ml, .~. -Type) # Removes near/far from stream classification.
x4sub2 <- update(x4_ml, .~. -Group) # Removes date.
x4sub3 <- update(x4_ml, .~. -Depthf) # Removes water depth.
x4sub4 <- update(x4_ml, .~. -Core) # Removes core section.
anova(x4_ml, x4sub1, x4sub2, x4sub3, x4sub4) # Compares all models. x4sub1 is preferred with an AIC value of -28.75271. So, remove Type.

x5 <- lme(logBDV ~ Group + Depthf + Core, 
          random =~1 | LTER_Site, method = "ML", data = bdvmar, 
          weights = varIdent(form =~1 | Depthf))
x5sub1 <- update(x5, .~. -Depthf) # Removes water depth.
x5sub2 <- update(x5, .~. -Group) # Removes date.
x5sub3 <- update(x5, .~. -Core) # Removes core section.
anova(x5, x5sub1, x5sub2, x5sub3) # x5 preferred with an AIC value of -28.75271 - keep everything else in.

# STEP 9: Refit with REML

xfinal <- lme(logBDV ~ Group + Depthf + Core, 
              random =~1 | LTER_Site, method = "REML", data = bdvmar, 
              weights = varIdent(form =~1 | Depthf)) # Yay!! LAST ONE!!!

# Output of the model.
summary(xfinal)
plot(xfinal, col=1) # Checking residuals.
qqnorm(xfinal) # Looks better than before.
qqnorm(xfinal, ~ranef (.), col = 1) # Plot of random effect residuals, looks good.
intervals(xfinal) # Show intervals.

# Final results.
anova(xfinal) # Output for the paper.

# STEP 10: What does this mean in WORDS?

# I applied a linear mixed effect modelling approach because the data are nested. My model suggests there is a significant effect of date sampled, core section, and water depth on 3,5Bd/V signatures of a given marine sediment sample. Random intercept by sample site was also included as well as a variance term accounting for water depth.

# Equation: 3,5-Bd/V = - 0.34 + 0.10[GroupE] + 0.13[GroupG] + 0.16[GroupJ] - 0.30[Depth20] + 0.06[CoreT] + random + variance

# BONUS : Tukey's HSD Post Hoc
xHSD_Group <- glht(xfinal, linfct=mcp(Group="Tukey"))
summary(xHSD_Group) # A&G and A&J significantly different.

xHSD_Depth <- glht(xfinal, linfct=mcp(Depthf="Tukey"))
summary(xHSD_Depth) # 20m and 10m significantly different.

xHSD_Core <- glht(xfinal, linfct=mcp(Core="Tukey"))
summary(xHSD_Core) # Top and Bottom significantly different.

```

The final model took the form : log(3,5Bd/V) ~ Group + Depth + Core + 1|LTER_Site + 1|Depth(var)

This translated to a formula of log(3,5-Bd/V) = - 0.34 + 0.10[GroupE] + 0.13[GroupG] + 0.16[GroupJ] - 0.30[Depth20] + 0.06[CoreT] + random + variance.

Post hoc results: Dec15 & Jun16, p = 0.0266; Dec15 & Mar17, p < 0.001; Dec15 & Jun17, p < 0.001; 20m & 10m, p < 0.0001; Top & Bottom, p = 0.0023.

This is the end of the RMarkdown document.